{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "OHJWesKs-tqd"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import time\n",
        "import ipyparallel as ipp\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import dfca as DFCA\n",
        "import ifca as IFCA\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from util import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAghP_o0-tqe"
      },
      "source": [
        "Reads Config file and prepares the arguments you can choose in the config_dfca.json/config_ifca.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting 3 engines with <class 'ipyparallel.cluster.launcher.LocalEngineSetLauncher'>\n",
            "100%|██████████| 3/3 [00:06<00:00,  2.06s/engine]\n"
          ]
        }
      ],
      "source": [
        "rc = ipp.Cluster(n=3).start_and_connect_sync()\n",
        "rc.activate()\n",
        "\n",
        "rc.ids \n",
        "\n",
        "dview = rc[:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%px --targets all\n",
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "seeds = [11,12]\n",
        "learning_rates = [0.001, 0.01]\n",
        "\n",
        "dfca_li = []\n",
        "dfca_gi = []\n",
        "ifca = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BbUZJ2E--tqe"
      },
      "outputs": [],
      "source": [
        "seeds = [11,12]\n",
        "learning_rates = [0.001, 0.01]\n",
        "\n",
        "dfca_li = []\n",
        "dfca_gi = []\n",
        "ifca = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ADsUSUi-tqf"
      },
      "source": [
        "Running the dfca-gi experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T_XDv25r-tqf",
        "outputId": "9c8f4300-c792-4e49-be40-c694fa066e6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AsyncResult(%px): pending>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%px --target 0 --noblock\n",
        "import dfca as DFCA\n",
        "import json\n",
        "import time\n",
        "import torch\n",
        "\n",
        "with open(\"config_dfca_gi.json\", \"r\") as read_file:\n",
        "    config = json.load(read_file)\n",
        "\n",
        "for lr in learning_rates:\n",
        "    config['lr'] = lr\n",
        "    res_final = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"---------------------------------DFCA-LI, lr: {lr}, seed: {seed}---------------------------------\")\n",
        "        start_time = time.time()\n",
        "        config['data_seed'] = seed\n",
        "        config['train_seed'] = config['data_seed']\n",
        "\n",
        "        print(\"config:\",config)\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {device}\")\n",
        "\n",
        "        exp = DFCA.TrainMNISTCluster(config, device)\n",
        "        exp.setup()\n",
        "        res = exp.run()\n",
        "        res_final.append([[r['test']['loss'] for r in res], [r['test']['acc'] for r in res], [r['test']['cl_acc'] for r in res]])\n",
        "        del exp\n",
        "        duration = (time.time() - start_time)\n",
        "        print(\"---train cluster Ended in %0.2f hour (%.3f sec) \" % (duration/float(3600), duration))\n",
        "\n",
        "    res_mean = np.mean(res_final, axis=0).tolist()\n",
        "    dfca_gi.append(res_mean)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the dfca-li experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AsyncResult(%px): pending>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%px --target 1 --noblock\n",
        "import dfca as DFCA\n",
        "import json\n",
        "import time\n",
        "import torch\n",
        "\n",
        "with open(\"config_dfca_li.json\", \"r\") as read_file:\n",
        "    config = json.load(read_file)\n",
        "\n",
        "for lr in learning_rates:\n",
        "    config['lr'] = lr\n",
        "    res_final = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"---------------------------------DFCA-LI, lr: {lr}, seed: {seed}---------------------------------\")\n",
        "        start_time = time.time()\n",
        "        config['data_seed'] = seed\n",
        "        config['train_seed'] = config['data_seed']\n",
        "\n",
        "        print(\"config:\",config)\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {device}\")\n",
        "\n",
        "        exp = DFCA.TrainMNISTCluster(config, device)\n",
        "        exp.setup()\n",
        "        res = exp.run()\n",
        "        res_final.append([[r['test']['loss'] for r in res], [r['test']['acc'] for r in res], [r['test']['cl_acc'] for r in res]])\n",
        "        del exp\n",
        "        duration = (time.time() - start_time)\n",
        "        print(\"---train cluster Ended in %0.2f hour (%.3f sec) \" % (duration/float(3600), duration))\n",
        "\n",
        "    res_mean = np.mean(res_final, axis=0).tolist()\n",
        "    dfca_li.append(res_mean)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running the ifca experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AsyncResult(%px): pending>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%px --target 2 --noblock\n",
        "import ifca as IFCA\n",
        "import json\n",
        "import time\n",
        "import torch\n",
        "\n",
        "with open(\"config_ifca.json\", \"r\") as read_file:\n",
        "    config = json.load(read_file)\n",
        "\n",
        "for lr in learning_rates:\n",
        "    config['lr'] = lr\n",
        "    res_final = []\n",
        "\n",
        "    for seed in seeds:\n",
        "        print(f\"---------------------------------IFCA, lr: {lr}, seed: {seed}---------------------------------\")\n",
        "        start_time = time.time()\n",
        "        config['data_seed'] = seed\n",
        "        config['train_seed'] = config['data_seed']\n",
        "\n",
        "        print(\"config:\",config)\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Using device: {device}\")\n",
        "\n",
        "        exp = IFCA.TrainMNISTCluster(config, device)\n",
        "        exp.setup()\n",
        "        res = exp.run()\n",
        "        res_final.append([[r['test']['loss'] for r in res], [r['test']['acc'] for r in res], [r['test']['cl_acc'] for r in res]])\n",
        "        del exp\n",
        "        duration = (time.time() - start_time)\n",
        "        print(\"---train cluster Ended in %0.2f hour (%.3f sec) \" % (duration/float(3600), duration))\n",
        "\n",
        "    res_mean = np.mean(res_final, axis=0).tolist()\n",
        "    ifca.append(res_mean)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Experiment Final Results: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unknown: 100%|██████████| 3/3 [02:53<00:00, 57.69s/tasks]\n"
          ]
        },
        {
          "ename": "RemoteError",
          "evalue": "[2:execute] TypeError: list indices must be integers or slices, not str",
          "output_type": "error",
          "traceback": [
            "[2:execute]",
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 26\u001b[0m",
            "\u001b[0;32m     24\u001b[0m exp\u001b[38;5;241m.\u001b[39msetup()",
            "\u001b[0;32m     25\u001b[0m res \u001b[38;5;241m=\u001b[39m exp\u001b[38;5;241m.\u001b[39mrun()",
            "\u001b[1;32m---> 26\u001b[0m res_final\u001b[38;5;241m.\u001b[39mappend([\u001b[43mres\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m], res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcl_acc\u001b[39m\u001b[38;5;124m'\u001b[39m]])",
            "\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m exp",
            "\u001b[0;32m     28\u001b[0m duration \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)",
            "",
            "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "rc.wait_interactive()\n",
        "%pxresult\n",
        "dfca_gi = rc[0].pull('dfca_gi', block=True)\n",
        "dfca_li = rc[1].pull('dfca_li', block=True)\n",
        "ifca = rc[2].pull('ifca', block=True)\n",
        "\n",
        "os.makedirs('graphs', exist_ok=True)\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot([r['test']['loss'] for r in ifca], label='ifca', color='blue')\n",
        "plt.plot([r['test']['loss'] for r in dfca_li], label='dfca-li', color='red')\n",
        "plt.plot([r['test']['loss'] for r in dfca_gi], label='dfca-gi', color='green')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Test Loss per Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join('graphs', 'train_loss.png'))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot([r['test']['acc'] for r in ifca], label='ifca', color='blue')\n",
        "plt.plot([r['test']['acc'] for r in dfca_li], label='dfca-li', color='red')\n",
        "plt.plot([r['test']['acc'] for r in dfca_gi], label='dfca-gi', color='green')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('test accuracy')\n",
        "plt.title('Test Accuracy per Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join('graphs', 'test_acc.png'))\n",
        "\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.plot([r['test']['cl_acc'] for r in ifca[:3]], label='ifca', color='blue')\n",
        "plt.plot([r['test']['cl_acc'] for r in dfca_li[:3]], label='dfca-li', color='red')\n",
        "plt.plot([r['test']['cl_acc'] for r in dfca_gi[:3]], label='dfca-gi', color='green')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('cluster acc')\n",
        "plt.title('Cluster Accuracy per Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(os.path.join('graphs', 'cluster_acc.png'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deep_learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
