{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "OHJWesKs-tqd"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import itertools\n",
        "import pickle\n",
        "import copy\n",
        "import random\n",
        "import math\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from util import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAghP_o0-tqe"
      },
      "source": [
        "Reads Config file and prepares the arguments you can choose in the config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "BbUZJ2E--tqe"
      },
      "outputs": [],
      "source": [
        "LR_DECAY = False\n",
        "def get_config():\n",
        "\n",
        "    # read config json and update the sysarg\n",
        "    with open(\"config.json\", \"r\") as read_file:\n",
        "        config = json.load(read_file)\n",
        "\n",
        "    if config[\"config_override\"] == \"\":\n",
        "        del config['config_override']\n",
        "    else:\n",
        "        print(config['config_override'])\n",
        "        config_override = json.loads(config['config_override'])\n",
        "        del config['config_override']\n",
        "        config.update(config_override)\n",
        "\n",
        "    return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-J1YEoM-tqe"
      },
      "source": [
        "Class SimpleLinear with simple MLP for MNIST Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "id5Wyt-V-tqf"
      },
      "outputs": [],
      "source": [
        "class SimpleLinear(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, h1=2048):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(28*28, h1)\n",
        "        self.fc2 = torch.nn.Linear(h1, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # x = F.sigmoid(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    # def weight(self):\n",
        "    #     return self.linear1.weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qFBH01M-tqf"
      },
      "source": [
        "Class TrainMNISTCluster with all the methods needed to run the experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkGiGQ2G-tqf"
      },
      "outputs": [],
      "source": [
        "class TrainMNISTCluster(object):\n",
        "    def __init__(self, config, device):\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        assert self.config['m'] % self.config['p'] == 0\n",
        "\n",
        "    def setup(self):\n",
        "\n",
        "        os.makedirs(self.config['project_dir'], exist_ok = True)\n",
        "\n",
        "        self.result_fname = os.path.join(self.config['project_dir'], 'results.pickle')\n",
        "        self.checkpoint_fname = os.path.join(self.config['project_dir'], 'checkpoint.pt')\n",
        "\n",
        "        self.setup_datasets()\n",
        "        self.setup_models()\n",
        "\n",
        "        self.epoch = None\n",
        "        self.lr = None\n",
        "        #self.cluster_switch = None\n",
        "\n",
        "\n",
        "    def setup_datasets(self):\n",
        "\n",
        "        np.random.seed(self.config['data_seed'])\n",
        "\n",
        "        # generate indices for each dataset\n",
        "        # also write cluster info\n",
        "\n",
        "        MNIST_TRAINSET_DATA_SIZE = 60000\n",
        "        MNIST_TESTSET_DATA_SIZE = 10000\n",
        "\n",
        "        np.random.seed(self.config['data_seed'])\n",
        "\n",
        "        cfg = self.config\n",
        "\n",
        "        self.dataset = {}\n",
        "\n",
        "        if cfg['uneven'] == True:\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset_random_n(MNIST_TRAINSET_DATA_SIZE, cfg['p'], cfg['m'], cfg['n'])\n",
        "            (X, y) = self._load_MNIST(train=True)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['train'] = dataset\n",
        "\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset_random_n(MNIST_TESTSET_DATA_SIZE, cfg['p'], cfg['m_test'], cfg['n'], random=True)\n",
        "            (X, y) = self._load_MNIST(train=False)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['test'] = dataset\n",
        "\n",
        "        else:\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset(MNIST_TRAINSET_DATA_SIZE, cfg['p'], cfg['m'], cfg['n'])\n",
        "            (X, y) = self._load_MNIST(train=True)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['train'] = dataset\n",
        "\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset(MNIST_TESTSET_DATA_SIZE, cfg['p'], cfg['m_test'], cfg['n'], random=True)\n",
        "            (X, y) = self._load_MNIST(train=False)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['test'] = dataset\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "\n",
        "    def _setup_dataset_random_n(self, num_data, p, m, n, random = True):\n",
        "\n",
        "        print(\"m:\",m)\n",
        "        print(\"p:\",p)\n",
        "        print(\"num_data:\",num_data)\n",
        "\n",
        "        dataset = {}\n",
        "\n",
        "        cfg = self.config\n",
        "\n",
        "        data_indices = []\n",
        "        cluster_assign = []\n",
        "\n",
        "        m_per_cluster = m // p\n",
        "\n",
        "        for p_i in range(p):\n",
        "\n",
        "            ll = list(np.random.permutation(num_data))\n",
        "\n",
        "            ll2 = chunkify_uneven(ll, m_per_cluster) # splits ll into m lists\n",
        "            data_indices += ll2\n",
        "\n",
        "            cluster_assign += [p_i for _ in range(m_per_cluster)]\n",
        "\n",
        "        data_indices = np.array(data_indices, dtype=object)\n",
        "        cluster_assign = np.array(cluster_assign)\n",
        "        assert data_indices.shape[0] == cluster_assign.shape[0]\n",
        "        assert data_indices.shape[0] == m\n",
        "\n",
        "\n",
        "        return data_indices, cluster_assign\n",
        "\n",
        "\n",
        "    def _load_MNIST(self, train=True):\n",
        "        transforms = torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               # torchvision.transforms.Normalize(\n",
        "                               #   (0.1307,), (0.3081,))\n",
        "                             ])\n",
        "        if train:\n",
        "            mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms)\n",
        "        else:\n",
        "            mnist_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms)\n",
        "\n",
        "        dl = DataLoader(mnist_dataset)\n",
        "\n",
        "        X = dl.dataset.data # (60000,28, 28)\n",
        "        y = dl.dataset.targets #(60000)\n",
        "\n",
        "        # normalize to have 0 ~ 1 range in each pixel\n",
        "\n",
        "        X = X / 255.0\n",
        "        X = X.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "    # Need p models for each client\n",
        "\n",
        "    def setup_models(self):\n",
        "        np.random.seed(self.config['train_seed'])\n",
        "        torch.manual_seed(self.config['train_seed'])\n",
        "\n",
        "        p = self.config['p']\n",
        "        m = self.config['m']\n",
        "\n",
        "        self.models = [[SimpleLinear(h1 = self.config['h1']).to(self.device) for p_i in range(p)] for m_i in range(m)] # p models with p different params of dimension(1,d) for each client m_i\n",
        "\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        num_epochs = self.config['num_epochs']\n",
        "        lr = self.config['lr']\n",
        "\n",
        "        #self.cluster_switch = [[0 for _ in range(self.config['p'])] for m_i in range(self.config['m'])] \n",
        "\n",
        "        results = []\n",
        "\n",
        "        # epoch -1\n",
        "        self.epoch = -1\n",
        "\n",
        "        result = {}\n",
        "        result['epoch'] = -1\n",
        "\n",
        "        t0 = time.time()\n",
        "        res = self.test(train=True)\n",
        "        t1 = time.time()\n",
        "        res['infer_time'] = t1-t0\n",
        "        result['train'] = res\n",
        "\n",
        "        self.print_epoch_stats(res)\n",
        "\n",
        "        t0 = time.time()\n",
        "        res = self.test(train=False)\n",
        "        t1 = time.time()\n",
        "        res['infer_time'] = t1-t0\n",
        "        result['test'] = res\n",
        "        self.print_epoch_stats(res)\n",
        "        results.append(result)\n",
        "\n",
        "        # this will be used in next epoch\n",
        "        cluster_assign = result['train']['cluster_assign']\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.epoch = epoch\n",
        "\n",
        "            result = {}\n",
        "            result['epoch'] = epoch\n",
        "\n",
        "            lr = self.lr_schedule(epoch)\n",
        "            result['lr'] = lr\n",
        "\n",
        "            t0 = time.time()\n",
        "            result['train'] = self.train(cluster_assign, lr = lr)\n",
        "            t1 = time.time()\n",
        "            train_time = t1-t0\n",
        "\n",
        "            t0 = time.time()\n",
        "            res = self.test(train=True)\n",
        "            t1 = time.time()\n",
        "            res['infer_time'] = t1-t0\n",
        "            res['train_time'] = train_time\n",
        "            res['lr'] = lr\n",
        "            result['train'] = res\n",
        "\n",
        "            self.print_epoch_stats(res)\n",
        "\n",
        "            t0 = time.time()\n",
        "            res = self.test(train=False)\n",
        "            t1 = time.time()\n",
        "            res['infer_time'] = t1-t0\n",
        "            result['test'] = res\n",
        "            self.print_epoch_stats(res)\n",
        "\n",
        "            results.append(result)\n",
        "\n",
        "            # this will be used in next epoch's gradient update\n",
        "            cluster_assign = result['train']['cluster_assign']\n",
        "\n",
        "            if epoch % 10 == 0 or epoch == num_epochs - 1 :\n",
        "                with open(self.result_fname, 'wb') as outfile:\n",
        "                    pickle.dump(results, outfile)\n",
        "                    print(f'result written at {self.result_fname}')\n",
        "#                self.save_checkpoint()\n",
        "                print(f'checkpoint written at {self.checkpoint_fname}')\n",
        "            \n",
        "            if epoch % 10 == 0:\n",
        "                self.test_all(train=False)\n",
        "\n",
        "\n",
        "\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.plot([r['train']['loss'] for r in results], label='train')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('loss')\n",
        "        plt.title('Training Loss per Epoch')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(self.config['project_dir'], 'train_loss.png'))\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.plot([r['test']['acc'] for r in results], label='train')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('test accuracy')\n",
        "        plt.title('Test Accuracy per Epoch')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(self.config['project_dir'], 'test_acc.png'))\n",
        "\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.plot([r['train']['cl_acc'] for r in results], label='train')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('cluster acc')\n",
        "        plt.title('Cluster Accuracy per Epoch')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(self.config['project_dir'], 'cluster_acc.png'))\n",
        "\n",
        "\n",
        "\n",
        "    def lr_schedule(self, epoch):\n",
        "        if self.lr is None:\n",
        "            self.lr = self.config['lr']\n",
        "\n",
        "        if epoch % 50 == 0 and epoch != 0 and LR_DECAY:\n",
        "            self.lr = self.lr * 0.1\n",
        "\n",
        "        return self.lr        \n",
        "\n",
        "\n",
        "    def print_epoch_stats(self, res):\n",
        "        if res['is_train']:\n",
        "            data_str = 'tr'\n",
        "        else:\n",
        "            data_str = 'tst'\n",
        "\n",
        "        if 'train_time' in res:\n",
        "            time_str = f\"{res['train_time']:.3f}sec(train) {res['infer_time']:.3f}sec(infer)\"\n",
        "        else:\n",
        "            time_str = f\"{res['infer_time']:.3f}sec\"\n",
        "\n",
        "        if 'lr' in res:\n",
        "            lr_str = f\" lr {res['lr']:4f}\"\n",
        "        else:\n",
        "            lr_str = \"\"\n",
        "\n",
        "        str0 = f\"Epoch {self.epoch} {data_str}: l {res['loss']:.3f} a {res['acc']:.3f} clct{res['cl_ct']} cl_acc {res['cl_acc']:.3f} {lr_str} {time_str}\"\n",
        "\n",
        "        print(str0)\n",
        "\n",
        "    def train(self, cluster_assign, lr):\n",
        "        VERBOSE = 0\n",
        "\n",
        "        cfg = self.config\n",
        "        m = cfg['m']\n",
        "        p = cfg['p']\n",
        "        tau = cfg['tau']\n",
        "\n",
        "        # run local update\n",
        "        t0 = time.time()\n",
        "\n",
        "\n",
        "        for m_i in range(m):\n",
        "            if VERBOSE and m_i % 100 == 0: print(f'm {m_i}/{m} processing \\r', end ='')\n",
        "\n",
        "            (X, y) = self.load_data(m_i)\n",
        "\n",
        "            p_i = cluster_assign[m_i]\n",
        "            model = self.models[m_i][p_i]\n",
        "\n",
        "            # LOCAL UPDATE PER MACHINE tau times\n",
        "            for step_i in range(tau):\n",
        "\n",
        "                y_logit = model(X)\n",
        "                loss = self.criterion(y_logit, y)\n",
        "\n",
        "                model.zero_grad()\n",
        "                loss.backward()\n",
        "                self.local_param_update(model, lr)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "\n",
        "        t02 = time.time()\n",
        "        # print(f'running single ..took {t02-t01:.3f}sec')\n",
        "\n",
        "\n",
        "        t1 = time.time()\n",
        "        if VERBOSE: print(f'local update {t1-t0:.3f}sec')\n",
        "\n",
        "        # apply gradient update\n",
        "        t0 = time.time()\n",
        "\n",
        "        # NEEDS TO BE DECENTRALIZED\n",
        "        self.dec_param_update(cluster_assign)\n",
        "        t1 = time.time()\n",
        "\n",
        "        if VERBOSE: print(f'global update {t1-t0:.3f}sec')\n",
        "\n",
        "    def check_local_model_loss(self, local_models):\n",
        "        # for debugging\n",
        "        m = self.config['m']\n",
        "\n",
        "        losses = []\n",
        "        for m_i in range(m):\n",
        "            (X, y) = self.load_data(m_i)\n",
        "            y_logit = local_models[m_i](X)\n",
        "            loss = self.criterion(y_logit, y)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        return np.array(losses)\n",
        "    \n",
        "    def get_cluster_accuracy(self, actual, pred):\n",
        "        \n",
        "        cm = confusion_matrix(actual, pred)\n",
        "\n",
        "        row_ind, col_ind = linear_sum_assignment(-cm)\n",
        "        matching = dict(zip(col_ind, row_ind))\n",
        "\n",
        "        remapped_preds = [matching[p] for p in pred]\n",
        "\n",
        "        cl_acc = np.mean(np.array(remapped_preds) == np.array(actual))\n",
        "\n",
        "        return cl_acc\n",
        "\n",
        "\n",
        "    def get_inference_stats(self, train = True):\n",
        "        cfg = self.config\n",
        "        if train:\n",
        "            m = cfg['m']\n",
        "            dataset = self.dataset['train']\n",
        "        else:\n",
        "            m = cfg['m_test']\n",
        "            dataset = self.dataset['test']\n",
        "\n",
        "        p = cfg['p']\n",
        "\n",
        "\n",
        "        num_data = 0\n",
        "        losses = {}\n",
        "        corrects = {}\n",
        "        for m_i in range(m):\n",
        "            (X, y) = self.load_data(m_i, train=train) # load batch data rotated\n",
        "\n",
        "            for p_i in range(p):\n",
        "                y_logit = self.models[m_i][p_i](X)\n",
        "                loss = self.criterion(y_logit, y) # loss of\n",
        "                n_correct = self.n_correct(y_logit, y)\n",
        "\n",
        "                # if torch.isnan(loss):\n",
        "                #     print(\"nan loss: \", dataset['data_indices'][m_i])\n",
        "\n",
        "                losses[(m_i,p_i)] = loss.item()\n",
        "                corrects[(m_i,p_i)] = n_correct\n",
        "\n",
        "            num_data += X.shape[0]\n",
        "\n",
        "        # calculate loss and cluster the machines\n",
        "        cluster_assign = []\n",
        "        for m_i in range(m):\n",
        "            machine_losses = [ losses[(m_i,p_i)] for p_i in range(p) ]\n",
        "            #print(\"Machine Losses:\", machine_losses)\n",
        "            min_p_i = np.argmin(machine_losses)\n",
        "            cluster_assign.append(min_p_i)\n",
        "\n",
        "        # calculate optimal model's loss, acc over all models\n",
        "        min_corrects = []\n",
        "        min_losses = []\n",
        "        for m_i, p_i in enumerate(cluster_assign):\n",
        "\n",
        "            min_loss = losses[(m_i,p_i)]\n",
        "            min_losses.append(min_loss)\n",
        "\n",
        "            min_correct = corrects[(m_i,p_i)]\n",
        "            min_corrects.append(min_correct)\n",
        "\n",
        "        # print(\"losses: \", min_losses)\n",
        "\n",
        "        if train:\n",
        "            loss = np.mean(min_losses)\n",
        "            acc = np.sum(min_corrects) / num_data\n",
        "\n",
        "        else:\n",
        "            loss, acc = self.test_all()\n",
        "\n",
        "\n",
        "        # check cluster assignment acc\n",
        "        cl_acc = self.get_cluster_accuracy(dataset['cluster_assign'], cluster_assign)\n",
        "        cl_ct = [np.sum(np.array(cluster_assign) == p_i ) for p_i in range(p)]\n",
        "\n",
        "        # improved cluster assignment acc (model 2 can work better on clients with p=3)\n",
        "        \n",
        "\n",
        "        res = {} # results\n",
        "        # res['losses'] = losses\n",
        "        # res['corrects'] = corrects\n",
        "        res['cluster_assign'] = cluster_assign\n",
        "        res['num_data'] = num_data\n",
        "        res['loss'] = loss\n",
        "        res['acc'] = acc\n",
        "        res['cl_acc'] = cl_acc\n",
        "        res['cl_ct'] = cl_ct\n",
        "        res['is_train'] = train\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "        return res\n",
        "\n",
        "    def n_correct(self, y_logit, y):\n",
        "        _, predicted = torch.max(y_logit.data, 1)\n",
        "        correct = (predicted == y).sum().item()\n",
        "\n",
        "        return correct\n",
        "\n",
        "    # TODO Does every Cluster get 4 clients with the same data, but rotated differently?\n",
        "\n",
        "    def load_data(self, m_i, train=True):\n",
        "        # this part is very fast since its just rearranging models\n",
        "        cfg = self.config\n",
        "\n",
        "        if train:\n",
        "            dataset = self.dataset['train']\n",
        "        else:\n",
        "            dataset = self.dataset['test']\n",
        "\n",
        "        indices = dataset['data_indices'][m_i]\n",
        "        p_i = dataset['cluster_assign'][m_i]\n",
        "\n",
        "        X_batch = dataset['X'][indices]\n",
        "        y_batch = dataset['y'][indices]\n",
        "\n",
        "        # k : how many times rotate 90 degree\n",
        "        # k =1 : 90 , k=2 180, k=3 270\n",
        "\n",
        "        if cfg['p'] == 4:\n",
        "            k = p_i\n",
        "        elif cfg['p'] == 2:\n",
        "            k = (p_i % 2) * 2\n",
        "        elif cfg['p'] == 1:\n",
        "            k = 0\n",
        "        else:\n",
        "            raise NotImplementedError(\"only p=1,2,4 supported\")\n",
        "\n",
        "        X_batch2 = torch.rot90(X_batch, k=int(k), dims = (1,2))\n",
        "        X_batch3 = X_batch2.reshape(-1, 28 * 28)\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "        return X_batch3, y_batch\n",
        "\n",
        "\n",
        "    def local_param_update(self, model, lr):\n",
        "\n",
        "        # gradient update manually\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                param.data -= lr * param.grad\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        # import ipdb; ipdb.set_trace() # we need to check the output of name, check if duplicate exists\n",
        "\n",
        "\n",
        "    def dec_param_update(self, cluster_assign):\n",
        "\n",
        "        num_clients = self.config['m']\n",
        "\n",
        "        if num_clients <= 4:\n",
        "            return\n",
        "\n",
        "        max_e = 100\n",
        "        if num_clients <= max_e:\n",
        "            e = num_clients - 1\n",
        "        else:\n",
        "            e = min(max_e, int(np.log(num_clients) * 20))\n",
        "\n",
        "        if e >= num_clients:\n",
        "            e = num_clients - 1\n",
        "\n",
        "        client_indices = list(range(num_clients)) \n",
        "\n",
        "        for m_i in range(num_clients):\n",
        "\n",
        "            counts = {i: 0 for i in range(self.config['p'])}\n",
        "            for value in cluster_assign:\n",
        "                counts[value] += 1\n",
        "\n",
        "            num_cluster_i = counts[cluster_assign[m_i]]\n",
        "            num_cluster_rest = num_clients - num_cluster_i\n",
        "\n",
        "            threshold_j = min(num_cluster_rest, 100)\n",
        "            threshold_i = min(num_cluster_i, 100)\n",
        "\n",
        "            # threshold_j = min(num_cluster_rest, int(np.floor(e/2)))\n",
        "            # threshold_i = min(num_cluster_i, int(np.floor(e/2))) - 1\n",
        "\n",
        "            selected_clients = random.sample([i for i in client_indices if i != m_i], torch.randint(1, min(threshold_i,threshold_j), (1,)))\n",
        "            # selected_clients += random.sample([i for i in client_indices if i != m_i and cluster_assign[m_i] == cluster_assign[i]], threshold_i)\n",
        "            m_i_cluster = cluster_assign[m_i]\n",
        "            for m_j in selected_clients:\n",
        "                m_j_cluster = cluster_assign[m_j]\n",
        "\n",
        "                m_j_params = dict(self.models[m_j][m_j_cluster].named_parameters())\n",
        "\n",
        "                if m_i_cluster == m_j_cluster:\n",
        "                    for name, param in self.models[m_i][m_i_cluster].named_parameters():\n",
        "                        m_i_param = param.data.clone()\n",
        "                        m_j_param = m_j_params[name].data.clone()\n",
        "                        alpha = 0.5\n",
        "                        param.data = (m_i_param + m_j_param) / 2     \n",
        "\n",
        "                else:\n",
        "                    for name, param in self.models[m_i][m_j_cluster].named_parameters():\n",
        "                        m_i_param = param.data.clone()\n",
        "                        m_j_param = m_j_params[name].data.clone()\n",
        "                        alpha = 0.4\n",
        "                        param.data = alpha * m_i_param + (1 - alpha) * m_j_param\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "\n",
        "    def test(self, train=False):\n",
        "        return self.get_inference_stats(train=train)\n",
        "\n",
        "    def load_test_data(self, m_i, train=False):\n",
        "        cfg = self.config\n",
        "\n",
        "        p = cfg['p']\n",
        "\n",
        "        if train:\n",
        "            dataset = self.dataset['train']\n",
        "        else:\n",
        "            dataset = self.dataset['test']\n",
        "\n",
        "        indices = dataset['data_indices'][m_i]\n",
        "        p_i = dataset['cluster_assign'][m_i]\n",
        "\n",
        "        X_batch = dataset['X'][indices]\n",
        "        y_batch = dataset['y'][indices]\n",
        "\n",
        "        data = []\n",
        "\n",
        "        for p_j in range(p):\n",
        "            X_batch2 = torch.rot90(X_batch, k=int(p_j), dims = (1,2))\n",
        "            X_batch3 = X_batch2.reshape(-1, 28 * 28)\n",
        "            data.append(X_batch3)\n",
        "\n",
        "        return data, y_batch\n",
        "\n",
        "    def test_all(self, train=False):\n",
        "        cfg = self.config\n",
        "        m = cfg['m_test']\n",
        "        dataset = self.dataset['test']\n",
        "\n",
        "        p = cfg['p']\n",
        "\n",
        "        num_data = 0\n",
        "        losses = []\n",
        "        corrects = []\n",
        "        for m_i in range(m):\n",
        "            \n",
        "            (data, y) = self.load_test_data(m_i, train=train)\n",
        "\n",
        "            for p_i in range(p):\n",
        "                X = data[p_i]\n",
        "                loss_m_i = []\n",
        "                correct_m_i = []\n",
        "                for model in range(p):\n",
        "                    y_logit = self.models[m_i][model](X)\n",
        "                    loss_m_i.append(self.criterion(y_logit, y))\n",
        "                    correct_m_i.append(self.n_correct(y_logit, y))\n",
        "\n",
        "                loss = np.min([l.item() for l in loss_m_i])\n",
        "                n_correct = np.max(correct_m_i)\n",
        "\n",
        "                # if torch.isnan(loss):\n",
        "                #     print(\"nan loss: \", dataset['data_indices'][m_i])\n",
        "\n",
        "                losses.append(loss)\n",
        "                corrects.append(n_correct)\n",
        "\n",
        "                num_data += X.shape[0]\n",
        "\n",
        "        loss = np.mean(losses)\n",
        "        acc = np.sum(corrects) / num_data\n",
        "\n",
        "        # print(f\"Average loss over all clients and models: {loss:.3f}\")\n",
        "        # print(f\"Average accuracy over all clients and models: {acc:.3f}\")    \n",
        "\n",
        "        return loss, acc\n",
        "\n",
        "\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        models_to_save = [model.state_dict() for model in self.models]\n",
        "        torch.save({'models':models_to_save}, self.checkpoint_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ADsUSUi-tqf"
      },
      "source": [
        "Running the Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T_XDv25r-tqf",
        "outputId": "9c8f4300-c792-4e49-be40-c694fa066e6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config: {'m': 1200, 'm_test': 200, 'p': 4, 'n': 200, 'uneven': True, 'h1': 200, 'num_epochs': 300, 'batch_size': 100, 'tau': 10, 'lr': 0.1, 'data_seed': 10, 'train_seed': 10, 'project_dir': 'output'}\n",
            "Using device: cuda\n",
            "m: 1200\n",
            "p: 4\n",
            "num_data: 60000\n",
            "len:  60000\n",
            "len:  60000\n",
            "len:  60000\n",
            "len:  60000\n",
            "m: 200\n",
            "p: 4\n",
            "num_data: 10000\n",
            "len:  10000\n",
            "len:  10000\n",
            "len:  10000\n",
            "len:  10000\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch -1 tr: l 2.295 a 0.117 clct[324, 294, 290, 292] cl_acc 0.279  1.315sec\n",
            "Epoch -1 tst: l 2.294 a 0.119 clct[54, 46, 47, 53] cl_acc 0.335  0.220sec\n",
            "Epoch 0 tr: l 2.251 a 0.283 clct[272, 339, 276, 313] cl_acc 0.276  lr 0.100000 17.076sec(train) 1.302sec(infer)\n",
            "Epoch 0 tst: l 2.244 a 0.292 clct[50, 44, 40, 66] cl_acc 0.305  0.219sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 2.244\n",
            "Average accuracy over all clients and models: 0.303\n",
            "Epoch 1 tr: l 2.252 a 0.256 clct[263, 326, 281, 330] cl_acc 0.297  lr 0.100000 16.331sec(train) 1.298sec(infer)\n",
            "Epoch 1 tst: l 2.242 a 0.268 clct[48, 49, 46, 57] cl_acc 0.295  0.218sec\n",
            "Epoch 2 tr: l 2.257 a 0.212 clct[283, 318, 278, 321] cl_acc 0.308  lr 0.100000 16.398sec(train) 1.282sec(infer)\n",
            "Epoch 2 tst: l 2.245 a 0.235 clct[37, 49, 58, 56] cl_acc 0.345  0.218sec\n",
            "Epoch 3 tr: l 2.246 a 0.179 clct[282, 329, 236, 353] cl_acc 0.324  lr 0.100000 16.295sec(train) 1.301sec(infer)\n",
            "Epoch 3 tst: l 2.246 a 0.196 clct[51, 50, 46, 53] cl_acc 0.310  0.219sec\n",
            "Epoch 4 tr: l 2.230 a 0.175 clct[245, 347, 281, 327] cl_acc 0.388  lr 0.100000 16.065sec(train) 1.290sec(infer)\n",
            "Epoch 4 tst: l 2.229 a 0.189 clct[43, 54, 52, 51] cl_acc 0.405  0.216sec\n",
            "Epoch 5 tr: l 2.190 a 0.219 clct[186, 376, 311, 327] cl_acc 0.464  lr 0.100000 16.733sec(train) 1.309sec(infer)\n",
            "Epoch 5 tst: l 2.193 a 0.221 clct[32, 61, 61, 46] cl_acc 0.435  0.220sec\n",
            "Epoch 6 tr: l 2.119 a 0.305 clct[170, 343, 333, 354] cl_acc 0.553  lr 0.100000 16.681sec(train) 1.311sec(infer)\n",
            "Epoch 6 tst: l 2.130 a 0.290 clct[27, 60, 53, 60] cl_acc 0.545  0.219sec\n",
            "Epoch 7 tr: l 2.009 a 0.394 clct[275, 316, 296, 313] cl_acc 0.652  lr 0.100000 16.129sec(train) 1.320sec(infer)\n",
            "Epoch 7 tst: l 2.025 a 0.382 clct[40, 53, 58, 49] cl_acc 0.570  0.218sec\n",
            "Epoch 8 tr: l 1.865 a 0.465 clct[344, 304, 299, 253] cl_acc 0.797  lr 0.100000 16.105sec(train) 1.309sec(infer)\n",
            "Epoch 8 tst: l 1.880 a 0.446 clct[53, 50, 52, 45] cl_acc 0.730  0.219sec\n",
            "Epoch 9 tr: l 1.684 a 0.517 clct[313, 301, 290, 296] cl_acc 0.931  lr 0.100000 16.293sec(train) 1.313sec(infer)\n",
            "Epoch 9 tst: l 1.700 a 0.497 clct[55, 49, 55, 41] cl_acc 0.890  0.220sec\n",
            "Epoch 10 tr: l 1.502 a 0.565 clct[306, 300, 298, 296] cl_acc 0.986  lr 0.100000 16.486sec(train) 1.301sec(infer)\n",
            "Epoch 10 tst: l 1.520 a 0.555 clct[52, 50, 51, 47] cl_acc 0.975  0.218sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 1.520\n",
            "Average accuracy over all clients and models: 0.549\n",
            "Epoch 11 tr: l 1.332 a 0.616 clct[303, 300, 298, 299] cl_acc 0.995  lr 0.100000 16.068sec(train) 1.293sec(infer)\n",
            "Epoch 11 tst: l 1.362 a 0.591 clct[50, 50, 49, 51] cl_acc 0.995  0.218sec\n",
            "Epoch 12 tr: l 1.189 a 0.660 clct[300, 300, 299, 301] cl_acc 0.998  lr 0.100000 16.005sec(train) 1.296sec(infer)\n",
            "Epoch 12 tst: l 1.214 a 0.648 clct[50, 50, 51, 49] cl_acc 0.995  0.217sec\n",
            "Epoch 13 tr: l 1.072 a 0.700 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.102sec(train) 1.296sec(infer)\n",
            "Epoch 13 tst: l 1.096 a 0.685 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "Epoch 14 tr: l 0.972 a 0.731 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.316sec(train) 1.301sec(infer)\n",
            "Epoch 14 tst: l 0.985 a 0.719 clct[50, 50, 50, 50] cl_acc 1.000  0.233sec\n",
            "Epoch 15 tr: l 0.886 a 0.755 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.620sec(train) 1.294sec(infer)\n",
            "Epoch 15 tst: l 0.916 a 0.738 clct[50, 50, 50, 50] cl_acc 1.000  0.217sec\n",
            "Epoch 16 tr: l 0.814 a 0.774 clct[301, 300, 299, 300] cl_acc 0.999  lr 0.100000 15.733sec(train) 1.291sec(infer)\n",
            "Epoch 16 tst: l 0.835 a 0.766 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 17 tr: l 0.755 a 0.789 clct[301, 300, 299, 300] cl_acc 0.999  lr 0.100000 15.804sec(train) 1.293sec(infer)\n",
            "Epoch 17 tst: l 0.774 a 0.783 clct[50, 50, 50, 50] cl_acc 1.000  0.217sec\n",
            "Epoch 18 tr: l 0.711 a 0.801 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.184sec(train) 1.301sec(infer)\n",
            "Epoch 18 tst: l 0.731 a 0.793 clct[50, 50, 50, 50] cl_acc 1.000  0.219sec\n",
            "Epoch 19 tr: l 0.668 a 0.811 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.142sec(train) 1.299sec(infer)\n",
            "Epoch 19 tst: l 0.694 a 0.802 clct[50, 50, 50, 50] cl_acc 1.000  0.217sec\n",
            "Epoch 20 tr: l 0.633 a 0.821 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.917sec(train) 1.302sec(infer)\n",
            "Epoch 20 tst: l 0.657 a 0.811 clct[50, 50, 50, 50] cl_acc 1.000  0.219sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.651\n",
            "Average accuracy over all clients and models: 0.815\n",
            "Epoch 21 tr: l 0.606 a 0.828 clct[301, 300, 299, 300] cl_acc 0.999  lr 0.100000 15.980sec(train) 1.300sec(infer)\n",
            "Epoch 21 tst: l 0.623 a 0.825 clct[50, 50, 50, 50] cl_acc 1.000  0.219sec\n",
            "Epoch 22 tr: l 0.584 a 0.834 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.327sec(train) 1.304sec(infer)\n",
            "Epoch 22 tst: l 0.590 a 0.836 clct[50, 50, 50, 50] cl_acc 1.000  0.219sec\n",
            "Epoch 23 tr: l 0.559 a 0.840 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.859sec(train) 1.297sec(infer)\n",
            "Epoch 23 tst: l 0.577 a 0.838 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 24 tr: l 0.540 a 0.847 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.737sec(train) 1.301sec(infer)\n",
            "Epoch 24 tst: l 0.556 a 0.841 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 25 tr: l 0.522 a 0.851 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.650sec(train) 1.295sec(infer)\n",
            "Epoch 25 tst: l 0.536 a 0.850 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 26 tr: l 0.505 a 0.856 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.921sec(train) 1.307sec(infer)\n",
            "Epoch 26 tst: l 0.523 a 0.853 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "Epoch 27 tr: l 0.490 a 0.861 clct[301, 300, 299, 300] cl_acc 0.999  lr 0.100000 16.881sec(train) 1.306sec(infer)\n",
            "Epoch 27 tst: l 0.511 a 0.857 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 28 tr: l 0.478 a 0.864 clct[301, 300, 299, 300] cl_acc 0.999  lr 0.100000 17.024sec(train) 1.300sec(infer)\n",
            "Epoch 28 tst: l 0.494 a 0.863 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 29 tr: l 0.470 a 0.867 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.223sec(train) 1.293sec(infer)\n",
            "Epoch 29 tst: l 0.479 a 0.866 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 30 tr: l 0.460 a 0.870 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.794sec(train) 1.298sec(infer)\n",
            "Epoch 30 tst: l 0.475 a 0.869 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.473\n",
            "Average accuracy over all clients and models: 0.869\n",
            "Epoch 31 tr: l 0.448 a 0.872 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.370sec(train) 1.306sec(infer)\n",
            "Epoch 31 tst: l 0.463 a 0.872 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "Epoch 32 tr: l 0.440 a 0.874 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.995sec(train) 1.308sec(infer)\n",
            "Epoch 32 tst: l 0.451 a 0.876 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "Epoch 33 tr: l 0.432 a 0.876 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.303sec(train) 1.295sec(infer)\n",
            "Epoch 33 tst: l 0.442 a 0.877 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 34 tr: l 0.423 a 0.879 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.053sec(train) 1.291sec(infer)\n",
            "Epoch 34 tst: l 0.436 a 0.878 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "Epoch 35 tr: l 0.419 a 0.880 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.552sec(train) 1.295sec(infer)\n",
            "Epoch 35 tst: l 0.428 a 0.881 clct[50, 50, 50, 50] cl_acc 1.000  0.217sec\n",
            "Epoch 36 tr: l 0.410 a 0.882 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.936sec(train) 1.295sec(infer)\n",
            "Epoch 36 tst: l 0.426 a 0.880 clct[50, 50, 50, 50] cl_acc 1.000  0.217sec\n",
            "Epoch 37 tr: l 0.405 a 0.883 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.106sec(train) 1.295sec(infer)\n",
            "Epoch 37 tst: l 0.423 a 0.883 clct[50, 50, 50, 50] cl_acc 1.000  0.219sec\n",
            "Epoch 38 tr: l 0.400 a 0.884 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.941sec(train) 1.305sec(infer)\n",
            "Epoch 38 tst: l 0.413 a 0.885 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "Epoch 39 tr: l 0.391 a 0.886 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.991sec(train) 1.296sec(infer)\n",
            "Epoch 39 tst: l 0.408 a 0.886 clct[50, 50, 50, 50] cl_acc 1.000  0.217sec\n",
            "Epoch 40 tr: l 0.390 a 0.887 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.894sec(train) 1.288sec(infer)\n",
            "Epoch 40 tst: l 0.406 a 0.886 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.402\n",
            "Average accuracy over all clients and models: 0.887\n",
            "Epoch 41 tr: l 0.388 a 0.887 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.090sec(train) 1.287sec(infer)\n",
            "Epoch 41 tst: l 0.399 a 0.888 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "Epoch 42 tr: l 0.378 a 0.889 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.438sec(train) 1.325sec(infer)\n",
            "Epoch 42 tst: l 0.396 a 0.888 clct[50, 50, 50, 50] cl_acc 1.000  0.223sec\n",
            "Epoch 43 tr: l 0.377 a 0.890 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.300sec(train) 1.339sec(infer)\n",
            "Epoch 43 tst: l 0.389 a 0.890 clct[50, 50, 50, 50] cl_acc 1.000  0.228sec\n",
            "Epoch 44 tr: l 0.374 a 0.890 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.899sec(train) 1.323sec(infer)\n",
            "Epoch 44 tst: l 0.384 a 0.892 clct[50, 50, 50, 50] cl_acc 1.000  0.223sec\n",
            "Epoch 45 tr: l 0.370 a 0.892 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.420sec(train) 1.332sec(infer)\n",
            "Epoch 45 tst: l 0.384 a 0.892 clct[50, 50, 50, 50] cl_acc 1.000  0.221sec\n",
            "Epoch 46 tr: l 0.368 a 0.893 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.516sec(train) 1.308sec(infer)\n",
            "Epoch 46 tst: l 0.377 a 0.892 clct[50, 50, 50, 50] cl_acc 1.000  0.217sec\n",
            "Epoch 47 tr: l 0.363 a 0.893 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.421sec(train) 1.326sec(infer)\n",
            "Epoch 47 tst: l 0.376 a 0.896 clct[50, 50, 50, 50] cl_acc 1.000  0.222sec\n",
            "Epoch 48 tr: l 0.361 a 0.894 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.620sec(train) 1.302sec(infer)\n",
            "Epoch 48 tst: l 0.372 a 0.894 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "Epoch 49 tr: l 0.358 a 0.896 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.748sec(train) 1.319sec(infer)\n",
            "Epoch 49 tst: l 0.372 a 0.895 clct[50, 50, 50, 50] cl_acc 1.000  0.223sec\n",
            "Epoch 50 tr: l 0.354 a 0.896 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.836sec(train) 1.311sec(infer)\n",
            "Epoch 50 tst: l 0.370 a 0.895 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.366\n",
            "Average accuracy over all clients and models: 0.896\n",
            "Epoch 51 tr: l 0.354 a 0.896 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.305sec(train) 1.307sec(infer)\n",
            "Epoch 51 tst: l 0.367 a 0.895 clct[50, 50, 50, 50] cl_acc 1.000  0.223sec\n",
            "Epoch 52 tr: l 0.350 a 0.897 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.214sec(train) 1.320sec(infer)\n",
            "Epoch 52 tst: l 0.363 a 0.897 clct[50, 50, 50, 50] cl_acc 1.000  0.221sec\n",
            "Epoch 53 tr: l 0.346 a 0.898 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.144sec(train) 1.306sec(infer)\n",
            "Epoch 53 tst: l 0.361 a 0.897 clct[50, 50, 50, 50] cl_acc 1.000  0.219sec\n",
            "Epoch 54 tr: l 0.346 a 0.898 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.140sec(train) 1.318sec(infer)\n",
            "Epoch 54 tst: l 0.357 a 0.899 clct[50, 50, 50, 50] cl_acc 1.000  0.221sec\n",
            "Epoch 55 tr: l 0.343 a 0.899 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.328sec(train) 1.305sec(infer)\n",
            "Epoch 55 tst: l 0.360 a 0.899 clct[50, 50, 50, 50] cl_acc 1.000  0.219sec\n",
            "Epoch 56 tr: l 0.340 a 0.899 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.026sec(train) 1.293sec(infer)\n",
            "Epoch 56 tst: l 0.359 a 0.899 clct[50, 50, 50, 50] cl_acc 1.000  0.217sec\n",
            "Epoch 57 tr: l 0.339 a 0.900 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.176sec(train) 1.297sec(infer)\n",
            "Epoch 57 tst: l 0.358 a 0.900 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 58 tr: l 0.336 a 0.900 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.080sec(train) 1.309sec(infer)\n",
            "Epoch 58 tst: l 0.350 a 0.901 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 59 tr: l 0.332 a 0.901 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.181sec(train) 1.357sec(infer)\n",
            "Epoch 59 tst: l 0.350 a 0.900 clct[50, 50, 50, 50] cl_acc 1.000  0.225sec\n",
            "Epoch 60 tr: l 0.334 a 0.902 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.428sec(train) 1.299sec(infer)\n",
            "Epoch 60 tst: l 0.352 a 0.902 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.346\n",
            "Average accuracy over all clients and models: 0.902\n",
            "Epoch 61 tr: l 0.331 a 0.902 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.951sec(train) 1.287sec(infer)\n",
            "Epoch 61 tst: l 0.347 a 0.902 clct[50, 50, 50, 50] cl_acc 1.000  0.219sec\n",
            "Epoch 62 tr: l 0.328 a 0.903 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.033sec(train) 1.297sec(infer)\n",
            "Epoch 62 tst: l 0.347 a 0.903 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 63 tr: l 0.326 a 0.903 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.701sec(train) 1.297sec(infer)\n",
            "Epoch 63 tst: l 0.343 a 0.903 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 64 tr: l 0.326 a 0.903 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.877sec(train) 1.299sec(infer)\n",
            "Epoch 64 tst: l 0.340 a 0.903 clct[50, 50, 50, 50] cl_acc 1.000  0.217sec\n",
            "Epoch 65 tr: l 0.325 a 0.903 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.073sec(train) 1.298sec(infer)\n",
            "Epoch 65 tst: l 0.338 a 0.904 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "Epoch 66 tr: l 0.321 a 0.905 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.747sec(train) 1.297sec(infer)\n",
            "Epoch 66 tst: l 0.337 a 0.905 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 67 tr: l 0.322 a 0.904 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.894sec(train) 1.298sec(infer)\n",
            "Epoch 67 tst: l 0.335 a 0.904 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 68 tr: l 0.320 a 0.905 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.976sec(train) 1.331sec(infer)\n",
            "Epoch 68 tst: l 0.332 a 0.905 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 69 tr: l 0.319 a 0.905 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.032sec(train) 1.288sec(infer)\n",
            "Epoch 69 tst: l 0.333 a 0.904 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 70 tr: l 0.316 a 0.905 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.877sec(train) 1.296sec(infer)\n",
            "Epoch 70 tst: l 0.338 a 0.905 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.332\n",
            "Average accuracy over all clients and models: 0.906\n",
            "Epoch 71 tr: l 0.316 a 0.905 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.998sec(train) 1.298sec(infer)\n",
            "Epoch 71 tst: l 0.331 a 0.907 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 72 tr: l 0.313 a 0.906 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.988sec(train) 1.297sec(infer)\n",
            "Epoch 72 tst: l 0.333 a 0.905 clct[50, 50, 50, 50] cl_acc 1.000  0.219sec\n",
            "Epoch 73 tr: l 0.311 a 0.907 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.760sec(train) 1.305sec(infer)\n",
            "Epoch 73 tst: l 0.331 a 0.907 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 74 tr: l 0.309 a 0.908 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.934sec(train) 1.310sec(infer)\n",
            "Epoch 74 tst: l 0.325 a 0.907 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "Epoch 75 tr: l 0.312 a 0.907 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.080sec(train) 1.295sec(infer)\n",
            "Epoch 75 tst: l 0.328 a 0.907 clct[50, 50, 50, 50] cl_acc 1.000  0.217sec\n",
            "Epoch 76 tr: l 0.308 a 0.908 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.861sec(train) 1.275sec(infer)\n",
            "Epoch 76 tst: l 0.332 a 0.907 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 77 tr: l 0.307 a 0.908 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.122sec(train) 1.289sec(infer)\n",
            "Epoch 77 tst: l 0.326 a 0.908 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 78 tr: l 0.307 a 0.908 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.105sec(train) 1.289sec(infer)\n",
            "Epoch 78 tst: l 0.322 a 0.908 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 79 tr: l 0.307 a 0.908 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.016sec(train) 1.288sec(infer)\n",
            "Epoch 79 tst: l 0.323 a 0.909 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 80 tr: l 0.303 a 0.909 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.885sec(train) 1.289sec(infer)\n",
            "Epoch 80 tst: l 0.321 a 0.909 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.320\n",
            "Average accuracy over all clients and models: 0.909\n",
            "Epoch 81 tr: l 0.304 a 0.908 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.954sec(train) 1.268sec(infer)\n",
            "Epoch 81 tst: l 0.320 a 0.909 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 82 tr: l 0.301 a 0.910 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.811sec(train) 1.272sec(infer)\n",
            "Epoch 82 tst: l 0.321 a 0.909 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 83 tr: l 0.302 a 0.910 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.132sec(train) 1.276sec(infer)\n",
            "Epoch 83 tst: l 0.318 a 0.908 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 84 tr: l 0.298 a 0.911 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.715sec(train) 1.274sec(infer)\n",
            "Epoch 84 tst: l 0.319 a 0.909 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 85 tr: l 0.299 a 0.911 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.046sec(train) 1.273sec(infer)\n",
            "Epoch 85 tst: l 0.318 a 0.910 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 86 tr: l 0.299 a 0.910 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.808sec(train) 1.276sec(infer)\n",
            "Epoch 86 tst: l 0.314 a 0.910 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 87 tr: l 0.298 a 0.911 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.908sec(train) 1.276sec(infer)\n",
            "Epoch 87 tst: l 0.314 a 0.911 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 88 tr: l 0.294 a 0.911 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.756sec(train) 1.273sec(infer)\n",
            "Epoch 88 tst: l 0.318 a 0.911 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 89 tr: l 0.294 a 0.912 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.796sec(train) 1.272sec(infer)\n",
            "Epoch 89 tst: l 0.321 a 0.909 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 90 tr: l 0.293 a 0.912 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.827sec(train) 1.272sec(infer)\n",
            "Epoch 90 tst: l 0.311 a 0.911 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.312\n",
            "Average accuracy over all clients and models: 0.911\n",
            "Epoch 91 tr: l 0.290 a 0.913 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.680sec(train) 1.274sec(infer)\n",
            "Epoch 91 tst: l 0.309 a 0.913 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 92 tr: l 0.289 a 0.912 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.694sec(train) 1.277sec(infer)\n",
            "Epoch 92 tst: l 0.310 a 0.912 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 93 tr: l 0.290 a 0.913 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.809sec(train) 1.284sec(infer)\n",
            "Epoch 93 tst: l 0.309 a 0.913 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 94 tr: l 0.289 a 0.913 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.965sec(train) 1.280sec(infer)\n",
            "Epoch 94 tst: l 0.309 a 0.912 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 95 tr: l 0.291 a 0.913 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.967sec(train) 1.272sec(infer)\n",
            "Epoch 95 tst: l 0.311 a 0.913 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 96 tr: l 0.289 a 0.914 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.398sec(train) 1.287sec(infer)\n",
            "Epoch 96 tst: l 0.309 a 0.913 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 97 tr: l 0.288 a 0.913 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.981sec(train) 1.284sec(infer)\n",
            "Epoch 97 tst: l 0.307 a 0.913 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 98 tr: l 0.287 a 0.914 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.262sec(train) 1.285sec(infer)\n",
            "Epoch 98 tst: l 0.304 a 0.915 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "Epoch 99 tr: l 0.288 a 0.914 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.794sec(train) 1.287sec(infer)\n",
            "Epoch 99 tst: l 0.305 a 0.914 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 100 tr: l 0.285 a 0.915 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.124sec(train) 1.285sec(infer)\n",
            "Epoch 100 tst: l 0.304 a 0.914 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.301\n",
            "Average accuracy over all clients and models: 0.915\n",
            "Epoch 101 tr: l 0.282 a 0.915 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.648sec(train) 1.291sec(infer)\n",
            "Epoch 101 tst: l 0.309 a 0.913 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 102 tr: l 0.284 a 0.915 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.736sec(train) 1.290sec(infer)\n",
            "Epoch 102 tst: l 0.302 a 0.915 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 103 tr: l 0.285 a 0.914 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.027sec(train) 1.292sec(infer)\n",
            "Epoch 103 tst: l 0.303 a 0.915 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 104 tr: l 0.280 a 0.915 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.913sec(train) 1.290sec(infer)\n",
            "Epoch 104 tst: l 0.301 a 0.915 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 105 tr: l 0.279 a 0.916 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.042sec(train) 1.288sec(infer)\n",
            "Epoch 105 tst: l 0.298 a 0.916 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 106 tr: l 0.279 a 0.916 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.760sec(train) 1.286sec(infer)\n",
            "Epoch 106 tst: l 0.300 a 0.915 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 107 tr: l 0.278 a 0.916 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.762sec(train) 1.270sec(infer)\n",
            "Epoch 107 tst: l 0.297 a 0.916 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 108 tr: l 0.278 a 0.916 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.669sec(train) 1.269sec(infer)\n",
            "Epoch 108 tst: l 0.295 a 0.916 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 109 tr: l 0.278 a 0.917 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.673sec(train) 1.280sec(infer)\n",
            "Epoch 109 tst: l 0.297 a 0.915 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 110 tr: l 0.275 a 0.917 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.670sec(train) 1.287sec(infer)\n",
            "Epoch 110 tst: l 0.296 a 0.917 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.294\n",
            "Average accuracy over all clients and models: 0.917\n",
            "Epoch 111 tr: l 0.273 a 0.918 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.092sec(train) 1.280sec(infer)\n",
            "Epoch 111 tst: l 0.295 a 0.917 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 112 tr: l 0.276 a 0.917 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.164sec(train) 1.273sec(infer)\n",
            "Epoch 112 tst: l 0.295 a 0.916 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 113 tr: l 0.274 a 0.917 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.327sec(train) 1.286sec(infer)\n",
            "Epoch 113 tst: l 0.301 a 0.915 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 114 tr: l 0.271 a 0.918 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.987sec(train) 1.284sec(infer)\n",
            "Epoch 114 tst: l 0.294 a 0.917 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 115 tr: l 0.271 a 0.918 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.924sec(train) 1.287sec(infer)\n",
            "Epoch 115 tst: l 0.293 a 0.916 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 116 tr: l 0.270 a 0.919 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.768sec(train) 1.281sec(infer)\n",
            "Epoch 116 tst: l 0.291 a 0.918 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 117 tr: l 0.271 a 0.918 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.070sec(train) 1.270sec(infer)\n",
            "Epoch 117 tst: l 0.290 a 0.918 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 118 tr: l 0.272 a 0.918 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.874sec(train) 1.282sec(infer)\n",
            "Epoch 118 tst: l 0.290 a 0.918 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 119 tr: l 0.270 a 0.919 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.808sec(train) 1.281sec(infer)\n",
            "Epoch 119 tst: l 0.290 a 0.917 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 120 tr: l 0.270 a 0.919 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.843sec(train) 1.293sec(infer)\n",
            "Epoch 120 tst: l 0.291 a 0.918 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.289\n",
            "Average accuracy over all clients and models: 0.918\n",
            "Epoch 121 tr: l 0.265 a 0.920 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.794sec(train) 1.276sec(infer)\n",
            "Epoch 121 tst: l 0.289 a 0.918 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 122 tr: l 0.269 a 0.919 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.040sec(train) 1.279sec(infer)\n",
            "Epoch 122 tst: l 0.288 a 0.919 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 123 tr: l 0.265 a 0.920 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.730sec(train) 1.279sec(infer)\n",
            "Epoch 123 tst: l 0.286 a 0.919 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 124 tr: l 0.265 a 0.920 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.095sec(train) 1.271sec(infer)\n",
            "Epoch 124 tst: l 0.286 a 0.919 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 125 tr: l 0.265 a 0.921 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.759sec(train) 1.261sec(infer)\n",
            "Epoch 125 tst: l 0.287 a 0.920 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 126 tr: l 0.265 a 0.920 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.981sec(train) 1.279sec(infer)\n",
            "Epoch 126 tst: l 0.290 a 0.917 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 127 tr: l 0.263 a 0.920 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.868sec(train) 1.298sec(infer)\n",
            "Epoch 127 tst: l 0.295 a 0.919 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 128 tr: l 0.264 a 0.920 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.946sec(train) 1.279sec(infer)\n",
            "Epoch 128 tst: l 0.284 a 0.919 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 129 tr: l 0.261 a 0.921 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.787sec(train) 1.275sec(infer)\n",
            "Epoch 129 tst: l 0.284 a 0.920 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 130 tr: l 0.260 a 0.921 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.944sec(train) 1.278sec(infer)\n",
            "Epoch 130 tst: l 0.284 a 0.920 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.285\n",
            "Average accuracy over all clients and models: 0.920\n",
            "Epoch 131 tr: l 0.262 a 0.921 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.100sec(train) 1.258sec(infer)\n",
            "Epoch 131 tst: l 0.281 a 0.921 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 132 tr: l 0.260 a 0.921 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.619sec(train) 1.278sec(infer)\n",
            "Epoch 132 tst: l 0.280 a 0.920 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 133 tr: l 0.261 a 0.922 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.854sec(train) 1.278sec(infer)\n",
            "Epoch 133 tst: l 0.281 a 0.921 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 134 tr: l 0.258 a 0.922 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.086sec(train) 1.276sec(infer)\n",
            "Epoch 134 tst: l 0.284 a 0.921 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 135 tr: l 0.257 a 0.922 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.818sec(train) 1.280sec(infer)\n",
            "Epoch 135 tst: l 0.280 a 0.921 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 136 tr: l 0.258 a 0.922 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.824sec(train) 1.280sec(infer)\n",
            "Epoch 136 tst: l 0.286 a 0.920 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 137 tr: l 0.254 a 0.922 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.567sec(train) 1.277sec(infer)\n",
            "Epoch 137 tst: l 0.282 a 0.920 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 138 tr: l 0.254 a 0.923 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.346sec(train) 1.277sec(infer)\n",
            "Epoch 138 tst: l 0.284 a 0.921 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 139 tr: l 0.254 a 0.923 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.561sec(train) 1.273sec(infer)\n",
            "Epoch 139 tst: l 0.279 a 0.920 clct[50, 50, 50, 50] cl_acc 1.000  0.210sec\n",
            "Epoch 140 tr: l 0.254 a 0.923 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.519sec(train) 1.273sec(infer)\n",
            "Epoch 140 tst: l 0.277 a 0.922 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.276\n",
            "Average accuracy over all clients and models: 0.922\n",
            "Epoch 141 tr: l 0.253 a 0.924 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.058sec(train) 1.276sec(infer)\n",
            "Epoch 141 tst: l 0.277 a 0.922 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 142 tr: l 0.251 a 0.924 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.611sec(train) 1.277sec(infer)\n",
            "Epoch 142 tst: l 0.276 a 0.922 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 143 tr: l 0.255 a 0.923 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.765sec(train) 1.271sec(infer)\n",
            "Epoch 143 tst: l 0.276 a 0.923 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 144 tr: l 0.251 a 0.924 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.961sec(train) 1.288sec(infer)\n",
            "Epoch 144 tst: l 0.273 a 0.922 clct[50, 50, 50, 50] cl_acc 1.000  0.218sec\n",
            "Epoch 145 tr: l 0.251 a 0.924 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.587sec(train) 1.272sec(infer)\n",
            "Epoch 145 tst: l 0.275 a 0.922 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 146 tr: l 0.249 a 0.924 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.070sec(train) 1.269sec(infer)\n",
            "Epoch 146 tst: l 0.275 a 0.923 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 147 tr: l 0.249 a 0.925 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.799sec(train) 1.272sec(infer)\n",
            "Epoch 147 tst: l 0.275 a 0.922 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 148 tr: l 0.250 a 0.924 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.706sec(train) 1.277sec(infer)\n",
            "Epoch 148 tst: l 0.273 a 0.924 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 149 tr: l 0.246 a 0.925 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.316sec(train) 1.270sec(infer)\n",
            "Epoch 149 tst: l 0.272 a 0.923 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 150 tr: l 0.245 a 0.926 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.508sec(train) 1.273sec(infer)\n",
            "Epoch 150 tst: l 0.271 a 0.924 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.271\n",
            "Average accuracy over all clients and models: 0.923\n",
            "Epoch 151 tr: l 0.248 a 0.925 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.030sec(train) 1.271sec(infer)\n",
            "Epoch 151 tst: l 0.268 a 0.924 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 152 tr: l 0.246 a 0.925 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.597sec(train) 1.278sec(infer)\n",
            "Epoch 152 tst: l 0.278 a 0.922 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 153 tr: l 0.246 a 0.925 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.474sec(train) 1.272sec(infer)\n",
            "Epoch 153 tst: l 0.270 a 0.923 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 154 tr: l 0.244 a 0.926 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.628sec(train) 1.274sec(infer)\n",
            "Epoch 154 tst: l 0.270 a 0.924 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 155 tr: l 0.244 a 0.926 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.731sec(train) 1.272sec(infer)\n",
            "Epoch 155 tst: l 0.271 a 0.924 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 156 tr: l 0.244 a 0.926 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.336sec(train) 1.263sec(infer)\n",
            "Epoch 156 tst: l 0.270 a 0.925 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 157 tr: l 0.244 a 0.926 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.709sec(train) 1.283sec(infer)\n",
            "Epoch 157 tst: l 0.269 a 0.924 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 158 tr: l 0.240 a 0.926 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.625sec(train) 1.258sec(infer)\n",
            "Epoch 158 tst: l 0.266 a 0.925 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 159 tr: l 0.243 a 0.927 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.439sec(train) 1.264sec(infer)\n",
            "Epoch 159 tst: l 0.267 a 0.924 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 160 tr: l 0.239 a 0.927 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.681sec(train) 1.262sec(infer)\n",
            "Epoch 160 tst: l 0.271 a 0.922 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.266\n",
            "Average accuracy over all clients and models: 0.924\n",
            "Epoch 161 tr: l 0.240 a 0.927 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.728sec(train) 1.277sec(infer)\n",
            "Epoch 161 tst: l 0.272 a 0.924 clct[50, 50, 50, 50] cl_acc 1.000  0.221sec\n",
            "Epoch 162 tr: l 0.239 a 0.928 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.785sec(train) 1.279sec(infer)\n",
            "Epoch 162 tst: l 0.265 a 0.924 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 163 tr: l 0.239 a 0.928 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.738sec(train) 1.277sec(infer)\n",
            "Epoch 163 tst: l 0.264 a 0.925 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 164 tr: l 0.240 a 0.927 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.003sec(train) 1.281sec(infer)\n",
            "Epoch 164 tst: l 0.263 a 0.926 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 165 tr: l 0.236 a 0.929 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.755sec(train) 1.266sec(infer)\n",
            "Epoch 165 tst: l 0.266 a 0.924 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 166 tr: l 0.237 a 0.928 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.899sec(train) 1.273sec(infer)\n",
            "Epoch 166 tst: l 0.258 a 0.926 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 167 tr: l 0.237 a 0.929 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.603sec(train) 1.268sec(infer)\n",
            "Epoch 167 tst: l 0.261 a 0.926 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 168 tr: l 0.235 a 0.929 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.565sec(train) 1.292sec(infer)\n",
            "Epoch 168 tst: l 0.261 a 0.927 clct[50, 50, 50, 50] cl_acc 1.000  0.210sec\n",
            "Epoch 169 tr: l 0.235 a 0.928 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.673sec(train) 1.272sec(infer)\n",
            "Epoch 169 tst: l 0.260 a 0.926 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 170 tr: l 0.234 a 0.929 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.719sec(train) 1.267sec(infer)\n",
            "Epoch 170 tst: l 0.259 a 0.926 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.259\n",
            "Average accuracy over all clients and models: 0.926\n",
            "Epoch 171 tr: l 0.234 a 0.929 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.640sec(train) 1.268sec(infer)\n",
            "Epoch 171 tst: l 0.258 a 0.927 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 172 tr: l 0.235 a 0.929 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.514sec(train) 1.275sec(infer)\n",
            "Epoch 172 tst: l 0.265 a 0.925 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 173 tr: l 0.231 a 0.930 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.736sec(train) 1.260sec(infer)\n",
            "Epoch 173 tst: l 0.263 a 0.925 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 174 tr: l 0.233 a 0.930 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.678sec(train) 1.274sec(infer)\n",
            "Epoch 174 tst: l 0.259 a 0.926 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 175 tr: l 0.233 a 0.929 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.169sec(train) 1.268sec(infer)\n",
            "Epoch 175 tst: l 0.262 a 0.927 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 176 tr: l 0.236 a 0.929 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.894sec(train) 1.273sec(infer)\n",
            "Epoch 176 tst: l 0.260 a 0.926 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 177 tr: l 0.230 a 0.930 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.782sec(train) 1.275sec(infer)\n",
            "Epoch 177 tst: l 0.256 a 0.927 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 178 tr: l 0.231 a 0.930 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.054sec(train) 1.262sec(infer)\n",
            "Epoch 178 tst: l 0.259 a 0.927 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 179 tr: l 0.229 a 0.930 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.991sec(train) 1.270sec(infer)\n",
            "Epoch 179 tst: l 0.256 a 0.928 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 180 tr: l 0.229 a 0.931 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.859sec(train) 1.265sec(infer)\n",
            "Epoch 180 tst: l 0.257 a 0.928 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.254\n",
            "Average accuracy over all clients and models: 0.928\n",
            "Epoch 181 tr: l 0.227 a 0.931 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.076sec(train) 1.274sec(infer)\n",
            "Epoch 181 tst: l 0.253 a 0.928 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 182 tr: l 0.228 a 0.930 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.059sec(train) 1.276sec(infer)\n",
            "Epoch 182 tst: l 0.258 a 0.928 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 183 tr: l 0.227 a 0.932 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.995sec(train) 1.273sec(infer)\n",
            "Epoch 183 tst: l 0.251 a 0.928 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 184 tr: l 0.225 a 0.932 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.643sec(train) 1.274sec(infer)\n",
            "Epoch 184 tst: l 0.251 a 0.929 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 185 tr: l 0.227 a 0.931 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.942sec(train) 1.271sec(infer)\n",
            "Epoch 185 tst: l 0.253 a 0.928 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 186 tr: l 0.226 a 0.932 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.973sec(train) 1.274sec(infer)\n",
            "Epoch 186 tst: l 0.254 a 0.929 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 187 tr: l 0.226 a 0.932 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.702sec(train) 1.272sec(infer)\n",
            "Epoch 187 tst: l 0.251 a 0.930 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 188 tr: l 0.225 a 0.932 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.648sec(train) 1.273sec(infer)\n",
            "Epoch 188 tst: l 0.249 a 0.929 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 189 tr: l 0.224 a 0.932 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.732sec(train) 1.273sec(infer)\n",
            "Epoch 189 tst: l 0.250 a 0.928 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 190 tr: l 0.225 a 0.932 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.185sec(train) 1.272sec(infer)\n",
            "Epoch 190 tst: l 0.257 a 0.927 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.252\n",
            "Average accuracy over all clients and models: 0.928\n",
            "Epoch 191 tr: l 0.222 a 0.932 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.944sec(train) 1.273sec(infer)\n",
            "Epoch 191 tst: l 0.249 a 0.928 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 192 tr: l 0.221 a 0.933 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.819sec(train) 1.249sec(infer)\n",
            "Epoch 192 tst: l 0.248 a 0.929 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 193 tr: l 0.222 a 0.932 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.106sec(train) 1.279sec(infer)\n",
            "Epoch 193 tst: l 0.256 a 0.930 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 194 tr: l 0.222 a 0.933 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.813sec(train) 1.274sec(infer)\n",
            "Epoch 194 tst: l 0.250 a 0.929 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 195 tr: l 0.220 a 0.934 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.884sec(train) 1.276sec(infer)\n",
            "Epoch 195 tst: l 0.248 a 0.929 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 196 tr: l 0.221 a 0.933 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.162sec(train) 1.260sec(infer)\n",
            "Epoch 196 tst: l 0.255 a 0.930 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 197 tr: l 0.219 a 0.934 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.567sec(train) 1.245sec(infer)\n",
            "Epoch 197 tst: l 0.247 a 0.931 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 198 tr: l 0.219 a 0.934 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.293sec(train) 1.263sec(infer)\n",
            "Epoch 198 tst: l 0.246 a 0.930 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 199 tr: l 0.219 a 0.934 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.693sec(train) 1.256sec(infer)\n",
            "Epoch 199 tst: l 0.244 a 0.930 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 200 tr: l 0.217 a 0.934 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.673sec(train) 1.276sec(infer)\n",
            "Epoch 200 tst: l 0.244 a 0.931 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.243\n",
            "Average accuracy over all clients and models: 0.931\n",
            "Epoch 201 tr: l 0.216 a 0.934 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.632sec(train) 1.279sec(infer)\n",
            "Epoch 201 tst: l 0.242 a 0.931 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 202 tr: l 0.216 a 0.934 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.699sec(train) 1.279sec(infer)\n",
            "Epoch 202 tst: l 0.244 a 0.930 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 203 tr: l 0.216 a 0.935 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.851sec(train) 1.276sec(infer)\n",
            "Epoch 203 tst: l 0.250 a 0.930 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 204 tr: l 0.213 a 0.935 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.425sec(train) 1.270sec(infer)\n",
            "Epoch 204 tst: l 0.246 a 0.930 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 205 tr: l 0.214 a 0.935 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.693sec(train) 1.269sec(infer)\n",
            "Epoch 205 tst: l 0.242 a 0.931 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 206 tr: l 0.217 a 0.934 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.582sec(train) 1.269sec(infer)\n",
            "Epoch 206 tst: l 0.244 a 0.930 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 207 tr: l 0.214 a 0.935 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.536sec(train) 1.268sec(infer)\n",
            "Epoch 207 tst: l 0.241 a 0.933 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 208 tr: l 0.214 a 0.935 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.373sec(train) 1.266sec(infer)\n",
            "Epoch 208 tst: l 0.247 a 0.931 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 209 tr: l 0.213 a 0.935 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.407sec(train) 1.254sec(infer)\n",
            "Epoch 209 tst: l 0.242 a 0.931 clct[50, 50, 50, 50] cl_acc 1.000  0.210sec\n",
            "Epoch 210 tr: l 0.212 a 0.936 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.642sec(train) 1.268sec(infer)\n",
            "Epoch 210 tst: l 0.244 a 0.930 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.240\n",
            "Average accuracy over all clients and models: 0.931\n",
            "Epoch 211 tr: l 0.212 a 0.936 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.673sec(train) 1.263sec(infer)\n",
            "Epoch 211 tst: l 0.239 a 0.931 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 212 tr: l 0.212 a 0.936 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.748sec(train) 1.261sec(infer)\n",
            "Epoch 212 tst: l 0.241 a 0.932 clct[50, 50, 50, 50] cl_acc 1.000  0.209sec\n",
            "Epoch 213 tr: l 0.211 a 0.936 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.633sec(train) 1.266sec(infer)\n",
            "Epoch 213 tst: l 0.240 a 0.932 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 214 tr: l 0.211 a 0.936 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.465sec(train) 1.265sec(infer)\n",
            "Epoch 214 tst: l 0.237 a 0.932 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 215 tr: l 0.210 a 0.936 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.294sec(train) 1.256sec(infer)\n",
            "Epoch 215 tst: l 0.236 a 0.933 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 216 tr: l 0.209 a 0.936 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.617sec(train) 1.265sec(infer)\n",
            "Epoch 216 tst: l 0.238 a 0.932 clct[50, 50, 50, 50] cl_acc 1.000  0.208sec\n",
            "Epoch 217 tr: l 0.209 a 0.937 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.589sec(train) 1.261sec(infer)\n",
            "Epoch 217 tst: l 0.245 a 0.930 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 218 tr: l 0.209 a 0.937 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.391sec(train) 1.261sec(infer)\n",
            "Epoch 218 tst: l 0.236 a 0.932 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 219 tr: l 0.208 a 0.937 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.548sec(train) 1.257sec(infer)\n",
            "Epoch 219 tst: l 0.236 a 0.934 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 220 tr: l 0.207 a 0.937 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.686sec(train) 1.270sec(infer)\n",
            "Epoch 220 tst: l 0.234 a 0.934 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.233\n",
            "Average accuracy over all clients and models: 0.933\n",
            "Epoch 221 tr: l 0.208 a 0.937 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.946sec(train) 1.279sec(infer)\n",
            "Epoch 221 tst: l 0.235 a 0.933 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 222 tr: l 0.206 a 0.937 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.962sec(train) 1.266sec(infer)\n",
            "Epoch 222 tst: l 0.239 a 0.932 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 223 tr: l 0.204 a 0.938 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.615sec(train) 1.261sec(infer)\n",
            "Epoch 223 tst: l 0.233 a 0.934 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 224 tr: l 0.206 a 0.937 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.814sec(train) 1.284sec(infer)\n",
            "Epoch 224 tst: l 0.236 a 0.933 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 225 tr: l 0.205 a 0.938 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.137sec(train) 1.273sec(infer)\n",
            "Epoch 225 tst: l 0.232 a 0.933 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 226 tr: l 0.206 a 0.938 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.104sec(train) 1.266sec(infer)\n",
            "Epoch 226 tst: l 0.232 a 0.934 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 227 tr: l 0.205 a 0.937 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.966sec(train) 1.274sec(infer)\n",
            "Epoch 227 tst: l 0.231 a 0.934 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 228 tr: l 0.204 a 0.938 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.118sec(train) 1.266sec(infer)\n",
            "Epoch 228 tst: l 0.231 a 0.935 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 229 tr: l 0.203 a 0.938 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.871sec(train) 1.276sec(infer)\n",
            "Epoch 229 tst: l 0.229 a 0.935 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 230 tr: l 0.205 a 0.938 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.632sec(train) 1.271sec(infer)\n",
            "Epoch 230 tst: l 0.228 a 0.935 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.228\n",
            "Average accuracy over all clients and models: 0.934\n",
            "Epoch 231 tr: l 0.203 a 0.938 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.047sec(train) 1.274sec(infer)\n",
            "Epoch 231 tst: l 0.229 a 0.934 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 232 tr: l 0.201 a 0.938 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.927sec(train) 1.277sec(infer)\n",
            "Epoch 232 tst: l 0.230 a 0.934 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 233 tr: l 0.200 a 0.939 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.054sec(train) 1.275sec(infer)\n",
            "Epoch 233 tst: l 0.229 a 0.935 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 234 tr: l 0.200 a 0.939 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.818sec(train) 1.273sec(infer)\n",
            "Epoch 234 tst: l 0.229 a 0.935 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 235 tr: l 0.201 a 0.939 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.130sec(train) 1.279sec(infer)\n",
            "Epoch 235 tst: l 0.228 a 0.936 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 236 tr: l 0.200 a 0.939 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.058sec(train) 1.273sec(infer)\n",
            "Epoch 236 tst: l 0.230 a 0.936 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 237 tr: l 0.199 a 0.939 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.847sec(train) 1.285sec(infer)\n",
            "Epoch 237 tst: l 0.234 a 0.935 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 238 tr: l 0.199 a 0.939 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.970sec(train) 1.274sec(infer)\n",
            "Epoch 238 tst: l 0.226 a 0.936 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 239 tr: l 0.197 a 0.940 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.797sec(train) 1.272sec(infer)\n",
            "Epoch 239 tst: l 0.236 a 0.935 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 240 tr: l 0.201 a 0.939 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.244sec(train) 1.288sec(infer)\n",
            "Epoch 240 tst: l 0.225 a 0.936 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.226\n",
            "Average accuracy over all clients and models: 0.935\n",
            "Epoch 241 tr: l 0.199 a 0.939 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.096sec(train) 1.270sec(infer)\n",
            "Epoch 241 tst: l 0.225 a 0.936 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 242 tr: l 0.197 a 0.940 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.691sec(train) 1.265sec(infer)\n",
            "Epoch 242 tst: l 0.227 a 0.934 clct[50, 50, 50, 50] cl_acc 1.000  0.210sec\n",
            "Epoch 243 tr: l 0.195 a 0.940 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.760sec(train) 1.272sec(infer)\n",
            "Epoch 243 tst: l 0.224 a 0.936 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 244 tr: l 0.196 a 0.940 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.098sec(train) 1.253sec(infer)\n",
            "Epoch 244 tst: l 0.225 a 0.935 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 245 tr: l 0.196 a 0.940 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.858sec(train) 1.252sec(infer)\n",
            "Epoch 245 tst: l 0.224 a 0.936 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 246 tr: l 0.196 a 0.940 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.772sec(train) 1.263sec(infer)\n",
            "Epoch 246 tst: l 0.228 a 0.935 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 247 tr: l 0.194 a 0.940 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.779sec(train) 1.261sec(infer)\n",
            "Epoch 247 tst: l 0.235 a 0.934 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 248 tr: l 0.195 a 0.941 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.947sec(train) 1.263sec(infer)\n",
            "Epoch 248 tst: l 0.222 a 0.936 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 249 tr: l 0.193 a 0.941 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.585sec(train) 1.252sec(infer)\n",
            "Epoch 249 tst: l 0.223 a 0.937 clct[50, 50, 50, 50] cl_acc 1.000  0.209sec\n",
            "Epoch 250 tr: l 0.195 a 0.941 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.924sec(train) 1.251sec(infer)\n",
            "Epoch 250 tst: l 0.224 a 0.936 clct[50, 50, 50, 50] cl_acc 1.000  0.208sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.221\n",
            "Average accuracy over all clients and models: 0.936\n",
            "Epoch 251 tr: l 0.192 a 0.942 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.072sec(train) 1.263sec(infer)\n",
            "Epoch 251 tst: l 0.221 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 252 tr: l 0.193 a 0.941 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.107sec(train) 1.263sec(infer)\n",
            "Epoch 252 tst: l 0.222 a 0.937 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 253 tr: l 0.191 a 0.942 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.872sec(train) 1.263sec(infer)\n",
            "Epoch 253 tst: l 0.220 a 0.937 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 254 tr: l 0.193 a 0.941 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.481sec(train) 1.261sec(infer)\n",
            "Epoch 254 tst: l 0.224 a 0.935 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 255 tr: l 0.193 a 0.941 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.872sec(train) 1.261sec(infer)\n",
            "Epoch 255 tst: l 0.220 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 256 tr: l 0.192 a 0.942 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.605sec(train) 1.258sec(infer)\n",
            "Epoch 256 tst: l 0.222 a 0.937 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 257 tr: l 0.190 a 0.942 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.942sec(train) 1.270sec(infer)\n",
            "Epoch 257 tst: l 0.219 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 258 tr: l 0.189 a 0.942 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.445sec(train) 1.270sec(infer)\n",
            "Epoch 258 tst: l 0.217 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 259 tr: l 0.188 a 0.942 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.895sec(train) 1.272sec(infer)\n",
            "Epoch 259 tst: l 0.219 a 0.936 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 260 tr: l 0.189 a 0.942 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.720sec(train) 1.272sec(infer)\n",
            "Epoch 260 tst: l 0.218 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.217\n",
            "Average accuracy over all clients and models: 0.938\n",
            "Epoch 261 tr: l 0.188 a 0.942 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.974sec(train) 1.281sec(infer)\n",
            "Epoch 261 tst: l 0.217 a 0.937 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 262 tr: l 0.188 a 0.943 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.946sec(train) 1.271sec(infer)\n",
            "Epoch 262 tst: l 0.219 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 263 tr: l 0.190 a 0.942 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.756sec(train) 1.271sec(infer)\n",
            "Epoch 263 tst: l 0.223 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 264 tr: l 0.188 a 0.942 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.630sec(train) 1.284sec(infer)\n",
            "Epoch 264 tst: l 0.229 a 0.935 clct[50, 50, 50, 50] cl_acc 1.000  0.220sec\n",
            "Epoch 265 tr: l 0.187 a 0.943 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.621sec(train) 1.268sec(infer)\n",
            "Epoch 265 tst: l 0.224 a 0.935 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 266 tr: l 0.188 a 0.943 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.891sec(train) 1.270sec(infer)\n",
            "Epoch 266 tst: l 0.217 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 267 tr: l 0.185 a 0.943 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.831sec(train) 1.271sec(infer)\n",
            "Epoch 267 tst: l 0.217 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 268 tr: l 0.188 a 0.943 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.934sec(train) 1.268sec(infer)\n",
            "Epoch 268 tst: l 0.215 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.210sec\n",
            "Epoch 269 tr: l 0.185 a 0.943 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.562sec(train) 1.268sec(infer)\n",
            "Epoch 269 tst: l 0.217 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 270 tr: l 0.185 a 0.943 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.678sec(train) 1.269sec(infer)\n",
            "Epoch 270 tst: l 0.217 a 0.939 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.218\n",
            "Average accuracy over all clients and models: 0.937\n",
            "Epoch 271 tr: l 0.186 a 0.943 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.989sec(train) 1.285sec(infer)\n",
            "Epoch 271 tst: l 0.213 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.210sec\n",
            "Epoch 272 tr: l 0.184 a 0.943 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.552sec(train) 1.269sec(infer)\n",
            "Epoch 272 tst: l 0.214 a 0.939 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 273 tr: l 0.185 a 0.944 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.927sec(train) 1.270sec(infer)\n",
            "Epoch 273 tst: l 0.214 a 0.939 clct[50, 50, 50, 50] cl_acc 1.000  0.210sec\n",
            "Epoch 274 tr: l 0.183 a 0.944 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.547sec(train) 1.283sec(infer)\n",
            "Epoch 274 tst: l 0.213 a 0.939 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 275 tr: l 0.183 a 0.944 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.883sec(train) 1.271sec(infer)\n",
            "Epoch 275 tst: l 0.221 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 276 tr: l 0.183 a 0.944 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.835sec(train) 1.272sec(infer)\n",
            "Epoch 276 tst: l 0.212 a 0.939 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 277 tr: l 0.181 a 0.944 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.045sec(train) 1.281sec(infer)\n",
            "Epoch 277 tst: l 0.212 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.216sec\n",
            "Epoch 278 tr: l 0.181 a 0.944 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.692sec(train) 1.309sec(infer)\n",
            "Epoch 278 tst: l 0.212 a 0.940 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 279 tr: l 0.182 a 0.945 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.053sec(train) 1.277sec(infer)\n",
            "Epoch 279 tst: l 0.210 a 0.939 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 280 tr: l 0.181 a 0.945 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.064sec(train) 1.266sec(infer)\n",
            "Epoch 280 tst: l 0.211 a 0.940 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.209\n",
            "Average accuracy over all clients and models: 0.940\n",
            "Epoch 281 tr: l 0.181 a 0.945 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.708sec(train) 1.270sec(infer)\n",
            "Epoch 281 tst: l 0.209 a 0.940 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 282 tr: l 0.180 a 0.945 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.990sec(train) 1.270sec(infer)\n",
            "Epoch 282 tst: l 0.211 a 0.939 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 283 tr: l 0.180 a 0.945 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.552sec(train) 1.272sec(infer)\n",
            "Epoch 283 tst: l 0.210 a 0.939 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 284 tr: l 0.180 a 0.945 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 18.280sec(train) 1.293sec(infer)\n",
            "Epoch 284 tst: l 0.217 a 0.940 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 285 tr: l 0.179 a 0.945 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.664sec(train) 1.252sec(infer)\n",
            "Epoch 285 tst: l 0.210 a 0.939 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 286 tr: l 0.179 a 0.945 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.347sec(train) 1.271sec(infer)\n",
            "Epoch 286 tst: l 0.208 a 0.941 clct[50, 50, 50, 50] cl_acc 1.000  0.213sec\n",
            "Epoch 287 tr: l 0.180 a 0.945 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.746sec(train) 1.288sec(infer)\n",
            "Epoch 287 tst: l 0.217 a 0.938 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 288 tr: l 0.177 a 0.946 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 17.935sec(train) 1.265sec(infer)\n",
            "Epoch 288 tst: l 0.207 a 0.941 clct[50, 50, 50, 50] cl_acc 1.000  0.210sec\n",
            "Epoch 289 tr: l 0.177 a 0.946 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.715sec(train) 1.272sec(infer)\n",
            "Epoch 289 tst: l 0.210 a 0.940 clct[50, 50, 50, 50] cl_acc 1.000  0.215sec\n",
            "Epoch 290 tr: l 0.176 a 0.946 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.993sec(train) 1.271sec(infer)\n",
            "Epoch 290 tst: l 0.209 a 0.941 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Average loss over all clients and models: 0.206\n",
            "Average accuracy over all clients and models: 0.941\n",
            "Epoch 291 tr: l 0.178 a 0.945 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.746sec(train) 1.272sec(infer)\n",
            "Epoch 291 tst: l 0.206 a 0.941 clct[50, 50, 50, 50] cl_acc 1.000  0.214sec\n",
            "Epoch 292 tr: l 0.175 a 0.947 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.639sec(train) 1.267sec(infer)\n",
            "Epoch 292 tst: l 0.209 a 0.941 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 293 tr: l 0.176 a 0.946 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.830sec(train) 1.245sec(infer)\n",
            "Epoch 293 tst: l 0.212 a 0.939 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 294 tr: l 0.179 a 0.945 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.871sec(train) 1.264sec(infer)\n",
            "Epoch 294 tst: l 0.207 a 0.941 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 295 tr: l 0.176 a 0.946 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 15.926sec(train) 1.245sec(infer)\n",
            "Epoch 295 tst: l 0.206 a 0.940 clct[50, 50, 50, 50] cl_acc 1.000  0.207sec\n",
            "Epoch 296 tr: l 0.174 a 0.947 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.400sec(train) 1.262sec(infer)\n",
            "Epoch 296 tst: l 0.203 a 0.941 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 297 tr: l 0.174 a 0.946 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.556sec(train) 1.267sec(infer)\n",
            "Epoch 297 tst: l 0.205 a 0.941 clct[50, 50, 50, 50] cl_acc 1.000  0.212sec\n",
            "Epoch 298 tr: l 0.173 a 0.947 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.332sec(train) 1.267sec(infer)\n",
            "Epoch 298 tst: l 0.205 a 0.941 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "Epoch 299 tr: l 0.172 a 0.946 clct[300, 300, 300, 300] cl_acc 1.000  lr 0.100000 16.527sec(train) 1.257sec(infer)\n",
            "Epoch 299 tst: l 0.203 a 0.942 clct[50, 50, 50, 50] cl_acc 1.000  0.211sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "---train cluster Ended in 1.49 hour (5362.526 sec) \n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAHWCAYAAABACtmGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABeg0lEQVR4nO3deXhU5d3/8c+ZPZNksq8kbAFBdsUNrEoVAbeKtdW6/ARba1u1rUK1Lk9d8HmktbVaq9WuUtu6tFaxFRdACxQFFwQXRHYIWxKyL5PMen5/TDIaE0jIwiST9+u6cjVzzpmZ7+Qm1A/3fX+PYZqmKQAAAADAIVliXQAAAAAA9HUEJwAAAADoAMEJAAAAADpAcAIAAACADhCcAAAAAKADBCcAAAAA6ADBCQAAAAA6QHACAAAAgA4QnAAAAACgAwQnAIhjc+fO1dChQ7v03LvvvluGYfRsQRhwhg4dqvPPPz/WZQBAtxGcACAGDMPo1NeKFStiXWpMzJ07V0lJSbEuo18YOnToIf/8zJo1K9blAUDcsMW6AAAYiP7yl7+0evzkk09q2bJlbY4fe+yx3Xqf3//+9wqHw1167v/8z//o1ltv7db74+iYNGmS5s+f3+Z4fn5+DKoBgPhEcAKAGLjyyitbPV67dq2WLVvW5vgXeb1eud3uTr+P3W7vUn2SZLPZZLPxfxOxFgwGFQ6H5XA4DnnNoEGDOvyzAwDoHpbqAUAfNW3aNI0bN07r1q3T6aefLrfbrdtvv12S9OKLL+q8885Tfn6+nE6nioqKdO+99yoUCrV6jS/ucdq1a5cMw9AvfvEL/e53v1NRUZGcTqdOPPFEvfvuu62e294eJ8MwdMMNN2jx4sUaN26cnE6nxo4dq1dffbVN/StWrNAJJ5wgl8uloqIi/fa3v+3xfVP/+Mc/NHnyZCUkJCgzM1NXXnml9u3b1+qakpISXX311SooKJDT6VReXp4uvPBC7dq1K3rNe++9p5kzZyozM1MJCQkaNmyYvvnNb3b4/i37d5YuXapJkybJ5XJpzJgxev7559tcW11drRtvvFGFhYVyOp0aMWKEfvazn7WaEfz8+Dz00EPR8fnkk0+6/kNq1rL8cceOHZo5c6YSExOVn5+vBQsWyDTNVtc2NDRo/vz50VpHjRqlX/ziF22uk6S//vWvOumkk+R2u5WWlqbTTz9dS5cubXPd6tWrddJJJ8nlcmn48OF68sknu/2ZAOBo4p8SAaAPq6io0DnnnKNvfOMbuvLKK5WTkyNJWrRokZKSkjRv3jwlJSXpjTfe0J133qna2lr9/Oc/7/B1n3rqKdXV1ek73/mODMPQ/fffr69+9avasWNHh7NUq1ev1vPPP6/rrrtOycnJevjhh3XxxReruLhYGRkZkqT169dr1qxZysvL0z333KNQKKQFCxYoKyur+z+UZosWLdLVV1+tE088UQsXLlRpaal+9atf6c0339T69euVmpoqSbr44ou1ceNGff/739fQoUNVVlamZcuWqbi4OPp4xowZysrK0q233qrU1FTt2rWr3fDTnq1bt+rSSy/Vd7/7Xc2ZM0dPPPGEvv71r+vVV1/V2WefLSkyU3jGGWdo3759+s53vqPBgwfrrbfe0m233aYDBw7ooYceavWaTzzxhJqamnTttdfK6XQqPT39sDUEAgGVl5e3OZ6YmKiEhITo41AopFmzZumUU07R/fffr1dffVV33XWXgsGgFixYIEkyTVNf+cpX9J///Eff+ta3NGnSJL322mu6+eabtW/fPj344IPR17vnnnt09913a+rUqVqwYIEcDofefvttvfHGG5oxY0b0um3btulrX/uavvWtb2nOnDn605/+pLlz52ry5MkaO3Zsp37OABBzJgAg5q6//nrzi38ln3HGGaYk8/HHH29zvdfrbXPsO9/5jul2u82mpqbosTlz5phDhgyJPt65c6cpyczIyDArKyujx1988UVTkvnvf/87euyuu+5qU5Mk0+FwmNu2bYse++CDD0xJ5q9//evosQsuuMB0u93mvn37ose2bt1q2my2Nq/Znjlz5piJiYmHPO/3+83s7Gxz3LhxZmNjY/T4Sy+9ZEoy77zzTtM0TbOqqsqUZP785z8/5Gu98MILpiTz3Xff7bCuLxoyZIgpyfznP/8ZPVZTU2Pm5eWZxx13XPTYvffeayYmJppbtmxp9fxbb73VtFqtZnFxsWman42Px+Mxy8rKjqiG9r4WLlwYvW7OnDmmJPP73/9+9Fg4HDbPO+880+FwmAcPHjRN0zQXL15sSjL/93//t9X7fO1rXzMNw4iO/datW02LxWJedNFFZigUanVtOBxuU9+qVauix8rKykyn02nOnz+/U58RAPoCluoBQB/mdDp19dVXtzn++VmEuro6lZeX67TTTpPX69Wnn37a4eteeumlSktLiz4+7bTTJEk7duzo8LnTp09XUVFR9PGECRPk8Xiizw2FQlq+fLlmz57dqjnBiBEjdM4553T4+p3x3nvvqaysTNddd51cLlf0+HnnnafRo0dryZIlkiI/J4fDoRUrVqiqqqrd12qZmXrppZcUCASOuJb8/HxddNFF0ccej0dXXXWV1q9fr5KSEkmRJYWnnXaa0tLSVF5eHv2aPn26QqGQVq1a1eo1L7744iOanTv55JO1bNmyNl+XXXZZm2tvuOGG6PctSy/9fr+WL18uSXr55ZdltVr1gx/8oNXz5s+fL9M09corr0iSFi9erHA4rDvvvFMWS+v/nPjicswxY8ZE/4xJUlZWlkaNGtWpP28A0FewVA8A+rBBgwa12xRg48aN+p//+R+98cYbqq2tbXWupqamw9cdPHhwq8ctIepQ4eJwz215fstzy8rK1NjYqBEjRrS5rr1jXbF7925J0qhRo9qcGz16tFavXi0pEjx/9rOfaf78+crJydEpp5yi888/X1dddZVyc3MlSWeccYYuvvhi3XPPPXrwwQc1bdo0zZ49W5dffrmcTmeHtYwYMaJNUDjmmGMkRfYs5ebmauvWrfrwww8PGYbKyspaPR42bFiH7/t5mZmZmj59eofXWSwWDR8+/JC1SpGfbX5+vpKTk1td19LhseVnv337dlksFo0ZM6bD9+3ozwwA9AcEJwDowz4/s9SiurpaZ5xxhjwejxYsWKCioiK5XC69//77+vGPf9yp9uNWq7Xd42Y7m/978rmxcOONN+qCCy7Q4sWL9dprr+knP/mJFi5cqDfeeEPHHXecDMPQc889p7Vr1+rf//63XnvtNX3zm9/UAw88oLVr1/bI/aTC4bDOPvts3XLLLe2ebwkvLdob9/6sv/2ZAYD2EJwAoJ9ZsWKFKioq9Pzzz+v000+PHt+5c2cMq/pMdna2XC6Xtm3b1uZce8e6YsiQIZKkzZs368wzz2x1bvPmzdHzLYqKijR//nzNnz9fW7du1aRJk/TAAw/or3/9a/SaU045Raeccor+7//+T0899ZSuuOIKPfPMM7rmmmsOW8u2bdtkmmarWactW7ZIUrSjYVFRkerr6zs1K9SbwuGwduzY0SqofbHWIUOGaPny5aqrq2s169SyBLTlZ1tUVKRwOKxPPvlEkyZNOjofAABiiD1OANDPtPzr/ef/td7v9+s3v/lNrEpqxWq1avr06Vq8eLH2798fPb5t27bo/pjuOuGEE5Sdna3HH39cPp8vevyVV17Rpk2bdN5550mKdLNrampq9dyioiIlJydHn1dVVdVm5qMlCHz+tQ9l//79euGFF6KPa2tr9eSTT2rSpEnR5YCXXHKJ1qxZo9dee63N86urqxUMBjvxqXvGI488Ev3eNE098sgjstvtOuussyRJ5557rkKhUKvrJOnBBx+UYRjRfWqzZ8+WxWLRggUL2sxyMpMEIB4x4wQA/czUqVOVlpamOXPm6Ac/+IEMw9Bf/vKXPvUfq3fffbeWLl2qU089Vd/73vei/yE+btw4bdiwoVOvEQgE9L//+79tjqenp+u6667Tz372M1199dU644wzdNlll0XbkQ8dOlQ33XSTpMhsyllnnaVLLrlEY8aMkc1m0wsvvKDS0lJ94xvfkCT9+c9/1m9+8xtddNFFKioqUl1dnX7/+9/L4/Ho3HPP7bDOY445Rt/61rf07rvvKicnR3/6059UWlqqJ554InrNzTffrH/96186//zzo224Gxoa9NFHH+m5557Trl27lJmZ2amfS3v27dvXavasRVJSkmbPnh197HK59Oqrr2rOnDk6+eST9corr2jJkiW6/fbbo/uvLrjgAn35y1/WHXfcoV27dmnixIlaunSpXnzxRd14443RxiAjRozQHXfcoXvvvVennXaavvrVr8rpdOrdd99Vfn6+Fi5c2OXPAwB9EcEJAPqZjIwMvfTSS5o/f77+53/+R2lpabryyit11llnaebMmbEuT5I0efJkvfLKK/rRj36kn/zkJyosLNSCBQu0adOmTnX9kyKzaD/5yU/aHC8qKtJ1112nuXPnyu1266c//al+/OMfKzExURdddJF+9rOfRTvlFRYW6rLLLtPrr7+uv/zlL7LZbBo9erT+/ve/6+KLL5YUaQ7xzjvv6JlnnlFpaalSUlJ00kkn6W9/+1unmjSMHDlSv/71r3XzzTdr8+bNGjZsmJ599tlWY+F2u7Vy5Urdd999+sc//qEnn3xSHo9HxxxzjO655x6lpKR06mdyKBs2bND/+3//r83xIUOGtApOVqtVr776qr73ve/p5ptvVnJysu666y7deeed0WssFov+9a9/6c4779Szzz6rJ554QkOHDtXPf/5zzZ8/v9XrL1iwQMOGDdOvf/1r3XHHHXK73ZowYUK7tQBAf2eYfemfKAEAcW327NnauHGjtm7dGutSesTQoUM1btw4vfTSS7EupUNz587Vc889p/r6+liXAgD9EnucAAC9orGxsdXjrVu36uWXX9a0adNiUxAAAN3AUj0AQK8YPny45s6dq+HDh2v37t167LHH5HA4DtmSGwCAvozgBADoFbNmzdLTTz+tkpISOZ1OTZkyRffdd59GjhwZ69IAADhi7HECAAAAgA6wxwkAAAAAOkBwAgAAAIAODLg9TuFwWPv371dycrIMw4h1OQAAAABixDRN1dXVKT8/XxbL4eeUBlxw2r9/vwoLC2NdBgAAAIA+Ys+ePSooKDjsNQMuOCUnJ0uK/HA8Hk+Mq5ECgYCWLl2qGTNmyG63x7oc9ADGNP4wpvGJcY0/jGl8YlzjT18a09raWhUWFkYzwuEMuODUsjzP4/H0meDkdrvl8Xhi/gcHPYMxjT+MaXxiXOMPYxqfGNf40xfHtDNbeGgOAQAAAAAdIDgBAAAAQAcITgAAAADQgQG3xwkAAADoT0zTVDAYVCgUinUpPSIQCMhms6mpqemofCa73S6r1drt1yE4AQAAAH2U3+/XgQMH5PV6Y11KjzFNU7m5udqzZ89Rua+qYRgqKChQUlJSt16H4AQAAAD0QeFwWDt37pTValV+fr4cDsdRCRq9LRwOq76+XklJSR3edLa7TNPUwYMHtXfvXo0cObJbM08EJwAAAKAP8vv9CofDKiwslNvtjnU5PSYcDsvv98vlcvV6cJKkrKws7dq1S4FAoFvBieYQAAAAQB92NMJFPOupWTpGAQAAAAA6QHACAAAAgA4QnAAAAAD0WUOHDtVDDz0U6zJoDgEAAACgZ02bNk2TJk3qkcDz7rvvKjExsftFdRPBKcZM01TIjHUVAAAAwNHTclNfh8PR4bVZWVlHoaKOsVQvhv64eqfO/OV/9X55/+/HDwAAgN5lmqa8/mBMvkyz8//SP3fuXK1cuVK/+tWvZBiGDMPQokWLZBiGXnnlFZ144onKycnR6tWrtX37dl144YXKyclRUlKSTjzxRC1fvrzV631xqZ5hGPrDH/6giy66SG63WyNHjtS//vWvnvoxHxIzTjFU0xjQ3uomfRAHNzIDAABA72oMhDTmztdi8t6fLJgpt6Nz0eFXv/qVtmzZonHjxmnBggWSpI0bN0qSbr31Vt1///3Kzs5WYWGh9u3bp3PPPVf/93//J6fTqSeffFIXXHCBNm/erMGDBx/yPe655x7df//9+vnPf65f//rXuuKKK7R7926lp6d3/8MeAjNOMXTu+FxJ0qZqQ/W+YIyrAQAAALovJSVFDodDbrdbubm5ys3Njd54dsGCBTr77LM1bNgwpaena+LEifrOd76jcePGaeTIkbr33ntVVFTU4QzS3Llzddlll2nEiBG67777VF9fr3feeadXPxczTjE0KidZQzPc2lXh1cot5Zp9fGGsSwIAAEAflWC36pMFM2P23j3hhBNOaPW4vr5ed999t5YsWaIDBw4oGAyqsbFRxcXFh32dCRMmRL9PTEyUx+NRWVlZj9R4KASnGDIMQ7PG5ujxVTv16sZSghMAAAAOyTCMTi+X66u+2B3vRz/6kZYtW6Zf/OIXGjFihBISEvS1r31Nfr//sK9jt9tbPTYMQ+FwuMfr/TyW6sXYzDE5kqSVWw6q0R+KcTUAAABA9zkcDoVCHf+37Ztvvqm5c+fqoosu0vjx45Wbm6tdu3b1foFdQHCKsbH5yUp3mmoMhLVyS2R6MRAK6z+by7TwlU3aUloX4woBAACAIzN06FC9/fbb2rVrl8rLyw85GzRy5Eg9//zz2rBhgz744ANdfvnlvT5z1FUEpxgzDEMT0yPtHX/26mb9vz++rVPue11XP/Gufrtyhy585E29uGFfjKsEAAAAOu9HP/qRrFarxowZo6ysrEPuWfrlL3+ptLQ0TZ06VRdccIFmzpyp448//ihX2zn9e5FknDguI6z/HLBoZ3mDdpY3SJIyEh3KS3Xp4321+uEzG/TJ/lrdes5oGbQuBwAAQB93zDHHaM2aNa2OzZ07V5JazSgNHTpUb7zxRqvrrr/++laPv7h0r717SlVXV3e92E4iOPUBQ5KlRy+bqIP1ASW77MpLcenEYemyGIYeXLZFj/xnm367aoeSXTbdcObIWJcLAAAADDgEpz5ixpicNt1BJOlHM0cp2+PUnS9u1C+WblGOx6Wvn0D3PQAAAOBoYo9TP3DVlKH63rQiSdKtz3+kT0tqY1wRAAAAMLAQnPqJW2aO0rRRWQqFTf393b2xLgcAAAAYUAhO/YRhGLpqyhBJ0r8+2K9gqG+2aQQAAEDPaq8ZAjqvp35+BKd+5LSRWcpIdKi83qfV28pjXQ4AAAB6Ucv+d6/XG+NK+je/3y9Jslqt3XodmkP0I3arRRdMzNeit3bphfX7NG1UdqxLAgAAQC+xWq1KTU1VWVmZJMntdsfFrWnC4bD8fr+amppksfTuPE44HNbBgwfldrtls3Uv+hCc+pnZxw3Sord26bWNJar3BZXkZAgBAADiVW5uriRFw1M8ME1TjY2NSkhIOCpB0GKxaPDgwd1+L/6ru5+ZWJCi4ZmJ2lHeoNc+LtHFkwtiXRIAAAB6iWEYysvLU3Z2tgKBQKzL6RGBQECrVq3S6aef3u7teHqaw+HokZktglM/YxiGvjIpXw8t36rlm0oJTgAAAAOA1Wrt9h6dvsJqtSoYDMrlch2V4NRTaA7RD500LF2S9NG+mhhXAgAAAAwMBKd+aNygFEnS3qpGVTX4Y1wNAAAAEP8ITv2Qx2XXsMxEScw6AQAAAEcDwamfapl1IjgBAAAAvY/g1E+NH+SRJH20l+AEAAAA9DaCUz81flCqJGacAAAAgKOB4NRPjW2ecdpXTYMIAAAAoLcRnPopGkQAAAAARw/BqR8bT4MIAAAA4KggOPVj0eBEgwgAAACgVxGc+jFakgMAAABHB8GpHxuT91mDCK8/GONqAAAAgPhFcOrHUtx2eVw2SdLeqsYYVwMAAADEL4JTP1eY7pYkFVd4Y1wJAAAAEL8ITv3c4ObgtKeK4AQAAAD0FoJTP9cy47SnkqV6AAAAQG8hOPVzhWkJkphxAgAAAHoTwamfK4jOOBGcAAAAgN5CcOrnCtM+C06maca4GgAAACA+EZz6uYLmpXoN/pCqvIEYVwMAAADEJ4JTP+eyW5XjcUpiuR4AAADQWwhOcSC6XI8GEQAAAECvIDjFAVqSAwAAAL2L4BQHWlqSF7NUDwAAAOgVBKc40NKSfC9L9QAAAIBeQXCKA59vSQ4AAACg5xGc4sDgjEhw2lfdqFCYezkBAAAAPS2mwWnhwoU68cQTlZycrOzsbM2ePVubN2/u8Hn/+Mc/NHr0aLlcLo0fP14vv/zyUai278r1uGS3GgqETJXWNsW6HAAAACDuxDQ4rVy5Utdff73Wrl2rZcuWKRAIaMaMGWpoaDjkc9566y1ddtll+ta3vqX169dr9uzZmj17tj7++OOjWHnfYrUYyk+lQQQAAADQW2yxfPNXX3211eNFixYpOztb69at0+mnn97uc371q19p1qxZuvnmmyVJ9957r5YtW6ZHHnlEjz/+eK/X3FcVpCVod4VX+6tpSQ4AAAD0tJgGpy+qqamRJKWnpx/ymjVr1mjevHmtjs2cOVOLFy9u93qfzyefzxd9XFtbK0kKBAIKBALdrLj7Wmrobi1ZiQ5J0oFqb5/4XANZT40p+g7GND4xrvGHMY1PjGv86UtjeiQ19JngFA6HdeONN+rUU0/VuHHjDnldSUmJcnJyWh3LyclRSUlJu9cvXLhQ99xzT5vjS5culdvt7l7RPWjZsmXden7dQYski975cLMK6jb1TFHolu6OKfoexjQ+Ma7xhzGNT4xr/OkLY+r1dn6bS58JTtdff70+/vhjrV69ukdf97bbbms1Q1VbW6vCwkLNmDFDHo+nR9+rKwKBgJYtW6azzz5bdru9y69T+tZuvb5/sxIz83TuuRN7sEIcqZ4aU/QdjGl8YlzjD2ManxjX+NOXxrRlNVpn9IngdMMNN+ill17SqlWrVFBQcNhrc3NzVVpa2upYaWmpcnNz273e6XTK6XS2OW6322M+UJ/X3Xrym+/lVF4f6FOfayDra3/G0H2MaXxiXOMPYxqfGNf40xfG9EjeP6Zd9UzT1A033KAXXnhBb7zxhoYNG9bhc6ZMmaLXX3+91bFly5ZpypQpvVVmv5Cd7JIkldXRjhwAAADoaTGdcbr++uv11FNP6cUXX1RycnJ0n1JKSooSEiLtta+66ioNGjRICxculCT98Ic/1BlnnKEHHnhA5513np555hm99957+t3vfhezz9EXZCdHZtVKa30yTVOGYcS4IgAAACB+xHTG6bHHHlNNTY2mTZumvLy86Nezzz4bvaa4uFgHDhyIPp46daqeeuop/e53v9PEiRP13HPPafHixYdtKDEQZHsiwakxEFK9LxjjagAAAID4EtMZJ9M0O7xmxYoVbY59/etf19e//vVeqKj/cjtsSnbaVOcLqqzOp2QXa4ABAACAnhLTGSf0rCxPy3I99jkBAAAAPYngFEda9jkdrPN1cCUAAACAI0FwiiM5nubOerUEJwAAAKAnEZziyGed9ViqBwAAAPQkglMc+exeTsw4AQAAAD2J4BRHWlqScxNcAAAAoGcRnOJIdMaJPU4AAABAjyI4xZHPZpwITgAAAEBPIjjFkZauevW+oLz+YIyrAQAAAOIHwSmOJDltcjuskliuBwAAAPQkglOcoSU5AAAA0PMITnEm20NLcgAAAKCnEZziTMuME8EJAAAA6DkEpzjzWUtyluoBAAAAPYXgFGdyaEkOAAAA9DiCU5zJTIoEp/J6ghMAAADQUwhOcSY90SFJqvL6Y1wJAAAAED8ITnEmrSU4NQRiXAkAAAAQPwhOcSbdHQlOlQ3MOAEAAAA9heAUZ9IS7ZKkxkBIjf5QjKsBAAAA4gPBKc4kOW2yWw1J7HMCAAAAegrBKc4YhhFtEMFyPQAAAKBnEJziUJqbznoAAABATyI4xSFmnAAAAICeRXCKQ5+1JCc4AQAAAD2B4BSHoi3JvdzLCQAAAOgJBKc4xIwTAAAA0LMITnEo3R25l1MlzSEAAACAHkFwikMtM06V9QQnAAAAoCcQnOJQS1c92pEDAAAAPYPgFIda7uNEO3IAAACgZxCc4tDnZ5xM04xxNQAAAED/R3CKQy0zToGQqXpfMMbVAAAAAP0fwSkOJTisSrBbJUlVDdzLCQAAAOguglOcalmuR0tyAAAAoPsITnEqLTFyLyduggsAAAB0H8EpTtFZDwAAAOg5BKc4xb2cAAAAgJ5DcIpTzDgBAAAAPYfgFKeYcQIAAAB6DsEpTqUlMuMEAAAA9BSCU5zKaJlx4j5OAAAAQLcRnOJUdI8TS/UAAACAbiM4xanoHieW6gEAAADdRnCKU9Eb4Hr9CofNGFcDAAAA9G8EpzjVslQvbEq1TexzAgAAALqD4BSn7FaLkl02SXTWAwAAALqL4BTHuJcTAAAA0DMITnEs2lmPluQAAABAtxCc4hid9QAAAICeQXCKY9zLCQAAAOgZBKc4lt7ckpzmEAAAAED3EJziWFpiyx4nghMAAADQHQSnOJbuZo8TAAAA0BMITnEsOuPEHicAAACgWwhOcYyuegAAAEDPIDjFsc/u40RwAgAAALqD4BTHWmacapuCCoTCMa4GAAAA6L8ITnEsJcEuw4h8X+0NxLYYAAAAoB8jOMUxq8VQakLkXk5VNIgAAAAAuozgFOe4lxMAAADQfQSnOMe9nAAAAIDuIzjFuXTu5QQAAAB0G8EpznEvJwAAAKD7CE5x7rM9TnTVAwAAALqK4BTnonucWKoHAAAAdBnBKc7RVQ8AAADoPoJTnEtP5D5OAAAAQHcRnOJcmpsZJwAAAKC7CE5xjq56AAAAQPcRnOJcyx6nBn9ITYFQjKsBAAAA+qeYBqdVq1bpggsuUH5+vgzD0OLFiw97/YoVK2QYRpuvkpKSo1NwP5TstMlmMSRJ1V5akgMAAABdEdPg1NDQoIkTJ+rRRx89oudt3rxZBw4ciH5lZ2f3UoX9n2EYdNYDAAAAuskWyzc/55xzdM455xzx87Kzs5WamtrzBcWpdLdDB+t8dNYDAAAAuiimwamrJk2aJJ/Pp3Hjxunuu+/WqaeeeshrfT6ffD5f9HFtba0kKRAIKBCI/dK1lhp6s5ZUd2SYy2q8feIzx7ujMaY4uhjT+MS4xh/GND4xrvGnL43pkdRgmKZp9mItnWYYhl544QXNnj37kNds3rxZK1as0AknnCCfz6c//OEP+stf/qK3335bxx9/fLvPufvuu3XPPfe0Of7UU0/J7Xb3VPl92hNbLNpQYdHFQ0M6Pa9PDDcAAAAQc16vV5dffrlqamrk8XgOe22/Ck7tOeOMMzR48GD95S9/afd8ezNOhYWFKi8v7/CHczQEAgEtW7ZMZ599tux2e6+8x93/3qS/vbNH108brhvPGtEr74HPHI0xxdHFmMYnxjX+MKbxiXGNP31pTGtra5WZmdmp4NQvl+p93kknnaTVq1cf8rzT6ZTT6Wxz3G63x3ygPq8368lMdkmSqhqDfeozx7u+9mcM3ceYxifGNf4wpvGJcY0/fWFMj+T9+/19nDZs2KC8vLxYl9GnZSY1d9WrpzkEAAAA0BUxnXGqr6/Xtm3boo937typDRs2KD09XYMHD9Ztt92mffv26cknn5QkPfTQQxo2bJjGjh2rpqYm/eEPf9Abb7yhpUuXxuoj9AvpiZEZN9qRAwAAAF0T0+D03nvv6ctf/nL08bx58yRJc+bM0aJFi3TgwAEVFxdHz/v9fs2fP1/79u2T2+3WhAkTtHz58lavgbYymmecyht8HVwJAAAAoD0xDU7Tpk3T4XpTLFq0qNXjW265RbfccksvVxV/MrgBLgAAANAt/X6PEzqW3hycqr0BBULhGFcDAAAA9D8EpwEg1e2QxYh8X+Vl1gkAAAA4UgSnAcBqMZTmjsw6VdBZDwAAADhiBKcBoqVBBPucAAAAgCNHcBogWvY5ldfTWQ8AAAA4UgSnASIjiXs5AQAAAF1FcBogaEkOAAAAdB3BaYD4bKkewQkAAAA4UgSnAeKzpXrscQIAAACOFMFpgGhZqkc7cgAAAODIEZwGCPY4AQAAAF1HcBogWu7jRDtyAAAA4MgRnAaIjMTIHqfapqD8wXCMqwEAAAD6F4LTAJGSYJfVYkiSqrws1wMAAACOBMFpgLBYDKW57ZJoEAEAAAAcKYLTANKyXI8GEQAAAMCRITgNIC03wa3gXk4AAADAESE4DSAtnfVYqgcAAAAcGYLTAJLBjBMAAADQJQSnASQjiT1OAAAAQFcQnAaQlj1O5SzVAwAAAI4IwWkAyWyecSqvZ6keAAAAcCQITgNIjicSnMpqCU4AAADAkSA4DSDZHpckqayuSaZpxrgaAAAAoP8gOA0gWc1L9QIhU1XeQIyrAQAAAPoPgtMA4rBZog0iSmubYlwNAAAA0H8QnAaY7OTmfU517HMCAAAAOovgNMDkNO9zYsYJAAAA6LwuBac///nPWrJkSfTxLbfcotTUVE2dOlW7d+/useLQ86IzTgQnAAAAoNO6FJzuu+8+JSQkSJLWrFmjRx99VPfff78yMzN100039WiB6Fk50c56LNUDAAAAOsvWlSft2bNHI0aMkCQtXrxYF198sa699lqdeuqpmjZtWk/Whx6W3XwvJ5bqAQAAAJ3XpRmnpKQkVVRUSJKWLl2qs88+W5LkcrnU2NjYc9Whx2UnM+MEAAAAHKkuzTidffbZuuaaa3Tcccdpy5YtOvfccyVJGzdu1NChQ3uyPvSwHE/LHieCEwAAANBZXZpxevTRRzVlyhQdPHhQ//znP5WRkSFJWrdunS677LIeLRA9Kzu6x6lJpmnGuBoAAACgf+jSjFNqaqoeeeSRNsfvueeebheE3pWVFJlxCoRMVXkD0RviAgAAADi0Ls04vfrqq1q9enX08aOPPqpJkybp8ssvV1VVVY8Vh57nsFmiYYkGEQAAAEDndCk43XzzzaqtrZUkffTRR5o/f77OPfdc7dy5U/PmzevRAtHzovdyokEEAAAA0CldWqq3c+dOjRkzRpL0z3/+U+eff77uu+8+vf/++9FGEei7sj0ufVpSx4wTAAAA0EldmnFyOBzyer2SpOXLl2vGjBmSpPT09OhMFPqunOYZp4PMOAEAAACd0qUZpy996UuaN2+eTj31VL3zzjt69tlnJUlbtmxRQUFBjxaInpfT3FmPGScAAACgc7o04/TII4/IZrPpueee02OPPaZBgwZJkl555RXNmjWrRwtEz8tuvpcTwQkAAADonC7NOA0ePFgvvfRSm+MPPvhgtwtC78tObrmXE0v1AAAAgM7oUnCSpFAopMWLF2vTpk2SpLFjx+orX/mKrFZrjxWH3tEy41RWS3ACAAAAOqNLwWnbtm0699xztW/fPo0aNUqStHDhQhUWFmrJkiUqKirq0SLRs1r2OJXVNck0TRmGEeOKAAAAgL6tS3ucfvCDH6ioqEh79uzR+++/r/fff1/FxcUaNmyYfvCDH/R0jehhWUmRGadAyFRlgz/G1QAAAAB9X5dmnFauXKm1a9cqPT09eiwjI0M//elPdeqpp/ZYcegdDptF2clOldX5tK+6URnNQQoAAABA+7o04+R0OlVXV9fmeH19vRwOR7eLQu8blJYgSdpX1RjjSgAAAIC+r0vB6fzzz9e1116rt99+W6ZpyjRNrV27Vt/97nf1la98padrRC8YlNocnKoJTgAAAEBHuhScHn74YRUVFWnKlClyuVxyuVyaOnWqRowYoYceeqiHS0RvaJlx2suMEwAAANChLu1xSk1N1Ysvvqht27ZF25Efe+yxGjFiRI8Wh95TwIwTAAAA0GmdDk7z5s077Pn//Oc/0e9/+ctfdr0iHBUFaW5JzDgBAAAAndHp4LR+/fpOXcc9gfqHz5pDeGNcCQAAAND3dTo4fX5GCf1fS3OI2qag6poCSnbZY1wRAAAA0Hd1qTkE+r9Ep02p7khYYp8TAAAAcHgEpwEs2pKcfU4AAADAYRGcBrCW4ESDCAAAAODwCE4DWEtnPZbqAQAAAIdHcBrAPuusR3ACAAAADofgNIBFl+ox4wQAAAAcFsFpACtgxgkAAADoFILTANYy41Re71NTIBTjagAAAIC+i+A0gKW67XI7rJJoEAEAAAAcDsFpADMMg+V6AAAAQCcQnAY47uUEAAAAdIzgNMANTo/cy6m40hvjSgAAAIC+i+A0wA3JSJQk7SpviHElAAAAQN9FcBrghmU2B6cKghMAAABwKASnAW5IRmSp3u4Kr0zTjHE1AAAAQN9EcBrgCtLcsloMNQZCKqvzxbocAAAAoE8iOA1wDpsl2lmPfU4AAABA+whO0FD2OQEAAACHRXCChjbvc9pVQUtyAAAAoD0xDU6rVq3SBRdcoPz8fBmGocWLF3f4nBUrVuj444+X0+nUiBEjtGjRol6vM97RkhwAAAA4vJgGp4aGBk2cOFGPPvpop67fuXOnzjvvPH35y1/Whg0bdOONN+qaa67Ra6+91suVxrdhmcw4AQAAAIdji+Wbn3POOTrnnHM6ff3jjz+uYcOG6YEHHpAkHXvssVq9erUefPBBzZw5s7fKjHstM067KxpkmqYMw4hxRQAAAEDfEtPgdKTWrFmj6dOntzo2c+ZM3XjjjYd8js/nk8/3WZvt2tpaSVIgEFAgEOiVOo9ESw2xrCU3yS6LIXn9Ie2valB2sjNmtcSDvjCm6FmMaXxiXOMPYxqfGNf405fG9Ehq6FfBqaSkRDk5Oa2O5eTkqLa2Vo2NjUpISGjznIULF+qee+5pc3zp0qVyu929VuuRWrZsWUzfP81hVYXP0LNLXleRJ6alxI1Yjyl6HmManxjX+MOYxifGNf70hTH1eju/VaVfBaeuuO222zRv3rzo49raWhUWFmrGjBnyeGKfEAKBgJYtW6azzz5bdrs9ZnX84+A6rd5WodyRE3Xu5EExqyMe9JUxRc9hTOMT4xp/GNP4xLjGn740pi2r0TqjXwWn3NxclZaWtjpWWloqj8fT7myTJDmdTjmdbZee2e32mA/U58W6nmGZSVq9rUJ7q5v61M+lP4v1mKLnMabxiXGNP4xpfGJc409fGNMjef9+dR+nKVOm6PXXX291bNmyZZoyZUqMKoof3AQXAAAAOLSYBqf6+npt2LBBGzZskBRpN75hwwYVFxdLiiyzu+qqq6LXf/e739WOHTt0yy236NNPP9VvfvMb/f3vf9dNN90Ui/LjSktL8h0HCU4AAADAF8U0OL333ns67rjjdNxxx0mS5s2bp+OOO0533nmnJOnAgQPRECVJw4YN05IlS7Rs2TJNnDhRDzzwgP7whz/QirwHjMhKliTtKG9QMBSOcTUAAABA3xLTPU7Tpk2TaZqHPL9o0aJ2n7N+/fperGpgKkhLkMtuUVMgrOJKr4ZnJcW6JAAAAKDP6Fd7nNB7LBZDI7IjYWlrWX2MqwEAAAD6FoIToo7JjizX20ZwAgAAAFohOCFqRE5kxmlLaV2MKwEAAAD6FoITokY2zzhtLWXGCQAAAPg8ghOijmmecdp+sF6h8KGbdgAAAAADDcEJUQVpbjltFvmCYe2p9Ma6HAAAAKDPIDghymoxVJRFZz0AAADgiwhOaOUYGkQAAAAAbRCc0MrIHFqSAwAAAF9EcEIrn90ElxknAAAAoAXBCa0c87kZpzCd9QAAAABJBCd8weB0txw2i5oCYRXTWQ8AAACQRHDCF1gtho7Njcw6fby/JsbVAAAAAH0DwQltjB2UIkn6aB/BCQAAAJAITmjH+ObgtHFfbYwrAQAAAPoGghPaGP+5GSfTpEEEAAAAQHBCGyNzkmS3GqppDGhvVWOsywEAAABijuCENpw2q0a1NIhgnxMAAABAcEL7xuXTIAIAAABoQXBCu8Y173P6eD8NIgAAAACCE9rV0iDiYxpEAAAAAAQntG9UbrJsFkOVDX4dqGmKdTkAAABATBGc0C6X3aqROZEGEexzAgAAwEBHcMIhjR/kkSRt2FMd20IAAACAGCM44ZBOGJouSXp3Z2WMKwEAAABii+CEQzp5WCQ4fbC3Wk2BUIyrAQAAAGKH4IRDGpzuVo7HqUDI1Pri6liXAwAAAMQMwQmHZBiGTmxZrreL5XoAAAAYuAhOOKyW5XrvsM8JAAAAAxjBCYd10rAMSdK63VUKhMIxrgYAAACIDYITDmtkdpJS3XY1BkL6mPs5AQAAYIAiOOGwLBZDJwxhuR4AAAAGNoITOsQ+JwAAAAx0BCd0aEpRZJ/TW9sr1Ojnfk4AAAAYeAhO6NDYfI8K0hLUGAhp5ZayWJcDAAAAHHUEJ3TIMAydMy5XkvTKxyUxrgYAAAA4+ghO6JRZ4/IkSa9vKpMvyHI9AAAADCwEJ3TKcYWpyvW4VO8LavXW8liXAwAAABxVBCd0isViaFbzcr2XP2K5HgAAAAYWghM6rSU4Ld9UqkAoHONqAAAAgKOH4IROO3FoujKTHKppDGjN9opYlwMAAAAcNQQndJrVYmjG2JbuegdiXA0AAABw9BCccETObe6ut3RjqYIs1wMAAMAAQXDCETl5eLpS3XZVNPj1zq7KWJcDAAAAHBUEJxwRu9WiGWNyJEmvcjNcAAAADBAEJxyxc5qX6736cYnCYTPG1QAAAAC9j+CEIzZ1RIaSXTaV1fn0fnFVrMsBAAAAeh3BCUfMabNq+rGR5XqLN+yLcTUAAABA7yM4oUu+NrlAkrR4/X41+IIxrgYAAADoXQQndMmU4Rkalpmoel9Q//pgf6zLAQAAAHoVwQldYrEYuuLkwZKkv67dLdOkSQQAAADiF8EJXXbx8QVy2CzauL9WH+ytiXU5AAAAQK8hOKHL0hIdOn9CpDX5X9fujnE1AAAAQO8hOKFbrjxliCTpxQ37VFzhjXE1AAAAQO8gOKFbjh+cptOPyVIgZOqBZZtjXQ4AAADQKwhO6LZbZo6SJL24Yb8+3sdeJwAAAMQfghO6bdygFF04KV+SdP9rzDoBAAAg/hCc0CPmnz1KdquhVVsO6o1PS2NdDgAAANCjCE7oEYMz3Lr61GGSpJ8s3qgGXzDGFQEAAAA9h+CEHnPj9JEqSEvQvupGPbB0S6zLAQAAAHoMwQk9xu2w6f8uGi9JWvTWTn2wpzq2BQEAAAA9hOCEHnXGMVmaPSlfYVO688WPFQ6bsS4JAAAA6DaCE3rc7ecdqySnTR/srdFz7++NdTkAAABAtxGc0OOyk136/pkjJEn3v7pZdU2BGFcEAAAAdA/BCb3i6lOHaVhmosrrfXr49a2xLgcAAADoFoITeoXDZtFPzj9WkvTH1Tv11vbyGFcEAAAAdB3BCb3mzNE5+trkAoVN6QdPb1BZbVOsSwIAAAC6hOCEXnXvheM0OjdZ5fU+3fD0egVD4ViXBAAAABwxghN6VYLDqkevOF6JDqve2VmpB5ZxY1wAAAD0PwQn9LqirCT97GsTJEmPrdiu1zeVxrgiAAAA4MgQnHBUnD8hX3OmDJEkzfv7B9pT6Y1xRQAAAEDn9Yng9Oijj2ro0KFyuVw6+eST9c477xzy2kWLFskwjFZfLpfrKFaLrrr9vGM1sSBFNY0BffvJ97i/EwAAAPqNmAenZ599VvPmzdNdd92l999/XxMnTtTMmTNVVlZ2yOd4PB4dOHAg+rV79+6jWDG6ymmz6jdXTlZWslOfltTpur+9rwDNIgAAANAPxDw4/fKXv9S3v/1tXX311RozZowef/xxud1u/elPfzrkcwzDUG5ubvQrJyfnKFaM7hiUmqA/zTlRCXar/ru1XHe88JFM04x1WQAAAMBh2WL55n6/X+vWrdNtt90WPWaxWDR9+nStWbPmkM+rr6/XkCFDFA6Hdfzxx+u+++7T2LFj273W5/PJ5/NFH9fW1kqSAoGAAoHYLxVrqaEv1HK0jM5x68FLxuu6pzbo7+/tlcdl0y0zRsowjFiX1iMG4pjGO8Y0PjGu8YcxjU+Ma/zpS2N6JDUYZgz/uX///v0aNGiQ3nrrLU2ZMiV6/JZbbtHKlSv19ttvt3nOmjVrtHXrVk2YMEE1NTX6xS9+oVWrVmnjxo0qKChoc/3dd9+te+65p83xp556Sm63u2c/EI7ImlJDz+ywSpLOKwxpRgEzTwAAADh6vF6vLr/8ctXU1Mjj8Rz22n4XnL4oEAjo2GOP1WWXXaZ77723zfn2ZpwKCwtVXl7e4Q/naAgEAlq2bJnOPvts2e32WJdz1P3pzV1a+Grk3k7XTxuuH55Z1O9nngb6mMYjxjQ+Ma7xhzGNT4xr/OlLY1pbW6vMzMxOBaeYLtXLzMyU1WpVaWnr+/qUlpYqNze3U69ht9t13HHHadu2be2edzqdcjqd7T4v1gP1eX2tnqPlO9NGyh+SHli2RY+u2KHSOr8WfnW87NaYb7/rtoE6pvGMMY1PjGv8YUzjE+Maf/rCmB7J+8f0v04dDocmT56s119/PXosHA7r9ddfbzUDdTihUEgfffSR8vLyeqtM9LLvnzVSC786XlaLoefW7dWsh1bp3x/sVzjM0j0AAAD0DTH/Z/158+bp97//vf785z9r06ZN+t73vqeGhgZdffXVkqSrrrqqVfOIBQsWaOnSpdqxY4fef/99XXnlldq9e7euueaaWH0E9IDLThqs3181Waluu7YfbND3n16vCx99UzvLG2JdGgAAABDbpXqSdOmll+rgwYO68847VVJSokmTJunVV1+NthgvLi6WxfJZvquqqtK3v/1tlZSUKC0tTZMnT9Zbb72lMWPGxOojoIecOTpH/73ly3rizV36/X936KN9NTr/4f/qvq+O14WTBsW6PAAAAAxgMQ9OknTDDTfohhtuaPfcihUrWj1+8MEH9eCDDx6FqhALyS67fnDWSF1yQqF+8Mx6vbOzUj98ZoPWF1frjvOOjYu9TwAAAOh/+K9Q9Em5KS49dc3J+v6ZIyRJi97apav++I4q6n0dPBMAAADoeQQn9Fk2q0XzZ4zS41dOltth1ZodFTrzgZX681u7FAyFY10eAAAABhCCE/q8WeNy9cJ1p2p0brJqGgO6618bdd7Dq/XW9vJYlwYAAIABguCEfmFUbrJe+v6XdO/scUp127W5tE6X//5tXfe3ddpb5Y11eQAAAIhzBCf0GzarRf/vlCH6z/xp+n+nDJHFkF7+qERnPbBSDy7bonpfMNYlAgAAIE4RnNDvpCU6dO/scVryg9N0yvB0+YJh/er1rTr+3mW65s/vacmHB2Sa3DwXAAAAPYfghH7r2DyPnv72KXr08uM1PDNR/mBYyzeV6vqn3teVf3xbu7h5LgAAAHpIn7iPE9BVhmHovAl5Ond8rjaX1ulfG/brj6t36s1tFZrx0CqdOy5XF08u0NSiTFktRqzLBQAAQD9FcEJcMAxDo3M9Gj3Lo0tPLNQdL3ys1dvKtXjDfi3esF/piQ6dOTpbF0zM1xnHZMW6XAAAAPQzLNVD3BmSkai/fOskPX/dVF15ymClJNhV2eDXc+v2as6f3tENT72vqgZ/rMsEAABAP8KME+KSYRg6fnCajh+cprsuGKt3d1Xq5Y8O6Ol39uilDw/ore0VGp2bLI/LrtwUlwrSEjSxMFUnDk2PdekAAADogwhOiHt2q0VTizI1tShTl5xQqHl//0Dbyur11vaKNteePyFP93xlrDKSnDGoFAAAAH0VwQkDyoSCVC35wZf09o5KVXn9qmkMaH91k3aW12v5pjK99OEBrd5WrvGDUpSR6NAxucmaWpSpcfke2aysbAUAABioCE4YcJw2q05vp0HER3trdPNzH+jTkjr9d2v5585sVrLLppOHZeiU4ekalpmoHI9LI7KT5LJbj17hAAAAiBmCE9BsfEGK/nXDl/T2zgqV1vp0sM6n9cVVWrujQrVNQS3fVKrlm0qj1yc7bbrwuHxddNwgjchKlifBJsOg5TkAAEA8IjgBn+OwWXTayNazUaGwqU/21+qt7eV6b3eVDtQ0al9Vo6q8Af11bbH+urZYkpTssmliQaomD05RuFbyBUKy2+2x+BgAAADoYQQnoANWi6HxBSkaX5Ci7zQfC4dNrdlRoaffKdbaHRUqr/errimo1dvKtXpbuSSbHv/0DY3O9SjBYZXTZtGYPI9OHZGpE4emK8HBEj8AAID+hOAEdIHFYujUEZk6dUSmJKnRH9LO8gat212ptdsr9N/NB1QbkD7aVxN9zn+3luu3q3bIYbXo+CGpOmFIupJdNrnsVhVlJWlCYYo8LmaoAAAA+iKCE9ADEhxWjcn3aEy+R984YZCWLNmrsaecoV2VPgVCYdU1BfTuriq9ta1c+2uatHZHpdbuqGz1GoYhDc1I1PDMRA3NTNSwzMj3w7ISletxsX8KAAAghghOQC9oCUEjc1Ojxy49cbBM09TO8ga9ub1Cn+yvlS8YUn1TUJ8cqNXeqkbtLG/QzvKGNq+XYI8Es1ljc3XaMZmqqPdrd4VX6YkOjc33qCAtgWAFAADQiwhOwFFkGIaGZyVpeFZSm3MH63zaWlqnHc3haWd5g3aVN6i40qvGQEjrdldp3e4q6eW2r5uSYNfYfI/G5Hk0NDNRg9PdSnXb5bBZlOiwKT3RIbfDSrgCAADoIoIT0EdkJTuVlezU1OZ9Uy0CobCKK716c1u5lnx4QB/urVFeqkuD090qq/Vpa1mdahoDemt7hd7aXnHI13c7rDpucKqmFmUqM8mh2sagTJkqTHOrMN2tlAS7EhxWpbkdsloIWAAAAJ9HcAL6OLvVoqKsJBVlJemqKUPbnPcFQ9paWq9P9tdqU0mt9lR6VVzpVX1TUP5QWPW+oJoCYXn9Ib25rUJvbjt0uJKkRIdVEwtTNSo3WQ6bRQ6rRSOykzSpMFWD093MWgEAgAGJ4AT0c06bVeMGpWjcoJRDXuP1B7WnslFrd1Ro7Y4K+YJheVw2hUxpT6VXe6sa1eALqjEQUoM/dMjZqwS7VQVpCc1fbuV4nNpf06RtpfVy2i2aWpSpU4ana1BqgjKSnLJaDJmmqbAphU1ThiSb1dKLPw0AAIDeQXACBgC3w6ZRuckalZusOVOHHvK6YCisbQfrtb64WrsqGhQKmfIGQvpkf60+2V+rxkBIW8vqtbWsvt3n/3drefR7w5AMSWHzs/NWi6EJBSmaWpShlAS7Gv1hJTgsGp3r0cicJFkNQ8Gwqcwkpxw2AhYAAOg7CE4AomzWSIgZnetpc84fDGtfdaP2Vnm1r6pRe6sadaCmSbkpTh2Tk6yqBr9WbyvXh3trVF7vU9iUzC+8Rihsan1xtdYXVx+2DqfNogkFKRqSkSivPyivPySrYchutchus8huMZSV7NRZx+Zo8pA09mQBAIBeR3AC0CkOm0XDmu8vdShzTx0mKRKQKhv8CpumLIYhq8WQ1TBU0xjQ2p0VendnpUJhUy6HVTXegDYdqNWuigYZhiFDki8Y1ru7qvTurqrD1vTbVTuU6rYryWlTOGzK7bQpM8mhvJQEjc5N1ug8j3I9LqUl2mUxDHl9IfmCIdmsFlkM6UBNk/ZUeuW0W3VsbrKGZSaylBAAALSL4ASgx1mbZ4S+KMVt1+AMty45obDNOdM0ZRiRPVE7yhu0bneVDtb5lOyyKcFuVdg05Q+ZCobC8gfD2lxap+WflKraG1C1NxB9nW1lXa/bMCS33aoER+TLbbfJZjUUCptqrLfqv76NmlCYqrH5KTo2L1kJdqsO1vl0oKZJ1Y0B1TcFNSI7ScfkJNFEAwCAOENwAtAntAQNwzCiXQQ74g+GtelAbXRmq8EX1MF6n/ZUerXpQJ22lNaposGvKq9fphlpye6wWRQKmQqGTWV7nCpMc8vrD+rTkjp5/ZHmGA3+UHsVavf7+/Tc+/skSRYj0vHQFwy3uXJwultThmco2+NUmtshm9WQYRhKdtqU1nxPraZASP5gWDarRXarocHpbg1K5UbGAAD0VQQnAP2Ww2bRxMLUDq8LN3eosBxmL1Q4bKq8wadGf0iNgZC8/pAa/SEFw6ZCoaD+u+ZdufNHalNJvT7eV6OyOp98wbAshpTjcSnV7ZDLbtHG/bUqbm4Jf6RyPS5NKkzVsKxEZSU5tXF/rdYXV8lmNXRMTrJG5yZrVK5HI7OTIgEwbMpptyg1wSGHzSLTNOULhlXl9auywS+X3arB6W7ZWX4IAEC3EZwAxL3DBabPX5Od7Gr3XCAQUN0WU+eeNUJ2u12SVFbXJF8grNwUV6tg0uAL6r9bD2pzSb3K632q8kb2eoXDUm1TQJUNfvmCYTltFjlsFgVDppqCIe2u8Kqktkmvbixpt4YtpfV66cMDh6zfbjUUCH2xHYdksxjK8bhksxqyGIbG5Ht05qhsJTptemdnpfZWeTWxMFVTizI0KC1BCXarbBaLQqapUMhUyDQVNk15XHY6HQIABjSCEwB0waFCVqLTplnj8jRr3JG9ntcf1IY91dp0oE67KxpUUtOkY3KSNXlomiRpc0ld9GtHeb3CYcliiTTSME21Ck1Wi6E0tyPakXBfdWP03M7yBi35QgBb+klpp2rMTHIo2WWXLxCSKWlkTrImFaQoPzVBCQ6rAiFTe6u8OljnU2aSU4PSEuSyW+UPhuWwWVSUlaiirCS57NYj++EAANAHEJwAoA9wO2yaWpSpqUWZ7Z7/8qjsdo+Hw6bqmoLyBoKyWyOzWEkOmyzNNx8uqW3SgZommabkC4S0ZkeFVmw+qEAorMlD0jQkw633dlXp3V2Vqvpck432lNf7VV7vjz4+UNOkVVsOHtHnNAwp3e1QZpJTpkxVNkTe8+Rh6ZpSlKFcj0tuh1UyImEwHDYjbeithhw2i+xWi7KTncr2RIJrSU2T3tlVqbwUlyYWpDIrBgDoNQQnAOjHLBZDKW67UmRvc84wDOWlJCgvJSF6bOqITM2fMarVddeeHvnflj1SwbApm8WItpK3GFKVN6ADNY1q8IXkslsUDJvauL9WH+2tVmWDP3KvLYuhgrQEZSU5dbDer33VjQo0zzY1+ILaWlavmsaAKhr8qmjwt6phyUcHtOSjQy9F/KLMJKdSEmzafrAhesxlt2hoRqIMw5DDamh4VpKOyUmWyx5p4uELhOULhmQY0vhBqZpUkBx9bkvI3F3hjba0T3Tyf5EAgM/w/woAAEmRoHWoZXTpiQ6lJzpaHTt+cJqkIZ1+fdM0VV7v18E6n8rrfbJZDKU2Lyl8c1uF3ttdqdqmoBr9QUmRroUWw1AgFJa/uQ29PxhWeb0v+mUY0th8jw5UN6miwa9PS+qi7/fB3poOa0qwWvXzTavU4A+1mXGzGJLNYlGCw6pcj0s5KS6lJtiV7LLJbo004zAlmWbk2lG5Hp0wNE0WQ9pcUq+6poAmFqZqVE5yh/vsgqGwLIbRqf14AIDYIDgBAI4Kw4jc36u9e3ydMDS906/T6A9pU0mtKur9mjwkTemJDpmmqa1l9SqtbZIkef0hbS2t09ay+kj3QZtVTrtFTptFTYGw1u2u1JbSejWGDO2tjjzHajE0KDVBVV6/6pqCCpuKBLbGsGoaA9pcWne4sg4pyWlTgsOqYCgsp82qVLddiU6b6puCqm0KqLYxoAZ/SKluu6Ydk6UTh6Wr0R9SRYNfFkNy2axKcds1KDUh2uhDktx2m5JcNiU6rXLaIoE3HDZV5wsqyWmT9RAhLBAKa29VowxJQw9zQ2sAQGsEJwBAv5LgsDbPdn3GMCIt24/J+Wz53cyxuYd9nYpar/758jIdd9JUJTgdGpH9WeOK2qaAmprb0df7giqpaVJJbZNqGwOqawoqFDZlGJIReXP5giF9uKdGG/ZUy2JEGmckOq3aUFytel9Q9b5g87sGVNIc7r6o2hvQ4g37tXjD/iP+mTisFjntFtX7gjJNKdlp03FD0pTncWl3ZYP2VzcpEIosw6xs8CvU3KL/uMGpuuSEQpmmtLfKK7fDqqKsJBWmu+WyW+WyW5Tj+axzZDgcWc6Z4KDBB4CBh+AEABiQPAl25SRIkwpTo23mo+dcdnlcnx37fCA7nHBLoGq+kXEwFNaO8gYFQ6bsVkNNgch9trz+kJJdtsj7JNiU7LJr+8F6vb6pTJsO1CrVbVeaO7I00hcMqbLBr71VjSqt9UkyZZpSU+CzmzX7m5cztqjzBQ/buCPBblUgFNb64mqtL64+7GeyWQwNyXDLlLS3qlH+YFhJTpuyPc7IEkaPSxbDUJXXr3pfUE6bpfnLGvlfuyU645fsjHxWKTLzleyyaUJBqkZmJ8nG/cYA9HEEJwAAesgX9yjZrJZOh670xHSdeARLFiUpFDbV4A+qvimoxsBnYWxbWb3W7a5SZYNfQzLckRkkm1WGIWUlO5Wd7NTBep/+/u4evfFpmVLdDhWkJajeF9T2snrtr2mSPxhWoz8kfyjcqgmHpMgs2sGgdnzheFfZLEbznjbJ0jyVZ5qSPxhWyDRVmJagYZmJCpvSwTqfwqapkTnJKspKbHUftWAwpO37DPk37FduqlvZyS5lJTsjnRo/x2IY7XZgDIcjTULSEx20zQfQBsEJAIB+ymox2syOSdK4QSkaNyjlsM/NTnbphjNH6oYzRx7ympYgsf1gvayGocJ0t1Lcdh2s86m0tkmltU0qqfHJlKmMRIcSnTYFQi0dDCNdDFu+bwyEVNcUUL0vKEOG7FZDZXU+fbi3RvW+oILh0CHr2FXh1a4Kb6tjn28E8oWfiv5V/PFhP7skDU53a1JhqlLddlU2RLpAbi6pk9cfksWQhmQkKj/VpQR7ZI9agt2iBLtVLodVCfbIl9thlctubT5vbf9882M7M2pAv0dwAgAA7bJYDOWnJig/NaHVcY/LrqKspB55j5ZwFgpHliCGTVNh05TFMOS0WxQ2pd0VDdpV7pXNGmkwYpqmtpTWa1d5g8KmKUOGDEMyzbC279ojR0qmKuoDKqtrOuT9yYorvSqu9LY5bjGksBm5WfTO8p6ZUZMis2qfD1Yue/O+MVNKdFiVnuhQSoJdTptVdpuhQNCUPxSW22FVjselvBSXRuYka0i6WwdqImE2FDaVmeRUssumxkBITYHIbQFsFouSnDalJzmU8bnZs1Dzz9qQlOtx0cUROEIEJwAAEDMt4exwBqUmaGpR62Nnjs5pc10gENDLL+/WueeeEN235g+23v8lRW4G/cmBWn2wp1qNgZDSEyPLF4/NS9bQjERVev3aWlqv8nqfGv0hef2haDBpbP6+8fPf+5vPff5487nmPhwKNnc8rIs2Cjl63A6rUhLsqqj3R38WDptFQ9LdGpKRqKEZbiW77LJZIzOBNktk2WRjIKxGf1AOm0XJLruSnDYlu2xKctrktEduSJ3mdig3xSWvL6S1Oyu06UCtMpKcKkxLUGG6W4NSE1j2iLhBcAIAAHHLYbO02c+U5LTptJFZOm1kVrvPyU52KTvZ1e33Ns3IrFGTP7JU0esPRgNYUyDc3JnRUL0vqKoGv2qbAvIFwwqEwrJbLXJYLarzBVVW26TiSq+2NIe5lAS7RmQnyWG1qLzepwZfUC6HVS6bVWHTVCAUVr0vqMoGvwIhU97m8CdJ9uZ29v5gWFvL6rW1rL7bn7O5F4pMs/3zOR6nCtPcyk9NiLTTN9V8DzRT4ebvDUkZSQ7lpbhktVhU1xRQKGwqN8WlzES73jtoaN/qnUpwRGY781Jcqm0Kqq4poByPS8OzEmW3WHSw3qeDdb7ozzElwa4cj0tpbnu0aQvQVQQnAACAXmAYRnN3QatSZO/4CZ3Q6A/JZbd0KgSYZmSWq7Ler+rGgDKTHMpLSZBpmjpQ06Sd5Q3aXdGg3RVeeQMhBUNhBUOmAuHIcsmWvVr+YCSI1TZF2vE3+ILyN+9lq2z4bBarKCtRkwrTVNPo157KRu2p8srrD6m01hfpCLm7qhuf3Cpt23rosxZDVsNoM7vYwmG1KNvjVI7HpVyPS9kepzISHUpxO2Rt7gpZ1xSM3PjaapHdYshmtagxENLeKq8O1vmUl+LS8KwkZSc7leS0yW6zRBqoBMMakZ2k0bnJagyEtG53lcrr/ZpUmKqirMRWYxUOR8I0s3D9E8EJAACgnziSe2gZRvvNQ6RIo4/CdLek9mfdOiscNlXp9TfPGLW+ubVpmtFW+nuqvDpQ3RTZk9Y809bSut9QZG/bwXqfSmuaFDalJJdNhqSSmiYdqGlUoKFGxw4dJF8orB0HG1RW55MnwaZEh037qhsj91eTKUtz50iX3SqrxVCNN6CK5nC3t6pRe6sau/V5D8dlt8gfDEeXZ0pSeqJDHpdNpqSG5lnAsCmluu3Kbb6hdTBkKsFhVV6KSxmJTpkyFQq3fEnJLptG5SZrSIZbobCppkC4edYyJIthKC0xMsYt+SzJaVdmUqRZSyhsKhg2FW7+30SnVW5H6//89wfDKqtrUqrboSQn0eBw+OkAAACgSywWQ5lfCEwtDMNQRpJTGUlOTSxM7fJ7RPauvaxzzx3f5p5rUiSgldb6FAiFlZviatPB0BcMNXeC/KwbZGmtT1UNflU3Rm4Inep2yOOyK2yaCoabZ95Cphw2iwrSEpSV5NT+mkbtLG9QZUPknmX+YFiJzkjA++RAreqaIvvXBqe7leNx6oO9Naps8Kuywd+m5mpvQNVfaFyyvss/oSPjskf2rBmKNAyp9PplmpHGKGPyPRqd65EUCbMeV+Secr5gSCU1TfIFwxqZk6RROckKm1JNY0Dbyur1wd5qldY2aXRussYNStHwrCQVpiUo2+OSu7nzpNPWuZnSvozgBAAAgH7LMAzlphx6T5rTZlVBmlsFae5eqyEcNrWzokFuh1V5KZFmJ02BkLaU1inQvHwwwW5TZpJDDptFJc3hzTRN2SwW1fuCKqlpVGWDX5bmZYcWiyGrxVB5nU+bS+u0r6pRDptFTnukPb7LblUobKrK61dtYzA641TbGDhkN8lIXWE1BXytjtkshoJhUx/vq9XH+2oP/2E/OvSpvVWNWr6prN1zFkNKdNjkdlrltlsVaLLqxNN8yk/vmWWsRwPBCQAAAOgGi8Vo06LfZbdqQkFqu9enuh0andt79QRCkYYkdouluUV9ZGmk1x9SZYM/OjtmsUhZSU6lJzpUUtukd3dVqbiiQVaLRYbREsL8clgtyk1JkM1i6NOSOm0rq5PDZlFKgl0FaW5NLExRridBn5ZEgldxZYP2VDaq0uuXPxgJjmFTX+gsGQmG/QnBCQAAAIgjdqul3ZsuJzptSjzEPqa8lAR9ZeLhbw3QkSlFGW2OBUNheZvb9Df4gvL6Q6r1+rTyzbXyuPpXFOlf1QIAAADoN2xWizxWS6smJYFAQAc/MWVrJ9z1Zf2rWgAAAACIAYITAAAAAHSA4AQAAAAAHSA4AQAAAEAHCE4AAAAA0AGCEwAAAAB0gOAEAAAAAB0gOAEAAABABwhOAAAAANABghMAAAAAdIDgBAAAAAAdIDgBAAAAQAcITgAAAADQAYITAAAAAHTAFusCjjbTNCVJtbW1Ma4kIhAIyOv1qra2Vna7PdbloAcwpvGHMY1PjGv8YUzjE+Maf/rSmLZkgpaMcDgDLjjV1dVJkgoLC2NcCQAAAIC+oK6uTikpKYe9xjA7E6/iSDgc1v79+5WcnCzDMGJdjmpra1VYWKg9e/bI4/HEuhz0AMY0/jCm8YlxjT+MaXxiXONPXxpT0zRVV1en/Px8WSyH38U04GacLBaLCgoKYl1GGx6PJ+Z/cNCzGNP4w5jGJ8Y1/jCm8YlxjT99ZUw7mmlqQXMIAAAAAOgAwQkAAAAAOkBwijGn06m77rpLTqcz1qWghzCm8YcxjU+Ma/xhTOMT4xp/+uuYDrjmEAAAAABwpJhxAgAAAIAOEJwAAAAAoAMEJwAAAADoAMEJAAAAADpAcIqhRx99VEOHDpXL5dLJJ5+sd955J9YloZPuvvtuGYbR6mv06NHR801NTbr++uuVkZGhpKQkXXzxxSotLY1hxWjPqlWrdMEFFyg/P1+GYWjx4sWtzpumqTvvvFN5eXlKSEjQ9OnTtXXr1lbXVFZW6oorrpDH41Fqaqq+9a1vqb6+/ih+CnxeR2M6d+7cNr+7s2bNanUNY9q3LFy4UCeeeKKSk5OVnZ2t2bNna/Pmza2u6czfucXFxTrvvPPkdruVnZ2tm2++WcFg8Gh+FHxOZ8Z12rRpbX5fv/vd77a6hnHtOx577DFNmDAhelPbKVOm6JVXXomej4ffU4JTjDz77LOaN2+e7rrrLr3//vuaOHGiZs6cqbKysliXhk4aO3asDhw4EP1avXp19NxNN92kf//73/rHP/6hlStXav/+/frqV78aw2rRnoaGBk2cOFGPPvpou+fvv/9+Pfzww3r88cf19ttvKzExUTNnzlRTU1P0miuuuEIbN27UsmXL9NJLL2nVqlW69tprj9ZHwBd0NKaSNGvWrFa/u08//XSr84xp37Jy5Updf/31Wrt2rZYtW6ZAIKAZM2aooaEhek1Hf+eGQiGdd9558vv9euutt/TnP/9ZixYt0p133hmLjwR1blwl6dvf/nar39f7778/eo5x7VsKCgr005/+VOvWrdN7772nM888UxdeeKE2btwoKU5+T03ExEknnWRef/310cehUMjMz883Fy5cGMOq0Fl33XWXOXHixHbPVVdXm3a73fzHP/4RPbZp0yZTkrlmzZqjVCGOlCTzhRdeiD4Oh8Nmbm6u+fOf/zx6rLq62nQ6nebTTz9tmqZpfvLJJ6Yk8913341e88orr5iGYZj79u07arWjfV8cU9M0zTlz5pgXXnjhIZ/DmPZ9ZWVlpiRz5cqVpml27u/cl19+2bRYLGZJSUn0mscee8z0eDymz+c7uh8A7friuJqmaZ5xxhnmD3/4w0M+h3Ht+9LS0sw//OEPcfN7yoxTDPj9fq1bt07Tp0+PHrNYLJo+fbrWrFkTw8pwJLZu3ar8/HwNHz5cV1xxhYqLiyVJ69atUyAQaDW+o0eP1uDBgxnffmTnzp0qKSlpNY4pKSk6+eSTo+O4Zs0apaam6oQTToheM336dFksFr399ttHvWZ0zooVK5Sdna1Ro0bpe9/7nioqKqLnGNO+r6amRpKUnp4uqXN/565Zs0bjx49XTk5O9JqZM2eqtrY2+q/hiK0vjmuLv/3tb8rMzNS4ceN02223yev1Rs8xrn1XKBTSM888o4aGBk2ZMiVufk9tsS5gICovL1coFGr1B0OScnJy9Omnn8aoKhyJk08+WYsWLdKoUaN04MAB3XPPPTrttNP08ccfq6SkRA6HQ6mpqa2ek5OTo5KSktgUjCPWMlbt/Z62nCspKVF2dnar8zabTenp6Yx1HzVr1ix99atf1bBhw7R9+3bdfvvtOuecc7RmzRpZrVbGtI8Lh8O68cYbdeqpp2rcuHGS1Km/c0tKStr9XW45h9hqb1wl6fLLL9eQIUOUn5+vDz/8UD/+8Y+1efNmPf/885IY177oo48+0pQpU9TU1KSkpCS98MILGjNmjDZs2BAXv6cEJ6ALzjnnnOj3EyZM0Mknn6whQ4bo73//uxISEmJYGYDD+cY3vhH9fvz48ZowYYKKioq0YsUKnXXWWTGsDJ1x/fXX6+OPP261pxT936HG9fN7C8ePH6+8vDydddZZ2r59u4qKio52meiEUaNGacOGDaqpqdFzzz2nOXPmaOXKlbEuq8ewVC8GMjMzZbVa23QSKS0tVW5uboyqQnekpqbqmGOO0bZt25Sbmyu/36/q6upW1zC+/UvLWB3u9zQ3N7dNQ5dgMKjKykrGup8YPny4MjMztW3bNkmMaV92ww036KWXXtJ//vMfFRQURI935u/c3Nzcdn+XW84hdg41ru05+eSTJanV7yvj2rc4HA6NGDFCkydP1sKFCzVx4kT96le/ipvfU4JTDDgcDk2ePFmvv/569Fg4HNbrr7+uKVOmxLAydFV9fb22b9+uvLw8TZ48WXa7vdX4bt68WcXFxYxvPzJs2DDl5ua2Gsfa2lq9/fbb0XGcMmWKqqurtW7duug1b7zxhsLhcPT/4NG37d27VxUVFcrLy5PEmPZFpmnqhhtu0AsvvKA33nhDw4YNa3W+M3/nTpkyRR999FGrULxs2TJ5PB6NGTPm6HwQtNLRuLZnw4YNktTq95Vx7dvC4bB8Pl/8/J7GujvFQPXMM8+YTqfTXLRokfnJJ5+Y1157rZmamtqqkwj6rvnz55srVqwwd+7cab755pvm9OnTzczMTLOsrMw0TdP87ne/aw4ePNh84403zPfee8+cMmWKOWXKlBhXjS+qq6sz169fb65fv96UZP7yl780169fb+7evds0TdP86U9/aqamppovvvii+eGHH5oXXnihOWzYMLOxsTH6GrNmzTKPO+448+233zZXr15tjhw50rzsssti9ZEGvMONaV1dnfmjH/3IXLNmjblz505z+fLl5vHHH2+OHDnSbGpqir4GY9q3fO973zNTUlLMFStWmAcOHIh+eb3e6DUd/Z0bDAbNcePGmTNmzDA3bNhgvvrqq2ZWVpZ52223xeIjwex4XLdt22YuWLDAfO+998ydO3eaL774ojl8+HDz9NNPj74G49q33HrrrebKlSvNnTt3mh9++KF56623moZhmEuXLjVNMz5+TwlOMfTrX//aHDx4sOlwOMyTTjrJXLt2baxLQiddeumlZl5enulwOMxBgwaZl156qblt27bo+cbGRvO6664z09LSTLfbbV500UXmgQMHYlgx2vOf//zHlNTma86cOaZpRlqS/+QnPzFzcnJMp9NpnnXWWebmzZtbvUZFRYV52WWXmUlJSabH4zGvvvpqs66uLgafBqZ5+DH1er3mjBkzzKysLNNut5tDhgwxv/3tb7f5ByvGtG9pbzwlmU888UT0ms78nbtr1y7znHPOMRMSEszMzExz/vz5ZiAQOMqfBi06Gtfi4mLz9NNPN9PT002n02mOGDHCvPnmm82amppWr8O49h3f/OY3zSFDhpgOh8PMysoyzzrrrGhoMs34+D01TNM0j978FgAAAAD0P+xxAgAAAIAOEJwAAAAAoAMEJwAAAADoAMEJAAAAADpAcAIAAACADhCcAAAAAKADBCcAAAAA6ADBCQAAAAA6QHACAKCTVqxYIcMwVF1dHetSAABHGcEJAAAAADpAcAIAAACADhCcAAD9Rjgc1sKFCzVs2DAlJCRo4sSJeu655yR9toxuyZIlmjBhglwul0455RR9/PHHrV7jn//8p8aOHSun06mhQ4fqgQceaHXe5/Ppxz/+sQoLC+V0OjVixAj98Y9/bHXNunXrdMIJJ8jtdmvq1KnavHlz735wAEDMEZwAAP3GwoUL9eSTT+rxxx/Xxo0bddNNN+nKK6/UypUro9fcfPPNeuCBB/Tuu+8qKytLF1xwgQKBgKRI4Lnkkkv0jW98Qx999JHuvvtu/eQnP9GiRYuiz7/qqqv09NNP6+GHH9amTZv029/+VklJSa3quOOOO/TAAw/ovffek81m0ze/+c2j8vkBALFjmKZpxroIAAA64vP5lJ6eruXLl2vKlCnR49dcc428Xq+uvfZaffnLX9YzzzyjSy+9VJJUWVmpgoICLVq0SJdccomuuOIKHTx4UEuXLo0+/5ZbbtGSJUu0ceNGbdmyRaNGjdKyZcs0ffr0NjWsWLFCX/7yl7V8+XKdddZZkqSXX35Z5513nhobG+VyuXr5pwAAiBVmnAAA/cK2bdvk9Xp19tlnKykpKfr15JNPavv27dHrPh+q0tPTNWrUKG3atEmStGnTJp166qmtXvfUU0/V1q1bFQqFtGHDBlmtVp1xxhmHrWXChAnR7/Py8iRJZWVl3f6MAIC+yxbrAgAA6Iz6+npJ0pIlSzRo0KBW55xOZ6vw1FUJCQmdus5ut0e/NwxDUmT/FQAgfjHjBADoF8aMGSOn06ni4mKNGDGi1VdhYWH0urVr10a/r6qq0pYtW3TsscdKko499li9+eabrV73zTff1DHHHCOr1arx48crHA632jMFAIDEjBMAoJ9ITk7Wj370I910000Kh8P60pe+pJqaGr355pvyeDwaMmSIJGnBggXKyMhQTk6O7rjjDmVmZmr27NmSpPnz5+vEE0/Uvffeq0svvVRr1qzRI488ot/85jeSpKFDh2rOnDn65je/qYcfflgTJ07U7t27VVZWpksuuSRWHx0A0AcQnAAA/ca9996rrKwsLVy4UDt27FBqaqqOP/543X777dGlcj/96U/1wx/+UFu3btWkSZP073//Ww6HQ5J0/PHH6+9//7vuvPNO3XvvvcrLy9OCBQs0d+7c6Hs89thjuv3223XdddepoqJCgwcP1u233x6LjwsA6EPoqgcAiAstHe+qqqqUmpoa63IAAHGGPU4AAAAA0AGCEwAAAAB0gKV6AAAAANABZpwAAAAAoAMEJwAAAADoAMEJAAAAADpAcAIAAACADhCcAAAAAKADBCcAAAAA6ADBCQAAAAA6QHACAAAAgA78f1rp9Sy8PhzUAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "config = get_config()\n",
        "\n",
        "config['train_seed'] = config['data_seed']\n",
        "\n",
        "print(\"config:\",config)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "exp = TrainMNISTCluster(config, device)\n",
        "exp.setup()\n",
        "exp.run()\n",
        "duration = (time.time() - start_time)\n",
        "print(\"---train cluster Ended in %0.2f hour (%.3f sec) \" % (duration/float(3600), duration))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deep_learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
