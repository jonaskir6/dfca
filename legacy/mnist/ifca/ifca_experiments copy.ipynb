{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OHJWesKs-tqd"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import time\n",
        "import itertools\n",
        "import pickle\n",
        "import copy\n",
        "import random\n",
        "import math\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from util import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAghP_o0-tqe"
      },
      "source": [
        "Reads Config file and prepares the arguments you can choose in the config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BbUZJ2E--tqe"
      },
      "outputs": [],
      "source": [
        "LR_DECAY = False\n",
        "def get_config():\n",
        "\n",
        "    # read config json and update the sysarg\n",
        "    with open(\"config.json\", \"r\") as read_file:\n",
        "        config = json.load(read_file)\n",
        "\n",
        "    if config[\"config_override\"] == \"\":\n",
        "        del config['config_override']\n",
        "    else:\n",
        "        print(config['config_override'])\n",
        "        config_override = json.loads(config['config_override'])\n",
        "        del config['config_override']\n",
        "        config.update(config_override)\n",
        "\n",
        "    return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-J1YEoM-tqe"
      },
      "source": [
        "Class SimpleLinear with simple MLP for MNIST Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "id5Wyt-V-tqf"
      },
      "outputs": [],
      "source": [
        "class SimpleLinear(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, h1=2048):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(28*28, h1)\n",
        "        self.fc2 = torch.nn.Linear(h1, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28 * 28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # x = F.sigmoid(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "    # def weight(self):\n",
        "    #     return self.linear1.weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qFBH01M-tqf"
      },
      "source": [
        "Class TrainMNISTCluster with all the methods needed to run the experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IkGiGQ2G-tqf"
      },
      "outputs": [],
      "source": [
        "class TrainMNISTCluster(object):\n",
        "    def __init__(self, config, device):\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        assert self.config['m'] % self.config['p'] == 0\n",
        "\n",
        "    def setup(self):\n",
        "\n",
        "        os.makedirs(self.config['project_dir'], exist_ok = True)\n",
        "\n",
        "        self.result_fname = os.path.join(self.config['project_dir'], 'results.pickle')\n",
        "        self.checkpoint_fname = os.path.join(self.config['project_dir'], 'checkpoint.pt')\n",
        "\n",
        "        self.setup_datasets()\n",
        "        self.setup_models()\n",
        "\n",
        "        self.epoch = None\n",
        "        self.lr = None\n",
        "\n",
        "\n",
        "    def setup_datasets(self):\n",
        "\n",
        "        np.random.seed(self.config['data_seed'])\n",
        "\n",
        "        # generate indices for each dataset\n",
        "        # also write cluster info\n",
        "\n",
        "        MNIST_TRAINSET_DATA_SIZE = 60000\n",
        "        MNIST_TESTSET_DATA_SIZE = 10000\n",
        "\n",
        "        np.random.seed(self.config['data_seed'])\n",
        "\n",
        "        cfg = self.config\n",
        "\n",
        "        self.dataset = {}\n",
        "\n",
        "        if cfg['uneven'] == True:\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset_random_n(MNIST_TRAINSET_DATA_SIZE, cfg['p'], cfg['m'], cfg['n'])\n",
        "            (X, y) = self._load_MNIST(train=True)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['train'] = dataset\n",
        "\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset_random_n(MNIST_TESTSET_DATA_SIZE, cfg['p'], cfg['m_test'], cfg['n'], random=True)\n",
        "            (X, y) = self._load_MNIST(train=False)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['test'] = dataset\n",
        "\n",
        "        else:\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset(MNIST_TRAINSET_DATA_SIZE, cfg['p'], cfg['m'], cfg['n'])\n",
        "            (X, y) = self._load_MNIST(train=True)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['train'] = dataset\n",
        "\n",
        "            dataset = {}\n",
        "            dataset['data_indices'], dataset['cluster_assign'] = \\\n",
        "                self._setup_dataset(MNIST_TESTSET_DATA_SIZE, cfg['p'], cfg['m_test'], cfg['n'], random=True)\n",
        "            (X, y) = self._load_MNIST(train=False)\n",
        "            dataset['X'] = X\n",
        "            dataset['y'] = y\n",
        "            self.dataset['test'] = dataset\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "    def _setup_dataset(self, num_data, p, m, n, random = True):\n",
        "\n",
        "        print(\"m:\",m)\n",
        "        print(\"p:\",p)\n",
        "        print(\"n:\",n)\n",
        "        print(\"num_data:\",num_data)\n",
        "        assert (m // p) * n == num_data\n",
        "\n",
        "        dataset = {}\n",
        "\n",
        "        cfg = self.config\n",
        "\n",
        "        data_indices = []\n",
        "        cluster_assign = []\n",
        "\n",
        "        m_per_cluster = m // p\n",
        "\n",
        "        for p_i in range(p):\n",
        "\n",
        "            if random:\n",
        "                ll = list(np.random.permutation(num_data))\n",
        "            else:\n",
        "                ll = list(range(num_data))\n",
        "\n",
        "            ll2 = chunkify(ll, m_per_cluster) # splits ll into m lists with size n\n",
        "            data_indices += ll2\n",
        "\n",
        "            cluster_assign += [p_i for _ in range(m_per_cluster)]\n",
        "\n",
        "        print(type(data_indices))\n",
        "        data_indices = np.array(data_indices)\n",
        "        cluster_assign = np.array(cluster_assign)\n",
        "        assert data_indices.shape[0] == cluster_assign.shape[0]\n",
        "        assert data_indices.shape[0] == m\n",
        "\n",
        "\n",
        "        return data_indices, cluster_assign\n",
        "\n",
        "\n",
        "    def _setup_dataset_random_n(self, num_data, p, m, n, random = True):\n",
        "\n",
        "        print(\"m:\",m)\n",
        "        print(\"p:\",p)\n",
        "        print(\"num_data:\",num_data)\n",
        "\n",
        "        dataset = {}\n",
        "\n",
        "        cfg = self.config\n",
        "\n",
        "        data_indices = []\n",
        "        cluster_assign = []\n",
        "\n",
        "        m_per_cluster = m // p\n",
        "\n",
        "        for p_i in range(p):\n",
        "\n",
        "            ll = list(np.random.permutation(num_data))\n",
        "\n",
        "            ll2 = chunkify_uneven(ll, m_per_cluster) # splits ll into m lists\n",
        "            data_indices += ll2\n",
        "\n",
        "            cluster_assign += [p_i for _ in range(m_per_cluster)]\n",
        "\n",
        "        data_indices = np.array(data_indices, dtype=object)\n",
        "        cluster_assign = np.array(cluster_assign)\n",
        "        assert data_indices.shape[0] == cluster_assign.shape[0]\n",
        "        assert data_indices.shape[0] == m\n",
        "\n",
        "\n",
        "        return data_indices, cluster_assign\n",
        "\n",
        "\n",
        "    def _load_MNIST(self, train=True):\n",
        "        transforms = torchvision.transforms.Compose([\n",
        "                               torchvision.transforms.ToTensor(),\n",
        "                               # torchvision.transforms.Normalize(\n",
        "                               #   (0.1307,), (0.3081,))\n",
        "                             ])\n",
        "        if train:\n",
        "            mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms)\n",
        "        else:\n",
        "            mnist_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms)\n",
        "\n",
        "        dl = DataLoader(mnist_dataset)\n",
        "\n",
        "        X = dl.dataset.data # (60000,28, 28)\n",
        "        y = dl.dataset.targets #(60000)\n",
        "\n",
        "        # normalize to have 0 ~ 1 range in each pixel\n",
        "\n",
        "        X = X / 255.0\n",
        "        X = X.to(self.device)\n",
        "        y = y.to(self.device)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "    # Need p models for each client\n",
        "\n",
        "    def setup_models(self):\n",
        "        np.random.seed(self.config['train_seed'])\n",
        "        torch.manual_seed(self.config['train_seed'])\n",
        "\n",
        "        p = self.config['p']\n",
        "\n",
        "        self.models = [ SimpleLinear(h1 = self.config['h1']).to(self.device) for p_i in range(p)] # p models with p different params of dimension(1,d)\n",
        "\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        num_epochs = self.config['num_epochs']\n",
        "        lr = self.config['lr']\n",
        "\n",
        "        results = []\n",
        "\n",
        "        # epoch -1\n",
        "        self.epoch = -1\n",
        "\n",
        "        result = {}\n",
        "        result['epoch'] = -1\n",
        "\n",
        "        t0 = time.time()\n",
        "        res = self.test(train=True)\n",
        "        t1 = time.time()\n",
        "        res['infer_time'] = t1-t0\n",
        "        result['train'] = res\n",
        "\n",
        "        self.print_epoch_stats(res)\n",
        "\n",
        "        t0 = time.time()\n",
        "        res = self.test(train=False)\n",
        "        t1 = time.time()\n",
        "        res['infer_time'] = t1-t0\n",
        "        result['test'] = res\n",
        "        self.print_epoch_stats(res)\n",
        "        results.append(result)\n",
        "\n",
        "        # this will be used in next epoch\n",
        "        cluster_assign = result['train']['cluster_assign']\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.epoch = epoch\n",
        "\n",
        "            result = {}\n",
        "            result['epoch'] = epoch\n",
        "\n",
        "            lr = self.lr_schedule(epoch)\n",
        "            result['lr'] = lr\n",
        "\n",
        "            t0 = time.time()\n",
        "            result['train'] = self.train(cluster_assign, lr = lr)\n",
        "            t1 = time.time()\n",
        "            train_time = t1-t0\n",
        "\n",
        "            t0 = time.time()\n",
        "            res = self.test(train=True)\n",
        "            t1 = time.time()\n",
        "            res['infer_time'] = t1-t0\n",
        "            res['train_time'] = train_time\n",
        "            res['lr'] = lr\n",
        "            result['train'] = res\n",
        "\n",
        "            self.print_epoch_stats(res)\n",
        "\n",
        "            t0 = time.time()\n",
        "            res = self.test(train=False)\n",
        "            t1 = time.time()\n",
        "            res['infer_time'] = t1-t0\n",
        "            result['test'] = res\n",
        "            self.print_epoch_stats(res)\n",
        "\n",
        "            results.append(result)\n",
        "\n",
        "            # this will be used in next epoch's gradient update\n",
        "            cluster_assign = result['train']['cluster_assign']\n",
        "\n",
        "            if epoch % 10 == 0 or epoch == num_epochs - 1 :\n",
        "                with open(self.result_fname, 'wb') as outfile:\n",
        "                    pickle.dump(results, outfile)\n",
        "                    print(f'result written at {self.result_fname}')\n",
        "                self.save_checkpoint()\n",
        "                print(f'checkpoint written at {self.checkpoint_fname}')\n",
        "\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.plot([r['train']['loss'] for r in results], label='train loss')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('loss')\n",
        "        plt.title('Training Loss per Epoch')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(self.config['project_dir'], 'train_loss.png'))\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "        plt.figure(figsize=(10,5))\n",
        "        plt.plot([r['test']['acc'] for r in results], label='test acc')\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('test accuracy')\n",
        "        plt.title('Test Accuracy per Epoch')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "        plt.savefig(os.path.join(self.config['project_dir'], 'test_acc.png'))\n",
        "\n",
        "    def lr_schedule(self, epoch):\n",
        "        if self.lr is None:\n",
        "            self.lr = self.config['lr']\n",
        "\n",
        "        if epoch % 50 == 0 and epoch != 0 and LR_DECAY:\n",
        "            self.lr = self.lr * 0.1\n",
        "\n",
        "        return self.lr\n",
        "\n",
        "\n",
        "    def print_epoch_stats(self, res):\n",
        "        if res['is_train']:\n",
        "            data_str = 'tr'\n",
        "        else:\n",
        "            data_str = 'tst'\n",
        "\n",
        "        if 'train_time' in res:\n",
        "            time_str = f\"{res['train_time']:.3f}sec(train) {res['infer_time']:.3f}sec(infer)\"\n",
        "        else:\n",
        "            time_str = f\"{res['infer_time']:.3f}sec\"\n",
        "\n",
        "        if 'lr' in res:\n",
        "            lr_str = f\" lr {res['lr']:4f}\"\n",
        "        else:\n",
        "            lr_str = \"\"\n",
        "\n",
        "        str0 = f\"Epoch {self.epoch} {data_str}: l {res['loss']:.3f} a {res['acc']:.3f} cl_acc {res['cl_acc']:.3f} clct{res['cl_ct']}{lr_str} {time_str}\"\n",
        "\n",
        "        print(str0)\n",
        "\n",
        "    def train(self, cluster_assign, lr):\n",
        "        VERBOSE = 0\n",
        "\n",
        "        cfg = self.config\n",
        "        m = cfg['m']\n",
        "        p = cfg['p']\n",
        "        tau = cfg['tau']\n",
        "\n",
        "        # run local update\n",
        "        t0 = time.time()\n",
        "\n",
        "\n",
        "        updated_models = []\n",
        "        for m_i in range(m):\n",
        "            if VERBOSE and m_i % 100 == 0: print(f'm {m_i}/{m} processing \\r', end ='')\n",
        "\n",
        "            (X, y) = self.load_data(m_i)\n",
        "\n",
        "            p_i = cluster_assign[m_i]\n",
        "            model = copy.deepcopy(self.models[p_i])\n",
        "\n",
        "            # LOCAL UPDATE PER MACHINE tau times\n",
        "            for step_i in range(tau):\n",
        "\n",
        "                y_logit = model(X)\n",
        "                loss = self.criterion(y_logit, y)\n",
        "\n",
        "                model.zero_grad()\n",
        "                loss.backward()\n",
        "                self.local_param_update(model, lr)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            updated_models.append(model)\n",
        "\n",
        "        t02 = time.time()\n",
        "        # print(f'running single ..took {t02-t01:.3f}sec')\n",
        "\n",
        "\n",
        "        t1 = time.time()\n",
        "        if VERBOSE: print(f'local update {t1-t0:.3f}sec')\n",
        "\n",
        "        # apply gradient update\n",
        "        t0 = time.time()\n",
        "\n",
        "        # CLUSTER MACHINES INTO p_i's\n",
        "        local_models = [[] for p_i in range(p)]\n",
        "        for m_i in range(m):\n",
        "            p_i = cluster_assign[m_i]\n",
        "            local_models[p_i].append(updated_models[m_i])\n",
        "\n",
        "        # NEEDS TO BE DECENTRALIZED\n",
        "        for p_i, models in enumerate(local_models):\n",
        "            if len(models) > 0:\n",
        "                # self.dec_param_update(models, self.models[p_i])\n",
        "                self.global_param_update(models, self.models[p_i])\n",
        "        t1 = time.time()\n",
        "\n",
        "        if VERBOSE: print(f'global update {t1-t0:.3f}sec')\n",
        "\n",
        "    def check_local_model_loss(self, local_models):\n",
        "        # for debugging\n",
        "        m = self.config['m']\n",
        "\n",
        "        losses = []\n",
        "        for m_i in range(m):\n",
        "            (X, y) = self.load_data(m_i)\n",
        "            y_logit = local_models[m_i](X)\n",
        "            loss = self.criterion(y_logit, y)\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        return np.array(losses)\n",
        "    \n",
        "    def get_cluster_accuracy(self, actual, pred):\n",
        "        \n",
        "        cm = confusion_matrix(actual, pred)\n",
        "\n",
        "        row_ind, col_ind = linear_sum_assignment(-cm)\n",
        "        matching = dict(zip(col_ind, row_ind))\n",
        "\n",
        "        remapped_preds = [matching[p] for p in actual]\n",
        "\n",
        "        cl_acc = np.mean(np.array(remapped_preds) == np.array(pred))\n",
        "\n",
        "        return cl_acc\n",
        "\n",
        "\n",
        "    def get_inference_stats(self, train = True):\n",
        "        cfg = self.config\n",
        "        if train:\n",
        "            m = cfg['m']\n",
        "            dataset = self.dataset['train']\n",
        "        else:\n",
        "            m = cfg['m_test']\n",
        "            dataset = self.dataset['test']\n",
        "\n",
        "        p = cfg['p']\n",
        "\n",
        "\n",
        "        num_data = 0\n",
        "        losses = {}\n",
        "        corrects = {}\n",
        "        for m_i in range(m):\n",
        "            (X, y) = self.load_data(m_i, train=train) # load batch data rotated\n",
        "\n",
        "            for p_i in range(p):\n",
        "                y_logit = self.models[p_i](X)\n",
        "                loss = self.criterion(y_logit, y) # loss of\n",
        "                n_correct = self.n_correct(y_logit, y)\n",
        "\n",
        "                # if torch.isnan(loss):\n",
        "                #     print(\"nan loss: \", dataset['data_indices'][m_i])\n",
        "\n",
        "                losses[(m_i,p_i)] = loss.item()\n",
        "                corrects[(m_i,p_i)] = n_correct\n",
        "\n",
        "            num_data += X.shape[0]\n",
        "\n",
        "        # calculate loss and cluster the machines\n",
        "        cluster_assign = []\n",
        "        for m_i in range(m):\n",
        "            machine_losses = [ losses[(m_i,p_i)] for p_i in range(p) ]\n",
        "            min_p_i = np.argmin(machine_losses)\n",
        "            cluster_assign.append(min_p_i)\n",
        "\n",
        "        # calculate optimal model's loss, acc over all models\n",
        "        min_corrects = []\n",
        "        min_losses = []\n",
        "        for m_i, p_i in enumerate(cluster_assign):\n",
        "\n",
        "            min_loss = losses[(m_i,p_i)]\n",
        "            min_losses.append(min_loss)\n",
        "\n",
        "            min_correct = corrects[(m_i,p_i)]\n",
        "            min_corrects.append(min_correct)\n",
        "\n",
        "        # print(\"losses: \", min_losses)\n",
        "        loss = np.mean(min_losses)\n",
        "        acc = np.sum(min_corrects) / num_data\n",
        "\n",
        "\n",
        "        # check cluster assignment acc\n",
        "        cl_acc = self.get_cluster_accuracy(dataset['cluster_assign'], cluster_assign)\n",
        "        cl_ct = [np.sum(np.array(cluster_assign) == p_i ) for p_i in range(p)]\n",
        "\n",
        "        # ca_t = np.array(cluster_assign)\n",
        "        # ca_acc = []\n",
        "        # portion = m / p\n",
        "        # index=0\n",
        "        # for p_i in range(1, p+1):\n",
        "        #     split = ca_t[index:int(portion*p_i)].tolist()\n",
        "        #     most_common = max(set(split), key=split.count)\n",
        "        #     count = split.count(most_common)\n",
        "        #     ca_acc.append(count / len(split))\n",
        "        #     index = int(portion*p_i)\n",
        "\n",
        "        # print(\"cluster assign acc: \", ca_acc)\n",
        "        # ca_acc = np.mean(ca_acc)\n",
        "\n",
        "        res = {} # results\n",
        "        # res['losses'] = losses\n",
        "        # res['corrects'] = corrects\n",
        "        res['cluster_assign'] = cluster_assign\n",
        "        res['num_data'] = num_data\n",
        "        res['loss'] = loss\n",
        "        res['acc'] = acc\n",
        "        res['cl_acc'] = cl_acc\n",
        "        res['cl_ct'] = cl_ct\n",
        "        res['is_train'] = train\n",
        "        # res['ca_acc'] = ca_acc\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "        return res\n",
        "\n",
        "    def n_correct(self, y_logit, y):\n",
        "        _, predicted = torch.max(y_logit.data, 1)\n",
        "        correct = (predicted == y).sum().item()\n",
        "\n",
        "        return correct\n",
        "\n",
        "    # TODO Does every Cluster get 4 clients with the same data, but rotated differently?\n",
        "\n",
        "    def load_data(self, m_i, train=True):\n",
        "        # this part is very fast since its just rearranging models\n",
        "        cfg = self.config\n",
        "\n",
        "        if train:\n",
        "            dataset = self.dataset['train']\n",
        "        else:\n",
        "            dataset = self.dataset['test']\n",
        "\n",
        "        indices = dataset['data_indices'][m_i]\n",
        "        p_i = dataset['cluster_assign'][m_i]\n",
        "\n",
        "        X_batch = dataset['X'][indices]\n",
        "        y_batch = dataset['y'][indices]\n",
        "\n",
        "        # k : how many times rotate 90 degree\n",
        "        # k =1 : 90 , k=2 180, k=3 270\n",
        "\n",
        "        if cfg['p'] == 4:\n",
        "            k = p_i\n",
        "        elif cfg['p'] == 2:\n",
        "            k = (p_i % 2) * 2\n",
        "        elif cfg['p'] == 1:\n",
        "            k = 0\n",
        "        else:\n",
        "            raise NotImplementedError(\"only p=1,2,4 supported\")\n",
        "\n",
        "        X_batch2 = torch.rot90(X_batch, k=int(k), dims = (1,2))\n",
        "        X_batch3 = X_batch2.reshape(-1, 28 * 28)\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "        return X_batch3, y_batch\n",
        "\n",
        "\n",
        "    def local_param_update(self, model, lr):\n",
        "\n",
        "        # gradient update manually\n",
        "\n",
        "        for name, param in model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                param.data -= lr * param.grad\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        # import ipdb; ipdb.set_trace() # we need to check the output of name, check if duplicate exists\n",
        "\n",
        "\n",
        "    def global_param_update(self, local_models, global_model):\n",
        "\n",
        "        # average of each weight\n",
        "\n",
        "        weights = {}\n",
        "\n",
        "        for m_i, local_model in enumerate(local_models):\n",
        "            for name, param in local_model.named_parameters():\n",
        "                if name not in weights:\n",
        "                    weights[name] = torch.zeros_like(param.data)\n",
        "\n",
        "                weights[name] += param.data\n",
        "\n",
        "        for name, param in global_model.named_parameters():\n",
        "            weights[name] /= len(local_models)\n",
        "            param.data = weights[name]\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "\n",
        "    def dec_param_update(self, local_models, global_model):\n",
        "\n",
        "        num_clients = len(local_models)\n",
        "\n",
        "        if num_clients == 0:\n",
        "            return\n",
        "\n",
        "        if num_clients == 1:\n",
        "            bc_client = dict(local_models[0].named_parameters())\n",
        "            for name, param in global_model.named_parameters():\n",
        "                param.data = bc_client[name].data.clone()\n",
        "            return\n",
        "\n",
        "        max_e = 100\n",
        "        if num_clients <= max_e:\n",
        "            e = num_clients - 1\n",
        "        else:\n",
        "            e = min(max_e, int(np.log(num_clients) * 10))\n",
        "\n",
        "        if e >= num_clients:\n",
        "            e = num_clients - 1\n",
        "\n",
        "        client_indices = list(range(num_clients))\n",
        "\n",
        "        for m_i, local_model in enumerate(local_models):\n",
        "            selected_clients = random.sample([i for i in client_indices if i != m_i], e)\n",
        "\n",
        "            for m_j in selected_clients:\n",
        "\n",
        "                m_j_params = dict(local_models[m_j].named_parameters())\n",
        "\n",
        "                for name, param in local_model.named_parameters():\n",
        "                    m_i_param = param.data.clone()\n",
        "                    m_j_param = m_j_params[name].data.clone()\n",
        "                    param.data = (m_i_param + m_j_param) / 2\n",
        "\n",
        "        bc_client = random.choice(client_indices)\n",
        "        bc_client_params = dict(local_models[bc_client].named_parameters())\n",
        "        for name, param in global_model.named_parameters():\n",
        "            param.data = bc_client_params[name].data.clone()\n",
        "\n",
        "        # import ipdb; ipdb.set_trace()\n",
        "\n",
        "\n",
        "    def test(self, train=False):\n",
        "        return self.get_inference_stats(train=train)\n",
        "\n",
        "    def save_checkpoint(self):\n",
        "        models_to_save = [model.state_dict() for model in self.models]\n",
        "        torch.save({'models':models_to_save}, self.checkpoint_fname)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ADsUSUi-tqf"
      },
      "source": [
        "Running the Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T_XDv25r-tqf",
        "outputId": "1dda7e5a-27bd-46d0-c125-b6987383650d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "config: {'m': 1200, 'm_test': 200, 'p': 4, 'n': 200, 'uneven': True, 'h1': 200, 'num_epochs': 300, 'batch_size': 100, 'tau': 10, 'lr': 0.1, 'data_seed': 10, 'train_seed': 10, 'project_dir': 'output'}\n",
            "Using device: cuda\n",
            "m: 1200\n",
            "p: 4\n",
            "num_data: 60000\n",
            "len:  60000\n",
            "len:  60000\n",
            "len:  60000\n",
            "len:  60000\n",
            "m: 200\n",
            "p: 4\n",
            "num_data: 10000\n",
            "len:  10000\n",
            "len:  10000\n",
            "len:  10000\n",
            "len:  10000\n",
            "Epoch -1 tr: l 2.294 a 0.113 cl_acc 0.562 clct[346, 317, 154, 383] 3.632sec\n",
            "Epoch -1 tst: l 2.292 a 0.114 cl_acc 0.575 clct[53, 69, 22, 56] 0.586sec\n",
            "Epoch 0 tr: l 2.170 a 0.391 cl_acc 0.873 clct[304, 413, 175, 308] lr 0.100000 7.866sec(train) 3.146sec(infer)\n",
            "Epoch 0 tst: l 2.168 a 0.394 cl_acc 0.850 clct[49, 73, 25, 53] 0.553sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 1 tr: l 1.909 a 0.643 cl_acc 0.997 clct[302, 297, 301, 300] lr 0.100000 7.904sec(train) 3.496sec(infer)\n",
            "Epoch 1 tst: l 1.905 a 0.650 cl_acc 0.995 clct[50, 51, 49, 50] 0.583sec\n",
            "Epoch 2 tr: l 1.566 a 0.737 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.682sec(train) 3.325sec(infer)\n",
            "Epoch 2 tst: l 1.559 a 0.747 cl_acc 1.000 clct[50, 50, 50, 50] 0.563sec\n",
            "Epoch 3 tr: l 1.256 a 0.777 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.915sec(train) 3.393sec(infer)\n",
            "Epoch 3 tst: l 1.245 a 0.788 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "Epoch 4 tr: l 1.027 a 0.805 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.767sec(train) 3.388sec(infer)\n",
            "Epoch 4 tst: l 1.016 a 0.814 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 5 tr: l 0.871 a 0.824 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.857sec(train) 2.836sec(infer)\n",
            "Epoch 5 tst: l 0.860 a 0.832 cl_acc 1.000 clct[50, 50, 50, 50] 0.512sec\n",
            "Epoch 6 tr: l 0.764 a 0.836 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.776sec(train) 3.527sec(infer)\n",
            "Epoch 6 tst: l 0.753 a 0.844 cl_acc 1.000 clct[50, 50, 50, 50] 0.588sec\n",
            "Epoch 7 tr: l 0.687 a 0.845 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.688sec(train) 3.048sec(infer)\n",
            "Epoch 7 tst: l 0.677 a 0.853 cl_acc 1.000 clct[50, 50, 50, 50] 0.536sec\n",
            "Epoch 8 tr: l 0.630 a 0.852 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.807sec(train) 3.513sec(infer)\n",
            "Epoch 8 tst: l 0.620 a 0.861 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 9 tr: l 0.587 a 0.858 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.817sec(train) 3.209sec(infer)\n",
            "Epoch 9 tst: l 0.577 a 0.866 cl_acc 1.000 clct[50, 50, 50, 50] 0.547sec\n",
            "Epoch 10 tr: l 0.552 a 0.863 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.005sec(train) 3.503sec(infer)\n",
            "Epoch 10 tst: l 0.543 a 0.870 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 11 tr: l 0.524 a 0.867 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.911sec(train) 3.314sec(infer)\n",
            "Epoch 11 tst: l 0.516 a 0.875 cl_acc 1.000 clct[50, 50, 50, 50] 0.558sec\n",
            "Epoch 12 tr: l 0.501 a 0.871 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.140sec(train) 3.517sec(infer)\n",
            "Epoch 12 tst: l 0.493 a 0.879 cl_acc 1.000 clct[50, 50, 50, 50] 0.472sec\n",
            "Epoch 13 tr: l 0.482 a 0.874 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.870sec(train) 3.237sec(infer)\n",
            "Epoch 13 tst: l 0.474 a 0.882 cl_acc 1.000 clct[50, 50, 50, 50] 0.567sec\n",
            "Epoch 14 tr: l 0.465 a 0.877 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.146sec(train) 3.267sec(infer)\n",
            "Epoch 14 tst: l 0.458 a 0.884 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "Epoch 15 tr: l 0.451 a 0.879 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.984sec(train) 3.287sec(infer)\n",
            "Epoch 15 tst: l 0.444 a 0.886 cl_acc 1.000 clct[50, 50, 50, 50] 0.583sec\n",
            "Epoch 16 tr: l 0.439 a 0.881 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.057sec(train) 3.357sec(infer)\n",
            "Epoch 16 tst: l 0.432 a 0.888 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 17 tr: l 0.428 a 0.883 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.992sec(train) 3.239sec(infer)\n",
            "Epoch 17 tst: l 0.421 a 0.889 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "Epoch 18 tr: l 0.418 a 0.885 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.134sec(train) 3.254sec(infer)\n",
            "Epoch 18 tst: l 0.412 a 0.891 cl_acc 1.000 clct[50, 50, 50, 50] 0.475sec\n",
            "Epoch 19 tr: l 0.410 a 0.886 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.945sec(train) 3.282sec(infer)\n",
            "Epoch 19 tst: l 0.404 a 0.892 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 20 tr: l 0.402 a 0.888 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.172sec(train) 3.104sec(infer)\n",
            "Epoch 20 tst: l 0.397 a 0.894 cl_acc 1.000 clct[50, 50, 50, 50] 0.475sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 21 tr: l 0.395 a 0.889 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.540sec(train) 3.392sec(infer)\n",
            "Epoch 21 tst: l 0.390 a 0.895 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 22 tr: l 0.389 a 0.890 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.794sec(train) 2.834sec(infer)\n",
            "Epoch 22 tst: l 0.384 a 0.897 cl_acc 1.000 clct[50, 50, 50, 50] 0.530sec\n",
            "Epoch 23 tr: l 0.383 a 0.891 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.659sec(train) 3.521sec(infer)\n",
            "Epoch 23 tst: l 0.378 a 0.898 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 24 tr: l 0.378 a 0.892 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.750sec(train) 3.029sec(infer)\n",
            "Epoch 24 tst: l 0.373 a 0.899 cl_acc 1.000 clct[50, 50, 50, 50] 0.537sec\n",
            "Epoch 25 tr: l 0.373 a 0.893 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.669sec(train) 3.506sec(infer)\n",
            "Epoch 25 tst: l 0.369 a 0.899 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "Epoch 26 tr: l 0.368 a 0.894 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.515sec(train) 3.203sec(infer)\n",
            "Epoch 26 tst: l 0.364 a 0.900 cl_acc 1.000 clct[50, 50, 50, 50] 0.534sec\n",
            "Epoch 27 tr: l 0.364 a 0.895 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.001sec(train) 3.512sec(infer)\n",
            "Epoch 27 tst: l 0.360 a 0.901 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 28 tr: l 0.360 a 0.896 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.035sec(train) 3.210sec(infer)\n",
            "Epoch 28 tst: l 0.357 a 0.901 cl_acc 1.000 clct[50, 50, 50, 50] 0.534sec\n",
            "Epoch 29 tr: l 0.356 a 0.897 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.017sec(train) 3.474sec(infer)\n",
            "Epoch 29 tst: l 0.353 a 0.902 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 30 tr: l 0.353 a 0.898 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.019sec(train) 3.208sec(infer)\n",
            "Epoch 30 tst: l 0.350 a 0.903 cl_acc 1.000 clct[50, 50, 50, 50] 0.535sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 31 tr: l 0.350 a 0.898 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.007sec(train) 3.500sec(infer)\n",
            "Epoch 31 tst: l 0.347 a 0.904 cl_acc 1.000 clct[50, 50, 50, 50] 0.583sec\n",
            "Epoch 32 tr: l 0.346 a 0.899 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.071sec(train) 3.213sec(infer)\n",
            "Epoch 32 tst: l 0.344 a 0.904 cl_acc 1.000 clct[50, 50, 50, 50] 0.535sec\n",
            "Epoch 33 tr: l 0.343 a 0.900 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.007sec(train) 3.513sec(infer)\n",
            "Epoch 33 tst: l 0.341 a 0.905 cl_acc 1.000 clct[50, 50, 50, 50] 0.531sec\n",
            "Epoch 34 tr: l 0.341 a 0.900 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.020sec(train) 3.217sec(infer)\n",
            "Epoch 34 tst: l 0.338 a 0.905 cl_acc 1.000 clct[50, 50, 50, 50] 0.539sec\n",
            "Epoch 35 tr: l 0.338 a 0.901 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.035sec(train) 3.438sec(infer)\n",
            "Epoch 35 tst: l 0.336 a 0.906 cl_acc 1.000 clct[50, 50, 50, 50] 0.472sec\n",
            "Epoch 36 tr: l 0.335 a 0.901 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.019sec(train) 3.235sec(infer)\n",
            "Epoch 36 tst: l 0.333 a 0.907 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 37 tr: l 0.333 a 0.902 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.045sec(train) 3.351sec(infer)\n",
            "Epoch 37 tst: l 0.331 a 0.907 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 38 tr: l 0.330 a 0.903 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.043sec(train) 3.268sec(infer)\n",
            "Epoch 38 tst: l 0.329 a 0.907 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 39 tr: l 0.328 a 0.903 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.180sec(train) 3.163sec(infer)\n",
            "Epoch 39 tst: l 0.327 a 0.908 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 40 tr: l 0.326 a 0.904 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.981sec(train) 3.308sec(infer)\n",
            "Epoch 40 tst: l 0.325 a 0.908 cl_acc 1.000 clct[50, 50, 50, 50] 0.583sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 41 tr: l 0.324 a 0.904 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.050sec(train) 3.072sec(infer)\n",
            "Epoch 41 tst: l 0.323 a 0.909 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "Epoch 42 tr: l 0.322 a 0.905 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.103sec(train) 3.385sec(infer)\n",
            "Epoch 42 tst: l 0.321 a 0.909 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 43 tr: l 0.320 a 0.905 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.391sec(train) 2.954sec(infer)\n",
            "Epoch 43 tst: l 0.319 a 0.910 cl_acc 1.000 clct[50, 50, 50, 50] 0.501sec\n",
            "Epoch 44 tr: l 0.318 a 0.906 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.634sec(train) 3.512sec(infer)\n",
            "Epoch 44 tst: l 0.318 a 0.911 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 45 tr: l 0.316 a 0.906 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.760sec(train) 3.024sec(infer)\n",
            "Epoch 45 tst: l 0.316 a 0.911 cl_acc 1.000 clct[50, 50, 50, 50] 0.537sec\n",
            "Epoch 46 tr: l 0.314 a 0.907 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.046sec(train) 3.504sec(infer)\n",
            "Epoch 46 tst: l 0.314 a 0.911 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "Epoch 47 tr: l 0.312 a 0.907 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.956sec(train) 3.081sec(infer)\n",
            "Epoch 47 tst: l 0.313 a 0.912 cl_acc 1.000 clct[50, 50, 50, 50] 0.531sec\n",
            "Epoch 48 tr: l 0.311 a 0.908 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.106sec(train) 3.477sec(infer)\n",
            "Epoch 48 tst: l 0.311 a 0.912 cl_acc 1.000 clct[50, 50, 50, 50] 0.583sec\n",
            "Epoch 49 tr: l 0.309 a 0.908 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.935sec(train) 3.096sec(infer)\n",
            "Epoch 49 tst: l 0.310 a 0.913 cl_acc 1.000 clct[50, 50, 50, 50] 0.534sec\n",
            "Epoch 50 tr: l 0.307 a 0.909 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.107sec(train) 3.510sec(infer)\n",
            "Epoch 50 tst: l 0.308 a 0.913 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 51 tr: l 0.306 a 0.909 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.928sec(train) 3.195sec(infer)\n",
            "Epoch 51 tst: l 0.307 a 0.914 cl_acc 1.000 clct[50, 50, 50, 50] 0.533sec\n",
            "Epoch 52 tr: l 0.304 a 0.910 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.115sec(train) 3.515sec(infer)\n",
            "Epoch 52 tst: l 0.305 a 0.914 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 53 tr: l 0.303 a 0.910 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.928sec(train) 3.200sec(infer)\n",
            "Epoch 53 tst: l 0.304 a 0.914 cl_acc 1.000 clct[50, 50, 50, 50] 0.534sec\n",
            "Epoch 54 tr: l 0.301 a 0.910 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.251sec(train) 3.498sec(infer)\n",
            "Epoch 54 tst: l 0.303 a 0.915 cl_acc 1.000 clct[50, 50, 50, 50] 0.582sec\n",
            "Epoch 55 tr: l 0.300 a 0.911 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.330sec(train) 3.206sec(infer)\n",
            "Epoch 55 tst: l 0.301 a 0.915 cl_acc 1.000 clct[50, 50, 50, 50] 0.533sec\n",
            "Epoch 56 tr: l 0.298 a 0.911 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.822sec(train) 3.501sec(infer)\n",
            "Epoch 56 tst: l 0.300 a 0.916 cl_acc 1.000 clct[50, 50, 50, 50] 0.516sec\n",
            "Epoch 57 tr: l 0.297 a 0.912 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.630sec(train) 3.226sec(infer)\n",
            "Epoch 57 tst: l 0.299 a 0.916 cl_acc 1.000 clct[50, 50, 50, 50] 0.583sec\n",
            "Epoch 58 tr: l 0.295 a 0.912 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.820sec(train) 3.089sec(infer)\n",
            "Epoch 58 tst: l 0.298 a 0.917 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "Epoch 59 tr: l 0.294 a 0.912 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.678sec(train) 3.360sec(infer)\n",
            "Epoch 59 tst: l 0.296 a 0.917 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "Epoch 60 tr: l 0.293 a 0.913 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.750sec(train) 2.842sec(infer)\n",
            "Epoch 60 tst: l 0.295 a 0.917 cl_acc 1.000 clct[50, 50, 50, 50] 0.536sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 61 tr: l 0.291 a 0.913 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.008sec(train) 3.536sec(infer)\n",
            "Epoch 61 tst: l 0.294 a 0.918 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 62 tr: l 0.290 a 0.914 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.128sec(train) 2.939sec(infer)\n",
            "Epoch 62 tst: l 0.293 a 0.918 cl_acc 1.000 clct[50, 50, 50, 50] 0.536sec\n",
            "Epoch 63 tr: l 0.289 a 0.914 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.007sec(train) 3.519sec(infer)\n",
            "Epoch 63 tst: l 0.292 a 0.918 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 64 tr: l 0.287 a 0.914 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.102sec(train) 3.045sec(infer)\n",
            "Epoch 64 tst: l 0.291 a 0.918 cl_acc 1.000 clct[50, 50, 50, 50] 0.536sec\n",
            "Epoch 65 tr: l 0.286 a 0.915 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.075sec(train) 3.509sec(infer)\n",
            "Epoch 65 tst: l 0.290 a 0.919 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 66 tr: l 0.285 a 0.915 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.101sec(train) 3.088sec(infer)\n",
            "Epoch 66 tst: l 0.289 a 0.919 cl_acc 1.000 clct[50, 50, 50, 50] 0.532sec\n",
            "Epoch 67 tr: l 0.284 a 0.915 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.022sec(train) 3.499sec(infer)\n",
            "Epoch 67 tst: l 0.288 a 0.920 cl_acc 1.000 clct[50, 50, 50, 50] 0.567sec\n",
            "Epoch 68 tr: l 0.282 a 0.916 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.035sec(train) 3.153sec(infer)\n",
            "Epoch 68 tst: l 0.287 a 0.920 cl_acc 1.000 clct[50, 50, 50, 50] 0.534sec\n",
            "Epoch 69 tr: l 0.281 a 0.916 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.041sec(train) 3.478sec(infer)\n",
            "Epoch 69 tst: l 0.285 a 0.920 cl_acc 1.000 clct[50, 50, 50, 50] 0.583sec\n",
            "Epoch 70 tr: l 0.280 a 0.917 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.068sec(train) 3.239sec(infer)\n",
            "Epoch 70 tst: l 0.284 a 0.921 cl_acc 1.000 clct[50, 50, 50, 50] 0.551sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 71 tr: l 0.279 a 0.917 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.182sec(train) 3.535sec(infer)\n",
            "Epoch 71 tst: l 0.283 a 0.921 cl_acc 1.000 clct[50, 50, 50, 50] 0.589sec\n",
            "Epoch 72 tr: l 0.278 a 0.917 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.923sec(train) 3.317sec(infer)\n",
            "Epoch 72 tst: l 0.282 a 0.921 cl_acc 1.000 clct[50, 50, 50, 50] 0.558sec\n",
            "Epoch 73 tr: l 0.277 a 0.918 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.047sec(train) 3.615sec(infer)\n",
            "Epoch 73 tst: l 0.281 a 0.921 cl_acc 1.000 clct[50, 50, 50, 50] 0.578sec\n",
            "Epoch 74 tr: l 0.275 a 0.918 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.910sec(train) 3.324sec(infer)\n",
            "Epoch 74 tst: l 0.281 a 0.922 cl_acc 1.000 clct[50, 50, 50, 50] 0.575sec\n",
            "Epoch 75 tr: l 0.274 a 0.918 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.187sec(train) 3.239sec(infer)\n",
            "Epoch 75 tst: l 0.280 a 0.922 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 76 tr: l 0.273 a 0.919 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.016sec(train) 3.410sec(infer)\n",
            "Epoch 76 tst: l 0.279 a 0.922 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 77 tr: l 0.272 a 0.919 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.033sec(train) 2.963sec(infer)\n",
            "Epoch 77 tst: l 0.278 a 0.922 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "Epoch 78 tr: l 0.271 a 0.919 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.042sec(train) 3.468sec(infer)\n",
            "Epoch 78 tst: l 0.277 a 0.923 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "Epoch 79 tr: l 0.270 a 0.920 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.023sec(train) 2.834sec(infer)\n",
            "Epoch 79 tst: l 0.276 a 0.923 cl_acc 1.000 clct[50, 50, 50, 50] 0.520sec\n",
            "Epoch 80 tr: l 0.269 a 0.920 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.131sec(train) 3.429sec(infer)\n",
            "Epoch 80 tst: l 0.275 a 0.924 cl_acc 1.000 clct[50, 50, 50, 50] 0.563sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 81 tr: l 0.268 a 0.920 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.003sec(train) 2.968sec(infer)\n",
            "Epoch 81 tst: l 0.274 a 0.924 cl_acc 1.000 clct[50, 50, 50, 50] 0.550sec\n",
            "Epoch 82 tr: l 0.267 a 0.921 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.215sec(train) 3.524sec(infer)\n",
            "Epoch 82 tst: l 0.273 a 0.924 cl_acc 1.000 clct[50, 50, 50, 50] 0.583sec\n",
            "Epoch 83 tr: l 0.266 a 0.921 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.991sec(train) 3.196sec(infer)\n",
            "Epoch 83 tst: l 0.272 a 0.924 cl_acc 1.000 clct[50, 50, 50, 50] 0.547sec\n",
            "Epoch 84 tr: l 0.265 a 0.921 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.118sec(train) 3.477sec(infer)\n",
            "Epoch 84 tst: l 0.271 a 0.925 cl_acc 1.000 clct[50, 50, 50, 50] 0.582sec\n",
            "Epoch 85 tr: l 0.264 a 0.922 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.949sec(train) 3.304sec(infer)\n",
            "Epoch 85 tst: l 0.270 a 0.925 cl_acc 1.000 clct[50, 50, 50, 50] 0.551sec\n",
            "Epoch 86 tr: l 0.263 a 0.922 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.149sec(train) 3.498sec(infer)\n",
            "Epoch 86 tst: l 0.269 a 0.925 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 87 tr: l 0.262 a 0.922 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.960sec(train) 3.201sec(infer)\n",
            "Epoch 87 tst: l 0.269 a 0.925 cl_acc 1.000 clct[50, 50, 50, 50] 0.534sec\n",
            "Epoch 88 tr: l 0.261 a 0.923 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.087sec(train) 3.494sec(infer)\n",
            "Epoch 88 tst: l 0.268 a 0.926 cl_acc 1.000 clct[50, 50, 50, 50] 0.581sec\n",
            "Epoch 89 tr: l 0.260 a 0.923 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.884sec(train) 3.208sec(infer)\n",
            "Epoch 89 tst: l 0.267 a 0.926 cl_acc 1.000 clct[50, 50, 50, 50] 0.542sec\n",
            "Epoch 90 tr: l 0.259 a 0.923 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.118sec(train) 3.504sec(infer)\n",
            "Epoch 90 tst: l 0.266 a 0.926 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 91 tr: l 0.258 a 0.923 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.884sec(train) 3.218sec(infer)\n",
            "Epoch 91 tst: l 0.265 a 0.926 cl_acc 1.000 clct[50, 50, 50, 50] 0.533sec\n",
            "Epoch 92 tr: l 0.257 a 0.923 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.154sec(train) 3.448sec(infer)\n",
            "Epoch 92 tst: l 0.264 a 0.927 cl_acc 1.000 clct[50, 50, 50, 50] 0.472sec\n",
            "Epoch 93 tr: l 0.256 a 0.924 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.965sec(train) 3.213sec(infer)\n",
            "Epoch 93 tst: l 0.264 a 0.927 cl_acc 1.000 clct[50, 50, 50, 50] 0.575sec\n",
            "Epoch 94 tr: l 0.255 a 0.924 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.155sec(train) 3.299sec(infer)\n",
            "Epoch 94 tst: l 0.263 a 0.927 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 95 tr: l 0.254 a 0.924 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.940sec(train) 3.269sec(infer)\n",
            "Epoch 95 tst: l 0.262 a 0.927 cl_acc 1.000 clct[50, 50, 50, 50] 0.582sec\n",
            "Epoch 96 tr: l 0.253 a 0.925 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.161sec(train) 3.185sec(infer)\n",
            "Epoch 96 tst: l 0.261 a 0.928 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 97 tr: l 0.252 a 0.925 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.935sec(train) 3.309sec(infer)\n",
            "Epoch 97 tst: l 0.260 a 0.928 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 98 tr: l 0.251 a 0.925 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.147sec(train) 3.066sec(infer)\n",
            "Epoch 98 tst: l 0.260 a 0.928 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "Epoch 99 tr: l 0.250 a 0.925 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.959sec(train) 3.373sec(infer)\n",
            "Epoch 99 tst: l 0.259 a 0.928 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 100 tr: l 0.249 a 0.926 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.161sec(train) 2.963sec(infer)\n",
            "Epoch 100 tst: l 0.258 a 0.928 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 101 tr: l 0.249 a 0.926 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.968sec(train) 3.456sec(infer)\n",
            "Epoch 101 tst: l 0.257 a 0.929 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "Epoch 102 tr: l 0.248 a 0.926 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.127sec(train) 2.837sec(infer)\n",
            "Epoch 102 tst: l 0.256 a 0.929 cl_acc 1.000 clct[50, 50, 50, 50] 0.536sec\n",
            "Epoch 103 tr: l 0.247 a 0.926 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.109sec(train) 3.498sec(infer)\n",
            "Epoch 103 tst: l 0.256 a 0.929 cl_acc 1.000 clct[50, 50, 50, 50] 0.583sec\n",
            "Epoch 104 tr: l 0.246 a 0.927 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.058sec(train) 2.917sec(infer)\n",
            "Epoch 104 tst: l 0.255 a 0.929 cl_acc 1.000 clct[50, 50, 50, 50] 0.536sec\n",
            "Epoch 105 tr: l 0.245 a 0.927 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.017sec(train) 3.516sec(infer)\n",
            "Epoch 105 tst: l 0.254 a 0.929 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 106 tr: l 0.244 a 0.927 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.118sec(train) 2.999sec(infer)\n",
            "Epoch 106 tst: l 0.253 a 0.929 cl_acc 1.000 clct[50, 50, 50, 50] 0.531sec\n",
            "Epoch 107 tr: l 0.243 a 0.927 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.991sec(train) 3.616sec(infer)\n",
            "Epoch 107 tst: l 0.253 a 0.930 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "Epoch 108 tr: l 0.242 a 0.928 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.002sec(train) 3.088sec(infer)\n",
            "Epoch 108 tst: l 0.252 a 0.930 cl_acc 1.000 clct[50, 50, 50, 50] 0.533sec\n",
            "Epoch 109 tr: l 0.242 a 0.928 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.172sec(train) 3.517sec(infer)\n",
            "Epoch 109 tst: l 0.251 a 0.930 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 110 tr: l 0.241 a 0.928 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.999sec(train) 3.196sec(infer)\n",
            "Epoch 110 tst: l 0.250 a 0.930 cl_acc 1.000 clct[50, 50, 50, 50] 0.534sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 111 tr: l 0.240 a 0.928 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.980sec(train) 3.515sec(infer)\n",
            "Epoch 111 tst: l 0.250 a 0.930 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 112 tr: l 0.239 a 0.929 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.014sec(train) 3.216sec(infer)\n",
            "Epoch 112 tst: l 0.249 a 0.931 cl_acc 1.000 clct[50, 50, 50, 50] 0.538sec\n",
            "Epoch 113 tr: l 0.238 a 0.929 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.130sec(train) 3.511sec(infer)\n",
            "Epoch 113 tst: l 0.248 a 0.931 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 114 tr: l 0.237 a 0.929 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.905sec(train) 3.214sec(infer)\n",
            "Epoch 114 tst: l 0.248 a 0.931 cl_acc 1.000 clct[50, 50, 50, 50] 0.540sec\n",
            "Epoch 115 tr: l 0.237 a 0.929 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.005sec(train) 3.609sec(infer)\n",
            "Epoch 115 tst: l 0.247 a 0.931 cl_acc 1.000 clct[50, 50, 50, 50] 0.588sec\n",
            "Epoch 116 tr: l 0.236 a 0.930 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.859sec(train) 3.219sec(infer)\n",
            "Epoch 116 tst: l 0.246 a 0.931 cl_acc 1.000 clct[50, 50, 50, 50] 0.539sec\n",
            "Epoch 117 tr: l 0.235 a 0.930 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.142sec(train) 3.511sec(infer)\n",
            "Epoch 117 tst: l 0.245 a 0.932 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 118 tr: l 0.234 a 0.930 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.854sec(train) 3.225sec(infer)\n",
            "Epoch 118 tst: l 0.245 a 0.932 cl_acc 1.000 clct[50, 50, 50, 50] 0.538sec\n",
            "Epoch 119 tr: l 0.233 a 0.930 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.997sec(train) 3.510sec(infer)\n",
            "Epoch 119 tst: l 0.244 a 0.932 cl_acc 1.000 clct[50, 50, 50, 50] 0.472sec\n",
            "Epoch 120 tr: l 0.233 a 0.931 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.992sec(train) 3.220sec(infer)\n",
            "Epoch 120 tst: l 0.243 a 0.932 cl_acc 1.000 clct[50, 50, 50, 50] 0.570sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 121 tr: l 0.232 a 0.931 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.072sec(train) 3.243sec(infer)\n",
            "Epoch 121 tst: l 0.243 a 0.932 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 122 tr: l 0.231 a 0.931 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.043sec(train) 3.343sec(infer)\n",
            "Epoch 122 tst: l 0.242 a 0.932 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 123 tr: l 0.230 a 0.931 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.040sec(train) 3.021sec(infer)\n",
            "Epoch 123 tst: l 0.241 a 0.933 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "Epoch 124 tr: l 0.230 a 0.932 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.080sec(train) 3.427sec(infer)\n",
            "Epoch 124 tst: l 0.241 a 0.933 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 125 tr: l 0.229 a 0.932 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.026sec(train) 2.839sec(infer)\n",
            "Epoch 125 tst: l 0.240 a 0.933 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 126 tr: l 0.228 a 0.932 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.091sec(train) 3.491sec(infer)\n",
            "Epoch 126 tst: l 0.239 a 0.933 cl_acc 1.000 clct[50, 50, 50, 50] 0.563sec\n",
            "Epoch 127 tr: l 0.227 a 0.932 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.040sec(train) 2.879sec(infer)\n",
            "Epoch 127 tst: l 0.239 a 0.933 cl_acc 1.000 clct[50, 50, 50, 50] 0.534sec\n",
            "Epoch 128 tr: l 0.227 a 0.933 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.093sec(train) 3.510sec(infer)\n",
            "Epoch 128 tst: l 0.238 a 0.933 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 129 tr: l 0.226 a 0.933 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.967sec(train) 2.974sec(infer)\n",
            "Epoch 129 tst: l 0.237 a 0.934 cl_acc 1.000 clct[50, 50, 50, 50] 0.535sec\n",
            "Epoch 130 tr: l 0.225 a 0.933 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.090sec(train) 3.509sec(infer)\n",
            "Epoch 130 tst: l 0.237 a 0.934 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 131 tr: l 0.224 a 0.933 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.950sec(train) 3.082sec(infer)\n",
            "Epoch 131 tst: l 0.236 a 0.934 cl_acc 1.000 clct[50, 50, 50, 50] 0.533sec\n",
            "Epoch 132 tr: l 0.224 a 0.933 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.151sec(train) 3.506sec(infer)\n",
            "Epoch 132 tst: l 0.236 a 0.934 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 133 tr: l 0.223 a 0.934 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.107sec(train) 3.219sec(infer)\n",
            "Epoch 133 tst: l 0.235 a 0.934 cl_acc 1.000 clct[50, 50, 50, 50] 0.541sec\n",
            "Epoch 134 tr: l 0.222 a 0.934 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.012sec(train) 3.521sec(infer)\n",
            "Epoch 134 tst: l 0.234 a 0.934 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 135 tr: l 0.221 a 0.934 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.888sec(train) 3.227sec(infer)\n",
            "Epoch 135 tst: l 0.234 a 0.935 cl_acc 1.000 clct[50, 50, 50, 50] 0.538sec\n",
            "Epoch 136 tr: l 0.221 a 0.934 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.328sec(train) 3.522sec(infer)\n",
            "Epoch 136 tst: l 0.233 a 0.935 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 137 tr: l 0.220 a 0.935 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.582sec(train) 3.450sec(infer)\n",
            "Epoch 137 tst: l 0.232 a 0.935 cl_acc 1.000 clct[50, 50, 50, 50] 0.561sec\n",
            "Epoch 138 tr: l 0.219 a 0.935 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.172sec(train) 3.359sec(infer)\n",
            "Epoch 138 tst: l 0.232 a 0.935 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "Epoch 139 tr: l 0.219 a 0.935 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.115sec(train) 3.428sec(infer)\n",
            "Epoch 139 tst: l 0.231 a 0.935 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 140 tr: l 0.218 a 0.935 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.062sec(train) 3.047sec(infer)\n",
            "Epoch 140 tst: l 0.231 a 0.935 cl_acc 1.000 clct[50, 50, 50, 50] 0.475sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 141 tr: l 0.217 a 0.935 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.986sec(train) 3.513sec(infer)\n",
            "Epoch 141 tst: l 0.230 a 0.935 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 142 tr: l 0.217 a 0.936 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.130sec(train) 2.958sec(infer)\n",
            "Epoch 142 tst: l 0.229 a 0.936 cl_acc 1.000 clct[50, 50, 50, 50] 0.558sec\n",
            "Epoch 143 tr: l 0.216 a 0.936 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.190sec(train) 3.478sec(infer)\n",
            "Epoch 143 tst: l 0.229 a 0.936 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 144 tr: l 0.215 a 0.936 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.608sec(train) 3.273sec(infer)\n",
            "Epoch 144 tst: l 0.228 a 0.936 cl_acc 1.000 clct[50, 50, 50, 50] 0.556sec\n",
            "Epoch 145 tr: l 0.215 a 0.936 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.689sec(train) 3.523sec(infer)\n",
            "Epoch 145 tst: l 0.228 a 0.936 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 146 tr: l 0.214 a 0.936 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.691sec(train) 3.335sec(infer)\n",
            "Epoch 146 tst: l 0.227 a 0.936 cl_acc 1.000 clct[50, 50, 50, 50] 0.577sec\n",
            "Epoch 147 tr: l 0.213 a 0.937 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.684sec(train) 3.322sec(infer)\n",
            "Epoch 147 tst: l 0.226 a 0.936 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 148 tr: l 0.213 a 0.937 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.635sec(train) 3.458sec(infer)\n",
            "Epoch 148 tst: l 0.226 a 0.936 cl_acc 1.000 clct[50, 50, 50, 50] 0.563sec\n",
            "Epoch 149 tr: l 0.212 a 0.937 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.767sec(train) 2.943sec(infer)\n",
            "Epoch 149 tst: l 0.225 a 0.937 cl_acc 1.000 clct[50, 50, 50, 50] 0.557sec\n",
            "Epoch 150 tr: l 0.211 a 0.937 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.719sec(train) 3.521sec(infer)\n",
            "Epoch 150 tst: l 0.225 a 0.937 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 151 tr: l 0.211 a 0.937 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.626sec(train) 3.331sec(infer)\n",
            "Epoch 151 tst: l 0.224 a 0.937 cl_acc 1.000 clct[50, 50, 50, 50] 0.557sec\n",
            "Epoch 152 tr: l 0.210 a 0.937 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.827sec(train) 3.522sec(infer)\n",
            "Epoch 152 tst: l 0.223 a 0.937 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 153 tr: l 0.209 a 0.938 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.588sec(train) 3.364sec(infer)\n",
            "Epoch 153 tst: l 0.223 a 0.937 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 154 tr: l 0.209 a 0.938 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.388sec(train) 3.122sec(infer)\n",
            "Epoch 154 tst: l 0.222 a 0.937 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "Epoch 155 tr: l 0.208 a 0.938 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.983sec(train) 3.457sec(infer)\n",
            "Epoch 155 tst: l 0.222 a 0.938 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 156 tr: l 0.207 a 0.938 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.159sec(train) 2.833sec(infer)\n",
            "Epoch 156 tst: l 0.221 a 0.938 cl_acc 1.000 clct[50, 50, 50, 50] 0.529sec\n",
            "Epoch 157 tr: l 0.207 a 0.938 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.028sec(train) 3.514sec(infer)\n",
            "Epoch 157 tst: l 0.221 a 0.938 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "Epoch 158 tr: l 0.206 a 0.939 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.110sec(train) 3.072sec(infer)\n",
            "Epoch 158 tst: l 0.220 a 0.938 cl_acc 1.000 clct[50, 50, 50, 50] 0.553sec\n",
            "Epoch 159 tr: l 0.206 a 0.939 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.015sec(train) 3.488sec(infer)\n",
            "Epoch 159 tst: l 0.220 a 0.938 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 160 tr: l 0.205 a 0.939 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.056sec(train) 3.296sec(infer)\n",
            "Epoch 160 tst: l 0.219 a 0.938 cl_acc 1.000 clct[50, 50, 50, 50] 0.553sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 161 tr: l 0.204 a 0.939 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.034sec(train) 3.529sec(infer)\n",
            "Epoch 161 tst: l 0.218 a 0.939 cl_acc 1.000 clct[50, 50, 50, 50] 0.588sec\n",
            "Epoch 162 tr: l 0.204 a 0.939 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.082sec(train) 3.328sec(infer)\n",
            "Epoch 162 tst: l 0.218 a 0.939 cl_acc 1.000 clct[50, 50, 50, 50] 0.554sec\n",
            "Epoch 163 tr: l 0.203 a 0.939 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.043sec(train) 3.502sec(infer)\n",
            "Epoch 163 tst: l 0.217 a 0.939 cl_acc 1.000 clct[50, 50, 50, 50] 0.481sec\n",
            "Epoch 164 tr: l 0.202 a 0.940 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.043sec(train) 3.361sec(infer)\n",
            "Epoch 164 tst: l 0.217 a 0.939 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 165 tr: l 0.202 a 0.940 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.110sec(train) 3.172sec(infer)\n",
            "Epoch 165 tst: l 0.216 a 0.939 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 166 tr: l 0.201 a 0.940 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.095sec(train) 3.460sec(infer)\n",
            "Epoch 166 tst: l 0.216 a 0.939 cl_acc 1.000 clct[50, 50, 50, 50] 0.589sec\n",
            "Epoch 167 tr: l 0.201 a 0.940 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.057sec(train) 2.901sec(infer)\n",
            "Epoch 167 tst: l 0.215 a 0.939 cl_acc 1.000 clct[50, 50, 50, 50] 0.466sec\n",
            "Epoch 168 tr: l 0.200 a 0.940 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.137sec(train) 3.515sec(infer)\n",
            "Epoch 168 tst: l 0.215 a 0.939 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "Epoch 169 tr: l 0.200 a 0.940 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.023sec(train) 2.939sec(infer)\n",
            "Epoch 169 tst: l 0.214 a 0.939 cl_acc 1.000 clct[50, 50, 50, 50] 0.557sec\n",
            "Epoch 170 tr: l 0.199 a 0.941 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.145sec(train) 3.502sec(infer)\n",
            "Epoch 170 tst: l 0.214 a 0.939 cl_acc 1.000 clct[50, 50, 50, 50] 0.575sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 171 tr: l 0.198 a 0.941 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.105sec(train) 2.969sec(infer)\n",
            "Epoch 171 tst: l 0.213 a 0.940 cl_acc 1.000 clct[50, 50, 50, 50] 0.553sec\n",
            "Epoch 172 tr: l 0.198 a 0.941 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.050sec(train) 3.522sec(infer)\n",
            "Epoch 172 tst: l 0.213 a 0.940 cl_acc 1.000 clct[50, 50, 50, 50] 0.585sec\n",
            "Epoch 173 tr: l 0.197 a 0.941 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.968sec(train) 3.321sec(infer)\n",
            "Epoch 173 tst: l 0.212 a 0.940 cl_acc 1.000 clct[50, 50, 50, 50] 0.557sec\n",
            "Epoch 174 tr: l 0.197 a 0.941 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.158sec(train) 3.513sec(infer)\n",
            "Epoch 174 tst: l 0.212 a 0.940 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 175 tr: l 0.196 a 0.941 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.900sec(train) 3.331sec(infer)\n",
            "Epoch 175 tst: l 0.211 a 0.940 cl_acc 1.000 clct[50, 50, 50, 50] 0.579sec\n",
            "Epoch 176 tr: l 0.196 a 0.941 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.221sec(train) 3.336sec(infer)\n",
            "Epoch 176 tst: l 0.211 a 0.940 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "Epoch 177 tr: l 0.195 a 0.942 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.937sec(train) 3.415sec(infer)\n",
            "Epoch 177 tst: l 0.210 a 0.940 cl_acc 1.000 clct[50, 50, 50, 50] 0.591sec\n",
            "Epoch 178 tr: l 0.194 a 0.942 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.165sec(train) 2.980sec(infer)\n",
            "Epoch 178 tst: l 0.210 a 0.940 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "Epoch 179 tr: l 0.194 a 0.942 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.000sec(train) 3.507sec(infer)\n",
            "Epoch 179 tst: l 0.209 a 0.940 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 180 tr: l 0.193 a 0.942 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.133sec(train) 2.878sec(infer)\n",
            "Epoch 180 tst: l 0.209 a 0.940 cl_acc 1.000 clct[50, 50, 50, 50] 0.554sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 181 tr: l 0.193 a 0.942 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.999sec(train) 3.513sec(infer)\n",
            "Epoch 181 tst: l 0.208 a 0.941 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "Epoch 182 tr: l 0.192 a 0.942 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.125sec(train) 3.162sec(infer)\n",
            "Epoch 182 tst: l 0.208 a 0.941 cl_acc 1.000 clct[50, 50, 50, 50] 0.553sec\n",
            "Epoch 183 tr: l 0.192 a 0.942 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.047sec(train) 3.525sec(infer)\n",
            "Epoch 183 tst: l 0.207 a 0.941 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "Epoch 184 tr: l 0.191 a 0.943 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.048sec(train) 3.331sec(infer)\n",
            "Epoch 184 tst: l 0.207 a 0.941 cl_acc 1.000 clct[50, 50, 50, 50] 0.557sec\n",
            "Epoch 185 tr: l 0.191 a 0.943 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.040sec(train) 3.519sec(infer)\n",
            "Epoch 185 tst: l 0.206 a 0.941 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 186 tr: l 0.190 a 0.943 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.012sec(train) 3.334sec(infer)\n",
            "Epoch 186 tst: l 0.206 a 0.941 cl_acc 1.000 clct[50, 50, 50, 50] 0.556sec\n",
            "Epoch 187 tr: l 0.190 a 0.943 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.072sec(train) 3.397sec(infer)\n",
            "Epoch 187 tst: l 0.205 a 0.941 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 188 tr: l 0.189 a 0.943 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.557sec(train) 3.437sec(infer)\n",
            "Epoch 188 tst: l 0.205 a 0.941 cl_acc 1.000 clct[50, 50, 50, 50] 0.586sec\n",
            "Epoch 189 tr: l 0.189 a 0.943 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.711sec(train) 2.834sec(infer)\n",
            "Epoch 189 tst: l 0.204 a 0.942 cl_acc 1.000 clct[50, 50, 50, 50] 0.367sec\n",
            "Epoch 190 tr: l 0.188 a 0.943 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.818sec(train) 3.520sec(infer)\n",
            "Epoch 190 tst: l 0.204 a 0.942 cl_acc 1.000 clct[50, 50, 50, 50] 0.588sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 191 tr: l 0.187 a 0.943 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.771sec(train) 3.329sec(infer)\n",
            "Epoch 191 tst: l 0.203 a 0.942 cl_acc 1.000 clct[50, 50, 50, 50] 0.555sec\n",
            "Epoch 192 tr: l 0.187 a 0.944 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.349sec(train) 4.454sec(infer)\n",
            "Epoch 192 tst: l 0.203 a 0.942 cl_acc 1.000 clct[50, 50, 50, 50] 0.742sec\n",
            "Epoch 193 tr: l 0.186 a 0.944 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.147sec(train) 5.864sec(infer)\n",
            "Epoch 193 tst: l 0.203 a 0.942 cl_acc 1.000 clct[50, 50, 50, 50] 1.180sec\n",
            "Epoch 194 tr: l 0.186 a 0.944 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.343sec(train) 5.362sec(infer)\n",
            "Epoch 194 tst: l 0.202 a 0.942 cl_acc 1.000 clct[50, 50, 50, 50] 0.767sec\n",
            "Epoch 195 tr: l 0.185 a 0.944 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.654sec(train) 7.713sec(infer)\n",
            "Epoch 195 tst: l 0.202 a 0.942 cl_acc 1.000 clct[50, 50, 50, 50] 1.545sec\n",
            "Epoch 196 tr: l 0.185 a 0.944 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.652sec(train) 5.333sec(infer)\n",
            "Epoch 196 tst: l 0.201 a 0.943 cl_acc 1.000 clct[50, 50, 50, 50] 1.039sec\n",
            "Epoch 197 tr: l 0.184 a 0.944 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.843sec(train) 6.619sec(infer)\n",
            "Epoch 197 tst: l 0.201 a 0.943 cl_acc 1.000 clct[50, 50, 50, 50] 0.793sec\n",
            "Epoch 198 tr: l 0.184 a 0.945 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.472sec(train) 7.068sec(infer)\n",
            "Epoch 198 tst: l 0.200 a 0.943 cl_acc 1.000 clct[50, 50, 50, 50] 1.560sec\n",
            "Epoch 199 tr: l 0.183 a 0.945 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.208sec(train) 4.986sec(infer)\n",
            "Epoch 199 tst: l 0.200 a 0.943 cl_acc 1.000 clct[50, 50, 50, 50] 0.891sec\n",
            "Epoch 200 tr: l 0.183 a 0.945 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.251sec(train) 7.532sec(infer)\n",
            "Epoch 200 tst: l 0.199 a 0.943 cl_acc 1.000 clct[50, 50, 50, 50] 0.963sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 201 tr: l 0.182 a 0.945 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.471sec(train) 6.838sec(infer)\n",
            "Epoch 201 tst: l 0.199 a 0.943 cl_acc 1.000 clct[50, 50, 50, 50] 1.194sec\n",
            "Epoch 202 tr: l 0.182 a 0.945 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.530sec(train) 5.171sec(infer)\n",
            "Epoch 202 tst: l 0.199 a 0.943 cl_acc 1.000 clct[50, 50, 50, 50] 0.859sec\n",
            "Epoch 203 tr: l 0.181 a 0.945 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.977sec(train) 7.550sec(infer)\n",
            "Epoch 203 tst: l 0.198 a 0.943 cl_acc 1.000 clct[50, 50, 50, 50] 0.960sec\n",
            "Epoch 204 tr: l 0.181 a 0.945 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.640sec(train) 5.799sec(infer)\n",
            "Epoch 204 tst: l 0.198 a 0.944 cl_acc 1.000 clct[50, 50, 50, 50] 1.194sec\n",
            "Epoch 205 tr: l 0.181 a 0.945 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.968sec(train) 5.436sec(infer)\n",
            "Epoch 205 tst: l 0.197 a 0.944 cl_acc 1.000 clct[50, 50, 50, 50] 0.851sec\n",
            "Epoch 206 tr: l 0.180 a 0.945 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.599sec(train) 7.472sec(infer)\n",
            "Epoch 206 tst: l 0.197 a 0.944 cl_acc 1.000 clct[50, 50, 50, 50] 1.464sec\n",
            "Epoch 207 tr: l 0.180 a 0.946 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.688sec(train) 5.087sec(infer)\n",
            "Epoch 207 tst: l 0.196 a 0.944 cl_acc 1.000 clct[50, 50, 50, 50] 1.067sec\n",
            "Epoch 208 tr: l 0.179 a 0.946 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.750sec(train) 6.753sec(infer)\n",
            "Epoch 208 tst: l 0.196 a 0.944 cl_acc 1.000 clct[50, 50, 50, 50] 0.959sec\n",
            "Epoch 209 tr: l 0.179 a 0.946 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.531sec(train) 6.736sec(infer)\n",
            "Epoch 209 tst: l 0.196 a 0.944 cl_acc 1.000 clct[50, 50, 50, 50] 1.200sec\n",
            "Epoch 210 tr: l 0.178 a 0.946 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.381sec(train) 5.377sec(infer)\n",
            "Epoch 210 tst: l 0.195 a 0.944 cl_acc 1.000 clct[50, 50, 50, 50] 0.859sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 211 tr: l 0.178 a 0.946 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.995sec(train) 7.518sec(infer)\n",
            "Epoch 211 tst: l 0.195 a 0.944 cl_acc 1.000 clct[50, 50, 50, 50] 0.963sec\n",
            "Epoch 212 tr: l 0.177 a 0.946 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.641sec(train) 5.979sec(infer)\n",
            "Epoch 212 tst: l 0.194 a 0.944 cl_acc 1.000 clct[50, 50, 50, 50] 1.235sec\n",
            "Epoch 213 tr: l 0.177 a 0.946 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.911sec(train) 5.467sec(infer)\n",
            "Epoch 213 tst: l 0.194 a 0.944 cl_acc 1.000 clct[50, 50, 50, 50] 0.856sec\n",
            "Epoch 214 tr: l 0.176 a 0.946 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.543sec(train) 8.047sec(infer)\n",
            "Epoch 214 tst: l 0.193 a 0.944 cl_acc 1.000 clct[50, 50, 50, 50] 1.173sec\n",
            "Epoch 215 tr: l 0.176 a 0.947 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.635sec(train) 5.458sec(infer)\n",
            "Epoch 215 tst: l 0.193 a 0.945 cl_acc 1.000 clct[50, 50, 50, 50] 1.135sec\n",
            "Epoch 216 tr: l 0.175 a 0.947 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.005sec(train) 6.113sec(infer)\n",
            "Epoch 216 tst: l 0.193 a 0.945 cl_acc 1.000 clct[50, 50, 50, 50] 0.784sec\n",
            "Epoch 217 tr: l 0.175 a 0.947 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.493sec(train) 7.586sec(infer)\n",
            "Epoch 217 tst: l 0.192 a 0.945 cl_acc 1.000 clct[50, 50, 50, 50] 1.536sec\n",
            "Epoch 218 tr: l 0.174 a 0.947 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.011sec(train) 4.900sec(infer)\n",
            "Epoch 218 tst: l 0.192 a 0.945 cl_acc 1.000 clct[50, 50, 50, 50] 1.045sec\n",
            "Epoch 219 tr: l 0.174 a 0.947 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.238sec(train) 7.354sec(infer)\n",
            "Epoch 219 tst: l 0.191 a 0.945 cl_acc 1.000 clct[50, 50, 50, 50] 0.961sec\n",
            "Epoch 220 tr: l 0.174 a 0.947 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.441sec(train) 6.900sec(infer)\n",
            "Epoch 220 tst: l 0.191 a 0.945 cl_acc 1.000 clct[50, 50, 50, 50] 1.347sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 221 tr: l 0.173 a 0.947 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.674sec(train) 4.542sec(infer)\n",
            "Epoch 221 tst: l 0.191 a 0.945 cl_acc 1.000 clct[50, 50, 50, 50] 0.943sec\n",
            "Epoch 222 tr: l 0.173 a 0.947 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.073sec(train) 8.246sec(infer)\n",
            "Epoch 222 tst: l 0.190 a 0.945 cl_acc 1.000 clct[50, 50, 50, 50] 0.963sec\n",
            "Epoch 223 tr: l 0.172 a 0.948 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.334sec(train) 6.928sec(infer)\n",
            "Epoch 223 tst: l 0.190 a 0.946 cl_acc 1.000 clct[50, 50, 50, 50] 1.333sec\n",
            "Epoch 224 tr: l 0.172 a 0.948 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.979sec(train) 4.673sec(infer)\n",
            "Epoch 224 tst: l 0.190 a 0.946 cl_acc 1.000 clct[50, 50, 50, 50] 0.855sec\n",
            "Epoch 225 tr: l 0.171 a 0.948 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.062sec(train) 8.509sec(infer)\n",
            "Epoch 225 tst: l 0.189 a 0.946 cl_acc 1.000 clct[50, 50, 50, 50] 0.965sec\n",
            "Epoch 226 tr: l 0.171 a 0.948 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.349sec(train) 6.681sec(infer)\n",
            "Epoch 226 tst: l 0.189 a 0.946 cl_acc 1.000 clct[50, 50, 50, 50] 1.230sec\n",
            "Epoch 227 tr: l 0.170 a 0.948 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.185sec(train) 4.531sec(infer)\n",
            "Epoch 227 tst: l 0.188 a 0.946 cl_acc 1.000 clct[50, 50, 50, 50] 0.858sec\n",
            "Epoch 228 tr: l 0.170 a 0.948 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.032sec(train) 8.797sec(infer)\n",
            "Epoch 228 tst: l 0.188 a 0.946 cl_acc 1.000 clct[50, 50, 50, 50] 0.966sec\n",
            "Epoch 229 tr: l 0.170 a 0.948 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.342sec(train) 6.571sec(infer)\n",
            "Epoch 229 tst: l 0.188 a 0.946 cl_acc 1.000 clct[50, 50, 50, 50] 1.208sec\n",
            "Epoch 230 tr: l 0.169 a 0.948 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.437sec(train) 4.349sec(infer)\n",
            "Epoch 230 tst: l 0.187 a 0.946 cl_acc 1.000 clct[50, 50, 50, 50] 0.853sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 231 tr: l 0.169 a 0.949 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.952sec(train) 8.917sec(infer)\n",
            "Epoch 231 tst: l 0.187 a 0.946 cl_acc 1.000 clct[50, 50, 50, 50] 0.778sec\n",
            "Epoch 232 tr: l 0.168 a 0.949 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.571sec(train) 7.044sec(infer)\n",
            "Epoch 232 tst: l 0.186 a 0.947 cl_acc 1.000 clct[50, 50, 50, 50] 1.559sec\n",
            "Epoch 233 tr: l 0.168 a 0.949 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.906sec(train) 4.982sec(infer)\n",
            "Epoch 233 tst: l 0.186 a 0.947 cl_acc 1.000 clct[50, 50, 50, 50] 1.068sec\n",
            "Epoch 234 tr: l 0.168 a 0.949 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.566sec(train) 7.425sec(infer)\n",
            "Epoch 234 tst: l 0.186 a 0.947 cl_acc 1.000 clct[50, 50, 50, 50] 0.713sec\n",
            "Epoch 235 tr: l 0.167 a 0.949 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.430sec(train) 7.451sec(infer)\n",
            "Epoch 235 tst: l 0.185 a 0.947 cl_acc 1.000 clct[50, 50, 50, 50] 1.459sec\n",
            "Epoch 236 tr: l 0.167 a 0.949 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.111sec(train) 5.305sec(infer)\n",
            "Epoch 236 tst: l 0.185 a 0.947 cl_acc 1.000 clct[50, 50, 50, 50] 1.078sec\n",
            "Epoch 237 tr: l 0.166 a 0.949 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.701sec(train) 6.292sec(infer)\n",
            "Epoch 237 tst: l 0.185 a 0.947 cl_acc 1.000 clct[50, 50, 50, 50] 0.714sec\n",
            "Epoch 238 tr: l 0.166 a 0.949 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.427sec(train) 8.664sec(infer)\n",
            "Epoch 238 tst: l 0.184 a 0.947 cl_acc 1.000 clct[50, 50, 50, 50] 1.552sec\n",
            "Epoch 239 tr: l 0.165 a 0.949 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.351sec(train) 7.045sec(infer)\n",
            "Epoch 239 tst: l 0.184 a 0.947 cl_acc 1.000 clct[50, 50, 50, 50] 1.548sec\n",
            "Epoch 240 tr: l 0.165 a 0.949 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.819sec(train) 4.937sec(infer)\n",
            "Epoch 240 tst: l 0.184 a 0.947 cl_acc 1.000 clct[50, 50, 50, 50] 1.127sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 241 tr: l 0.165 a 0.949 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.648sec(train) 6.560sec(infer)\n",
            "Epoch 241 tst: l 0.183 a 0.948 cl_acc 1.000 clct[50, 50, 50, 50] 0.714sec\n",
            "Epoch 242 tr: l 0.164 a 0.950 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.653sec(train) 8.927sec(infer)\n",
            "Epoch 242 tst: l 0.183 a 0.948 cl_acc 1.000 clct[50, 50, 50, 50] 1.514sec\n",
            "Epoch 243 tr: l 0.164 a 0.950 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.336sec(train) 7.439sec(infer)\n",
            "Epoch 243 tst: l 0.182 a 0.948 cl_acc 1.000 clct[50, 50, 50, 50] 1.557sec\n",
            "Epoch 244 tr: l 0.163 a 0.950 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.498sec(train) 5.452sec(infer)\n",
            "Epoch 244 tst: l 0.182 a 0.948 cl_acc 1.000 clct[50, 50, 50, 50] 1.140sec\n",
            "Epoch 245 tr: l 0.163 a 0.950 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.734sec(train) 6.034sec(infer)\n",
            "Epoch 245 tst: l 0.182 a 0.948 cl_acc 1.000 clct[50, 50, 50, 50] 0.715sec\n",
            "Epoch 246 tr: l 0.163 a 0.950 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.605sec(train) 8.910sec(infer)\n",
            "Epoch 246 tst: l 0.181 a 0.948 cl_acc 1.000 clct[50, 50, 50, 50] 1.559sec\n",
            "Epoch 247 tr: l 0.162 a 0.950 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.267sec(train) 7.453sec(infer)\n",
            "Epoch 247 tst: l 0.181 a 0.948 cl_acc 1.000 clct[50, 50, 50, 50] 1.545sec\n",
            "Epoch 248 tr: l 0.162 a 0.950 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.455sec(train) 5.576sec(infer)\n",
            "Epoch 248 tst: l 0.181 a 0.948 cl_acc 1.000 clct[50, 50, 50, 50] 1.138sec\n",
            "Epoch 249 tr: l 0.161 a 0.950 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.873sec(train) 5.598sec(infer)\n",
            "Epoch 249 tst: l 0.180 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 0.715sec\n",
            "Epoch 250 tr: l 0.161 a 0.950 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.639sec(train) 8.600sec(infer)\n",
            "Epoch 250 tst: l 0.180 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 1.455sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 251 tr: l 0.161 a 0.951 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.185sec(train) 6.745sec(infer)\n",
            "Epoch 251 tst: l 0.180 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 1.457sec\n",
            "Epoch 252 tr: l 0.160 a 0.951 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.829sec(train) 4.547sec(infer)\n",
            "Epoch 252 tst: l 0.179 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 1.069sec\n",
            "Epoch 253 tr: l 0.160 a 0.951 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.168sec(train) 7.758sec(infer)\n",
            "Epoch 253 tst: l 0.179 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 0.712sec\n",
            "Epoch 254 tr: l 0.160 a 0.951 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.394sec(train) 7.958sec(infer)\n",
            "Epoch 254 tst: l 0.179 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 1.543sec\n",
            "Epoch 255 tr: l 0.159 a 0.951 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.832sec(train) 6.020sec(infer)\n",
            "Epoch 255 tst: l 0.178 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 1.084sec\n",
            "Epoch 256 tr: l 0.159 a 0.951 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 10.067sec(train) 5.056sec(infer)\n",
            "Epoch 256 tst: l 0.178 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 0.712sec\n",
            "Epoch 257 tr: l 0.158 a 0.951 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.593sec(train) 8.087sec(infer)\n",
            "Epoch 257 tst: l 0.178 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 1.380sec\n",
            "Epoch 258 tr: l 0.158 a 0.951 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.427sec(train) 7.098sec(infer)\n",
            "Epoch 258 tst: l 0.177 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 1.547sec\n",
            "Epoch 259 tr: l 0.158 a 0.951 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.689sec(train) 4.831sec(infer)\n",
            "Epoch 259 tst: l 0.177 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 1.127sec\n",
            "Epoch 260 tr: l 0.157 a 0.951 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.442sec(train) 7.004sec(infer)\n",
            "Epoch 260 tst: l 0.177 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 0.715sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 261 tr: l 0.157 a 0.952 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.791sec(train) 8.671sec(infer)\n",
            "Epoch 261 tst: l 0.176 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 1.550sec\n",
            "Epoch 262 tr: l 0.157 a 0.952 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.562sec(train) 6.791sec(infer)\n",
            "Epoch 262 tst: l 0.176 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 1.453sec\n",
            "Epoch 263 tr: l 0.156 a 0.952 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 9.524sec(train) 4.306sec(infer)\n",
            "Epoch 263 tst: l 0.176 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 0.998sec\n",
            "Epoch 264 tr: l 0.156 a 0.952 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.907sec(train) 8.840sec(infer)\n",
            "Epoch 264 tst: l 0.175 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 0.820sec\n",
            "Epoch 265 tr: l 0.156 a 0.952 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.476sec(train) 7.509sec(infer)\n",
            "Epoch 265 tst: l 0.175 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 1.556sec\n",
            "Epoch 266 tr: l 0.155 a 0.952 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.740sec(train) 3.913sec(infer)\n",
            "Epoch 266 tst: l 0.175 a 0.949 cl_acc 1.000 clct[50, 50, 50, 50] 0.555sec\n",
            "Epoch 267 tr: l 0.155 a 0.952 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.978sec(train) 3.518sec(infer)\n",
            "Epoch 267 tst: l 0.175 a 0.950 cl_acc 1.000 clct[50, 50, 50, 50] 0.588sec\n",
            "Epoch 268 tr: l 0.154 a 0.952 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.031sec(train) 3.313sec(infer)\n",
            "Epoch 268 tst: l 0.174 a 0.950 cl_acc 1.000 clct[50, 50, 50, 50] 0.554sec\n",
            "Epoch 269 tr: l 0.154 a 0.952 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.059sec(train) 3.524sec(infer)\n",
            "Epoch 269 tst: l 0.174 a 0.950 cl_acc 1.000 clct[50, 50, 50, 50] 0.587sec\n",
            "Epoch 270 tr: l 0.154 a 0.952 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.017sec(train) 3.328sec(infer)\n",
            "Epoch 270 tst: l 0.174 a 0.950 cl_acc 1.000 clct[50, 50, 50, 50] 0.559sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 271 tr: l 0.153 a 0.952 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.028sec(train) 4.069sec(infer)\n",
            "Epoch 271 tst: l 0.173 a 0.950 cl_acc 1.000 clct[50, 50, 50, 50] 0.584sec\n",
            "Epoch 272 tr: l 0.153 a 0.953 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.202sec(train) 4.823sec(infer)\n",
            "Epoch 272 tst: l 0.173 a 0.950 cl_acc 1.000 clct[50, 50, 50, 50] 0.930sec\n",
            "Epoch 273 tr: l 0.153 a 0.953 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.977sec(train) 5.162sec(infer)\n",
            "Epoch 273 tst: l 0.173 a 0.950 cl_acc 1.000 clct[50, 50, 50, 50] 1.228sec\n",
            "Epoch 274 tr: l 0.152 a 0.953 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.513sec(train) 5.341sec(infer)\n",
            "Epoch 274 tst: l 0.172 a 0.950 cl_acc 1.000 clct[50, 50, 50, 50] 0.958sec\n",
            "Epoch 275 tr: l 0.152 a 0.953 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.828sec(train) 6.883sec(infer)\n",
            "Epoch 275 tst: l 0.172 a 0.950 cl_acc 1.000 clct[50, 50, 50, 50] 1.311sec\n",
            "Epoch 276 tr: l 0.152 a 0.953 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.859sec(train) 5.835sec(infer)\n",
            "Epoch 276 tst: l 0.172 a 0.950 cl_acc 1.000 clct[50, 50, 50, 50] 0.835sec\n",
            "Epoch 277 tr: l 0.151 a 0.953 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.828sec(train) 7.252sec(infer)\n",
            "Epoch 277 tst: l 0.171 a 0.950 cl_acc 1.000 clct[50, 50, 50, 50] 0.932sec\n",
            "Epoch 278 tr: l 0.151 a 0.953 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.774sec(train) 5.501sec(infer)\n",
            "Epoch 278 tst: l 0.171 a 0.950 cl_acc 1.000 clct[50, 50, 50, 50] 1.298sec\n",
            "Epoch 279 tr: l 0.151 a 0.953 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 8.570sec(train) 5.449sec(infer)\n",
            "Epoch 279 tst: l 0.171 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 1.231sec\n",
            "Epoch 280 tr: l 0.150 a 0.953 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.523sec(train) 7.057sec(infer)\n",
            "Epoch 280 tst: l 0.171 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 1.306sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 281 tr: l 0.150 a 0.954 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.596sec(train) 3.614sec(infer)\n",
            "Epoch 281 tst: l 0.170 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "Epoch 282 tr: l 0.150 a 0.954 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.096sec(train) 3.345sec(infer)\n",
            "Epoch 282 tst: l 0.170 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 0.566sec\n",
            "Epoch 283 tr: l 0.149 a 0.954 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.954sec(train) 3.073sec(infer)\n",
            "Epoch 283 tst: l 0.170 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 284 tr: l 0.149 a 0.954 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.917sec(train) 3.492sec(infer)\n",
            "Epoch 284 tst: l 0.169 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 0.592sec\n",
            "Epoch 285 tr: l 0.149 a 0.954 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.084sec(train) 2.836sec(infer)\n",
            "Epoch 285 tst: l 0.169 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 0.546sec\n",
            "Epoch 286 tr: l 0.148 a 0.954 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.082sec(train) 3.547sec(infer)\n",
            "Epoch 286 tst: l 0.169 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 0.592sec\n",
            "Epoch 287 tr: l 0.148 a 0.954 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.935sec(train) 3.125sec(infer)\n",
            "Epoch 287 tst: l 0.168 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 0.554sec\n",
            "Epoch 288 tr: l 0.148 a 0.954 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.329sec(train) 3.534sec(infer)\n",
            "Epoch 288 tst: l 0.168 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 0.589sec\n",
            "Epoch 289 tr: l 0.147 a 0.954 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.712sec(train) 3.323sec(infer)\n",
            "Epoch 289 tst: l 0.168 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 0.554sec\n",
            "Epoch 290 tr: l 0.147 a 0.954 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.808sec(train) 3.517sec(infer)\n",
            "Epoch 290 tst: l 0.168 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "Epoch 291 tr: l 0.147 a 0.954 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.643sec(train) 3.506sec(infer)\n",
            "Epoch 291 tst: l 0.167 a 0.951 cl_acc 1.000 clct[50, 50, 50, 50] 0.590sec\n",
            "Epoch 292 tr: l 0.146 a 0.955 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.511sec(train) 2.941sec(infer)\n",
            "Epoch 292 tst: l 0.167 a 0.952 cl_acc 1.000 clct[50, 50, 50, 50] 0.555sec\n",
            "Epoch 293 tr: l 0.146 a 0.955 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.078sec(train) 3.526sec(infer)\n",
            "Epoch 293 tst: l 0.167 a 0.952 cl_acc 1.000 clct[50, 50, 50, 50] 0.592sec\n",
            "Epoch 294 tr: l 0.146 a 0.955 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 6.943sec(train) 3.178sec(infer)\n",
            "Epoch 294 tst: l 0.166 a 0.952 cl_acc 1.000 clct[50, 50, 50, 50] 0.554sec\n",
            "Epoch 295 tr: l 0.145 a 0.955 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.125sec(train) 3.538sec(infer)\n",
            "Epoch 295 tst: l 0.166 a 0.952 cl_acc 1.000 clct[50, 50, 50, 50] 0.590sec\n",
            "Epoch 296 tr: l 0.145 a 0.955 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.360sec(train) 3.320sec(infer)\n",
            "Epoch 296 tst: l 0.166 a 0.952 cl_acc 1.000 clct[50, 50, 50, 50] 0.554sec\n",
            "Epoch 297 tr: l 0.145 a 0.955 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.785sec(train) 3.506sec(infer)\n",
            "Epoch 297 tst: l 0.166 a 0.952 cl_acc 1.000 clct[50, 50, 50, 50] 0.473sec\n",
            "Epoch 298 tr: l 0.144 a 0.955 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.557sec(train) 3.391sec(infer)\n",
            "Epoch 298 tst: l 0.165 a 0.952 cl_acc 1.000 clct[50, 50, 50, 50] 0.591sec\n",
            "Epoch 299 tr: l 0.144 a 0.955 cl_acc 1.000 clct[300, 300, 300, 300] lr 0.100000 7.265sec(train) 3.073sec(infer)\n",
            "Epoch 299 tst: l 0.165 a 0.952 cl_acc 1.000 clct[50, 50, 50, 50] 0.474sec\n",
            "result written at output/results.pickle\n",
            "checkpoint written at output/checkpoint.pt\n",
            "---train cluster Ended in 1.04 hour (3739.506 sec) \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "config = get_config()\n",
        "\n",
        "config['train_seed'] = config['data_seed']\n",
        "\n",
        "print(\"config:\",config)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "exp = TrainMNISTCluster(config, device)\n",
        "exp.setup()\n",
        "exp.run()\n",
        "duration = (time.time() - start_time)\n",
        "print(\"---train cluster Ended in %0.2f hour (%.3f sec) \" % (duration/float(3600), duration))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deep_learning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
