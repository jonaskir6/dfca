{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import ipyparallel as ipp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import dfca_pn as DFCA\n",
    "import numpy as np\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6c788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config: {'m': 200, 'm_test': 40, 'p': 2, 'n': 500, 'uneven': False, 'local_model_init': False, 'participation_rate': 1, 'num_epochs': 600, 'batch_size': 50, 'tau': 5, 'lr': 0.25, 'data_seed': 12, 'train_seed': 12, 'project_dir': 'output'}\n",
      "Using device: mps\n",
      "torch.Size([50000, 3, 24, 24])\n",
      "torch.Size([10000, 3, 24, 24])\n",
      "Epoch -1 tr: l 2.304 a 0.097 clct[np.int64(109), np.int64(91)] cl_acc 0.615  2.767sec\n",
      "Epoch -1 tst: l 2.304 a 0.101 clct[np.int64(22), np.int64(18)] cl_acc 0.600  1.601sec\n",
      "Epoch 0 tr: l 1.894 a 0.349 clct[np.int64(200), np.int64(0)] cl_acc 0.500  lr 0.250000 23.989sec(train) 2.703sec(infer)\n",
      "Epoch 0 tst: l 1.888 a 0.345 clct[np.int64(40), np.int64(0)] cl_acc 0.500  1.606sec\n",
      "result written at output/results.pickle\n",
      "checkpoint written at output/checkpoint.pt\n",
      "Epoch 1 tr: l 1.708 a 0.453 clct[np.int64(199), np.int64(1)] cl_acc 0.505  lr 0.250000 19.172sec(train) 2.787sec(infer)\n",
      "Epoch 1 tst: l 1.782 a 0.432 clct[np.int64(39), np.int64(1)] cl_acc 0.525  1.605sec\n",
      "Epoch 2 tr: l 1.503 a 0.517 clct[np.int64(197), np.int64(3)] cl_acc 0.515  lr 0.250000 19.189sec(train) 2.824sec(infer)\n",
      "Epoch 2 tst: l 1.646 a 0.483 clct[np.int64(35), np.int64(5)] cl_acc 0.625  1.621sec\n",
      "Epoch 3 tr: l 1.531 a 0.448 clct[np.int64(118), np.int64(82)] cl_acc 0.910  lr 0.250000 19.551sec(train) 2.773sec(infer)\n",
      "Epoch 3 tst: l 1.729 a 0.490 clct[np.int64(20), np.int64(20)] cl_acc 1.000  1.657sec\n",
      "Epoch 4 tr: l 1.095 a 0.620 clct[np.int64(100), np.int64(100)] cl_acc 1.000  lr 0.250000 23.629sec(train) 2.906sec(infer)\n",
      "Epoch 4 tst: l 1.408 a 0.558 clct[np.int64(20), np.int64(20)] cl_acc 1.000  1.718sec\n",
      "Epoch 5 tr: l 0.989 a 0.665 clct[np.int64(100), np.int64(100)] cl_acc 1.000  lr 0.250000 23.928sec(train) 2.719sec(infer)\n",
      "Epoch 5 tst: l 1.374 a 0.592 clct[np.int64(20), np.int64(20)] cl_acc 1.000  1.606sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m exp = DFCA.TrainCIFARCluster(config, device)\n\u001b[32m     17\u001b[39m exp.setup()\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m res = exp.run()\n\u001b[32m     19\u001b[39m res_final.append([[r[\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res], [r[\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33macc\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res], [r[\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcl_acc\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res]])\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m exp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/decentralized-ifca/cifar/notebooks/dfca.py:252\u001b[39m, in \u001b[36mTrainCIFARCluster.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    249\u001b[39m result[\u001b[33m'\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m'\u001b[39m] = lr\n\u001b[32m    251\u001b[39m t0 = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m result[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.train(cluster_assign, lr = lr)\n\u001b[32m    253\u001b[39m t1 = time.time()\n\u001b[32m    254\u001b[39m train_time = t1-t0\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/decentralized-ifca/cifar/notebooks/dfca.py:365\u001b[39m, in \u001b[36mTrainCIFARCluster.train\u001b[39m\u001b[34m(self, cluster_assign, lr)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(m):\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m VERBOSE \u001b[38;5;129;01mand\u001b[39;00m m_i % \u001b[32m100\u001b[39m == \u001b[32m0\u001b[39m: \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mm \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm_i\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m processing \u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[33m'\u001b[39m, end =\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     (X, y) = \u001b[38;5;28mself\u001b[39m.load_data(m_i)\n\u001b[32m    367\u001b[39m     p_i = cluster_assign[m_i]\n\u001b[32m    368\u001b[39m     model = \u001b[38;5;28mself\u001b[39m.models[m_i][p_i]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Coding/decentralized-ifca/cifar/notebooks/dfca.py:544\u001b[39m, in \u001b[36mTrainCIFARCluster.load_data\u001b[39m\u001b[34m(self, m_i, train)\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    542\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33monly p=1,2,4 supported\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m544\u001b[39m X_batch2 = torch.rot90(X_batch, k=\u001b[38;5;28mint\u001b[39m(k), dims = (\u001b[32m2\u001b[39m,\u001b[32m3\u001b[39m))\n\u001b[32m    546\u001b[39m \u001b[38;5;66;03m# import ipdb; ipdb.set_trace()\u001b[39;00m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X_batch2, y_batch\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "with open(\"config.json\", \"r\") as read_file:\n",
    "    config = json.load(read_file)\n",
    "\n",
    "res_final = []\n",
    "\n",
    "start_time = time.time()\n",
    "config['data_seed'] = 12\n",
    "config['train_seed'] = config['data_seed']\n",
    "\n",
    "print(\"config:\",config)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "exp = DFCA.TrainCIFARCluster(config, device)\n",
    "exp.setup()\n",
    "res = exp.run()\n",
    "res_final.append([[r['test']['loss'] for r in res], [r['test']['acc'] for r in res], [r['test']['cl_acc'] for r in res]])\n",
    "del exp\n",
    "duration = (time.time() - start_time)\n",
    "print(\"---train cluster Ended in %0.2f hour (%.3f sec) \" % (duration/float(3600), duration))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
